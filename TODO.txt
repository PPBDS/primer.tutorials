TO-DO Items for Tutorials

* Change tutorial id's to just have the name, without the leading chapter numbers. This makes the default download file name nicer.

* New tutorial: 02-gathering-data. Add two tsv (which is tab delimitted) file. Use read_delim() to read these in. Include commas in at least one column.

* Remove all Confirm Correct Package Version questions from the top of each tutorial.

* geom_col exists in a couple of places, but I removed it from Chapter 2. Do we still need it? If not, just replace it as best you can in those plots. Use Find in Files to find these. Use geom_bar(). May need to manipulate the data. (Just fix in wrsngling.) Or just delete the question!

* To tibble section in chapter 2, discuss weird variable names. You can have a variable named `1` or `my variable`, but in order to use it in R code, you must use backticks. Have them make, by hand, a tibble with these variable names and then access the values in those variables.




To Discuss:

New version of Information and setup code chunk. Can go in all tutorials.

Add yourself as an author.

Fix items in instructions.Rmd specified with BG.



* Get .Rbuildignore to ignore any non Rmd file in inst/tutorials

Every exercise requires some answer from students. For example, after installing **usethis**, check the installation from the R prompt with:

> packageVersion("usethis")

The answer requires that the student paste in the resulting output. And, after they do this, we should always show them what we get when we do the same thing. These early tutorials are ones in which we can hope that students are reading as they go along.



To discuss:


In many settings, it is natural for a tools question to have three parts. First, run a line of code that reports on the value of something. Example:

rstudioapi::readRStudioPreference(name = "load_workspace", default = "Code failed.")

This will return the defaul value. (I am not what that is.)

Second, change the setting. This generally want return anything.

rstudioapi::writeRStudioPreference(name = "load_workspace", value = FALSE)

See how the first was "read" and the second was "write"? Then, the third and final step is to confirm that the change worked by re-running the first code again.

rstudioapi::readRStudioPreference(name = "load_workspace", default = "Code failed.")

And finish with a sentence that tells the student to notice that the value has changed and that it is now correct. (Of course, we "monitor" that by making them copy/paste this last command and its return from the Console into the tutorial.)




* What to do with PDF and tinytex? This all seemed to work very easily. Maybe just install and then issue packageVersion("tinytex")?

* mention iter = 10000

* Revisit making tables nice.


________________________________

To Explore:


* Explore the use of setup chunks that are referenced by name, rather than requiring that the code chunk names match up. Example: exercise.setup = "setupA"

* How can we add a test to ensure that the hashing and downloading of the answers works?

* Put the number of exercises in the group header so that students know how long? Or maybe put in in the exercise header in exercise 5, 10 and so on.

* Can we do web-scraping in a tutorial?

* Can we get shortcut keys to work in tutorials, especialy CMD-shift-m?

* Can question_text provide the user with more empty lines to fill?

* Can we give students a search box in the tutorial so that they can find answers to questions they have already done?

* There is a lot of redundent text in tutorials: Write your name, submit, et cetera. Any way to avoid copying/pasting that each time? Maybe we need a "make tutorial" script which would take a raw tutorial and then add that material to it. Perhaps a template? But then we can't (?) go back and make a change in our other 20 tutorials.

* Can we show "answers" to a Tutorial after students have submitted it? How? Maybe all we need is a script which pulls out the code for all the major examples and puts it in a single RMD which we could knit and distribute? If we had a standard scheme for naming the R code chunks in which these are created, pulling them out would be easy. Indeed, creating this file could be part of the test process!

* How can we automate the testing of hints? Or maybe make all hints eval=FALSE? Maybe have our testing process check that all hints have eval=FALSE?

* How test for exercise chunks with no lines, which causes a weird error?

* Interesting discussion and some plausible claims: http://laderast.github.io/2020/09/15/getting-learnr-tutorials-to-run-on-mybinder-org/. Claims that "the .Rmd file containing the tutorial should be named the same as the directory it is in." But why? Also: "I personally like to have individual data/ folders in each tutorial, as it makes making them a little easier to deploy." Interesting! Would be nice to make each tutorial more self-contained, perhaps.


* https://github.com/karthik/holepunch is interesting.




