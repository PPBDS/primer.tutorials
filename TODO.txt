Change DESCRIPTION to use the current released version of primer.data, so it stops updating each time.

```{r}
pre_title_footnote <- "Preceptor Table Title"
pre_units_footnote <- "Units and time information"
pre_outcome_footnote <- "Outcome or potential outcomes description"
pre_treatment_footnote <- "Treatment or intervention description"
pre_covariates_footnote <- "Covariates and their units"

pop_title_footnote <- "Population Table Title"
pop_units_footnote <- "Units and time information"
pop_outcome_footnote <- "Outcome or potential outcomes description"
pop_treatment_footnote <- "Treatment or intervention description"
pop_covariates_footnote <- "Covariates and their units"

p_tibble <- tibble::tribble(
  ~`Senator`, ~`Session Year`, ~`Support Bill`, ~`Oppose Bill`, ~`Lobbying Contact`, ~`Senator Age`,
  "...", "...", "...", "...", "...", "...",
  "...", "...", "...", "...", "...", "...",
  "...", "...", "...", "...", "...", "..."
)

d_tibble <- tibble::tribble(
  ~`Source`, ~`Senator`, ~`Session Year`, ~`Support Bill`, ~`Oppose Bill`, ~`Lobbying Contact`, ~`Senator Age`,
  "...", "...", "...", "...", "...", "...", "...",
  "...", "...", "...", "...", "...", "...", "...",
  "...", "...", "...", "...", "...", "...", "..."
)
```

```{r}
p_tibble_full <- p_tibble |>
  dplyr::add_row(!!!as.list(rep(NA, ncol(p_tibble)))) |>
  dplyr::mutate(More = c(rep(NA, nrow(.) - 1), "..."))

gt::gt(p_tibble_full) |>
  gt::tab_header(title = "Preceptor Table") |>
  gt::tab_spanner(label = "Unit", id = "unit_span", columns = c(`Senator`, `Session Year`)) |>
  gt::tab_spanner(label = "Potential Outcomes", id = "outcome_span", columns = c(`Support Bill`, `Oppose Bill`)) |>
  gt::tab_spanner(label = "Treatment", id = "treatment_span", columns = c(`Lobbying Contact`)) |>
  gt::tab_spanner(label = "Covariates", id = "covariates_span", columns = c(`Senator Age`)) |>
  gt::cols_align(align = "center", columns = gt::everything()) |>
  gt::cols_align(align = "left", columns = c(`Senator`)) |>
  gt::cols_width(columns = c(`Senator`, `Session Year`, `Support Bill`, `Oppose Bill`, `Lobbying Contact`, `Senator Age`, `More`),
                 widths = gt::px(c(9, 14, 14, 14, 18, 13, 5))) |>
  gt::fmt_markdown(columns = gt::everything())
```

```{r}
d_tibble_full <- d_tibble |>
  dplyr::add_row(!!!as.list(rep(NA, ncol(d_tibble)))) |>
  dplyr::mutate(More = c(rep(NA, nrow(.) - 1), "..."))

gt::gt(d_tibble_full) |>
  gt::tab_header(title = "Population Table") |>
  gt::tab_spanner(label = "Unit/Time", id = "unit_span", columns = c(`Source`, `Senator`, `Session Year`)) |>
  gt::tab_spanner(label = "Potential Outcomes", id = "outcome_span", columns = c(`Support Bill`, `Oppose Bill`)) |>
  gt::tab_spanner(label = "Treatment", id = "treatment_span", columns = c(`Lobbying Contact`)) |>
  gt::tab_spanner(label = "Covariates", id = "covariates_span", columns = c(`Senator Age`)) |>
  gt::cols_align(align = "center", columns = gt::everything()) |>
  gt::cols_align(align = "left", columns = c(`Senator`)) |>
  gt::cols_width(columns = c(`Source`, `Senator`, `Session Year`, `Support Bill`, `Oppose Bill`, `Lobbying Contact`, `Senator Age`, `More`),
                 widths = gt::px(c(9, 14, 14, 14, 18, 13, 5))) |>
  gt::fmt_markdown(columns = gt::everything())
```

### make_p_table()

* "pre_title_footnote <- "Preceptor Table Title"" should be "pre_title_footnote <- ""

* center the ... in p/d_tibble creation

* Example case does not work. 

* Example outcome labels need **if** and a reference to the treatment variable. Support in Contract and Support if No Contract. Include first sentence in vignette.

* d_tibble should not include Source. You add that at the end, just before the gt code.

* expand_input_tibble is not working. Ought to fail if not at least three rows.


* Tell the AI to reorganize the code. Make sure that, at the top, it calculates the sizes of various things (and their names) before it needs to use those things. AP: had it calculate length and number of characters



 * Make this a couple of separate functions. All included on this one page. All with roxygen stuff which documents them.
  + Key function is write_input_tribble(names) which takes a character vector of names and then writes out the input tribble text, centering as appropriate. 
  + Another function exapnd_input_tibble(x, type, source = FALSE) which takes a list of tibble x, a type which is preceptor or population and source which is TRUE or FALSE. If type is preceptor, then source must be false. If type is preceptor, then length(x) == 1. If type is population, then length(x) == 2. It first, takes any tibble in x and adds a more column and a missing third row. It preceptor, then done. If population, then combine the two tibbles and adding missing rows at start, between and end. Returns a single.

  Feed the result from expand_input_tibble() directly to the gt pipeline for making the table.


* Not this: "# Leave the third row and last column as-is to signal more rows exist" User only gets three rows. You add the third row of ... magically in your own code.  

* Use the number of characters in each label to space out the "..." entries so that they are beneath (centered) (even if only roughly) the relevant label. There is no Source column   AP: still working on

* You can change the `More` column header to ... in the gt() code using a command like col_label(). (Might not be exact name.)


* The Population Table code chunk does NOT get to assume that the Preceptor Table code was run. It begins with "raw" p_tibble and d_tibble, objects which only contain the data enterted by the user. That means that there will be some replication in the code in the two chunks: they both add a missing third row to p_tibble and a More column, for example. But that is OK.

* Moreover, that suggest that we might want a transform_raw_tibble(x, which.rows = c(1, 3), more = TRUE) function which takes a tibble (either raw p_tibble or d_tibble) and then adds missing rows, which you specify as an argument. This function goes in its own .R file and is documented and exported.

* Add source_col argument. TRUE by default. Only used in third code chunk, after pre_tibble and data_tibble have been slapped together to create pop_tibble. At that point, check source_col and, if true, add "Source" to the FRONT of pop_tibble with appropriate values. (Note that we label the missing middle rows as being from the relevant source.)

make_p_tables(type,                 AP: added this              Just one covariate
              unit_label,
              outcome_label,
              treatment_label,
              covariate_label,
              source_col = TRUE)     AP: added this




* Both tables always include a set of spanner headers. Finish help page.    AP: included all this and finished help page

    + "Unit" in a Preceptor Table and "Unit/Time" for a Population Table
    + "Outcome" for a predictive model or "Potential Outcomes" for a causal model.
    + "Treatment", which is only present for a causal model.
    + "Covariates"

The point of the spanners is to indicate the type of variables. The variable names themselves will differ across tables and must be given by the author.  AP: Implemented

* We use the term "label" rather than "vars" to indicate that these are the labels in the table rather than the variable names from the data. As such, they are often human-readable phrases with spaces, like "Math Score if in Small Class". Will long labels be wrapped automagically? We probably want that. Of course, these descriptions can not be too long and so must be shortened in some way. In a pinch, the variable names may be used, but this is not preferred. AP: added this in vignette

* If type = "predictive", then ouctome_label must be of length one, since there is only one outcome --- and the spanner must indicate "Outcome". If type = "causal", then outcome_label must be of length two or more --- and the spanner must indicate "Potential Outcomes". AP: implemented

    + There will be a footnote for the title itself. This allows the author to provide background on the question which the table allows us to answer, once we fill in the missing values.        AP: added all footnote prose to vignette

    + There will be a footnote to the Units (if Preceptor) or Units/Time (if Population) spanners.  This is an opportunity for the author to explain the range of units and the time period covered. There is always something to say about these topics and, indeed, sometimes several sentences are necessary. A Preceptor/Population Table is self-contained. It includes all the text you need to understand it. (The language in this and other parts of the overview should be used in the help page.)

    + There will be a footnote to the "Outcome/Potenial Outcomes" spanner which explains how/why we determined that this was a predictive or causal model. It might also report some details about our actual outcome variable and why it might not be exactly what we are looking for, especially given differences between the outcome we have in our data and the outcome we were initially interested in when we started the process.

    + If it is a causal model, there will be a footnote to the "Treatment" spanner. There is almost always something useful to say about the treatment, especially in terms of how the treatment in the data differs from the treatment in the  Preceptor Table.

    + There will be a footnote to the "Covariates" spanner. There is almost always something useful to say about the covariates, especially in terms of how the covariates in the data differs from the covariates in the  Preceptor Table.
    
    + Perhaps it should be easy for the author to delete these footnotes altogether. Perhaps the code is such that, at the top, there is a covariates_footnote variable, which has "Fix Me!" text but which, if set to NULL, generates no footnote, and no error.

* Think about the information in these tribbles. The great benefit of tribbles is that it allows us to enter information by rows in the QMD, which makes lining things up much easier.      AP: trying to make things line up still (not done)

    + To make alignment easier, I think that there is just one tribble printed out for authors to fill in the values for. That tribble has length(outcome_label) + length(treatment_label) (which is always one if present?) + length(covariates_label) rows, each with the variable name, in backticks by default because they often include spaces, corresponding to the relevant label.

    + This tibble has a name. The gt code uses this name, and its knowledge of the values of the label variables. AP: not exactly sure what this is saying, but I'm pretty sure I did it

    + Note that this gets to the issue of creating a Preceptor and its corresponding Population Table at the same time. After all, if every column (and every row?) in the Preceptor Table is in the Population Table, then creating them at the same time makes sense.     AP: did that, p_tibble is incorporated into d_tibble

    + How do we handle conflicts between variables we create in this process, like the data entry tibble, and other variables in the overall document? I suspect that there is some way to make the entire code chunk a self-contained environment which does not interact with anything before or after it. That would be convenient. Maybe withr?     AP: code to remove the variables after made

 * Some miscellaneous details: 

    + The first column in Population Table is always "Source" and it has no spanner header.  It takes the value of "Data" for any rows from the data and "Preceptor Table" for any rows from the Preceptor Table.  But how does it know which rows from from where? Does the author need to enter it? If so, then the data tibble needs a "Source" row whenever `table` is "Population."       AP: DONE

* Do not provide default values for the labels, other than NULL. If an argument is not supplied, an error occurs.  AP: just fixed this

* Provide an example which works. OK if it is wrapped with donotrun{}, but does it really need to be?    AP: not necessary since we are using a vignette

* This does not work: make_p_tables(FALSE, "Senator", "Ouctome", "Phone Call", c("sex", "age", "incumbent")) AP: i have done something else for now    AP: new method implemented (DONE)


* Keep in mind, we need gt, tibble and glue libraries. How hard would it be to not use glue? (Do this at the end.) There are three approaches to the library issue: 1) Do nothing except ensure that the packages are in the DESCRIPTION file. 2) Load the packages in the code which is pasted in. 3) Use :: notation to call functions directly, like gt::tab_spanner(). Ask AI. What does it say?    AP: working on it (not done)


### Summer Associates

Think harder about where the data for these tutorials comes from. Does it all really need to be in primer.data? Wouldn't it be good to put some garbage data sources for the earlier tutorials into this tutorial itself. The biden polling data, for example. Three issues:

    * It is wrong for that data to be created on the fly. That is too confusing for students.
    * The data is too trivial for primer.data.
    * We should be making the data "fake" by adding sex and age and telephone_call to the tibble, even if we have to make it up. We want to move away from having students "imagine" treatment variables and other covariates, at least in the earlier tutorials.

Consider adding data used in class sessions, like resumes, to primer.data.


031-sampling exercises take too long time to  process. either shorten them or delete them.

Do we need some simulation tutorials?




### primer.data


### Animation

Overview of Cardinal Virtues and key concepts.

Use the DGM to create one complete Preceptor Table. In that draw, Joe is a 6 for `att_end`. Then, do another draw. Joe is a 5. Do a thousand draws. You then have a thousand Preceptor Tables. Calculate the Quantity of Interest for each Preceptor Table. The 1,000 values are the posterior for your QoI. Would be great to make a cool animation of this, perhaps with a simple example. Would be fun to have a similar animation for each chapter. Great summer project!

### Cross Sectional Exercises for Progressive Knowledge Drops


### Sharav

Tutorial selector as Positron extension. 

### Ansh

Fixes to bugs reported by students.

### Other Items

Submit a PR with some material for marginaleffects webpage: 
https://github.com/vincentarelbundock/marginaleffects/issues/1197


### Preceptor

Add some questions to Courage in template_tutorial to handle discussion/dismisal of hypothesis tests.

Decide on naming convention. Name can include model form (linear/logistic/multinomial), type (causal/predictive) and, perhaps, difficulty level. Want to get away from arbitrary number of parameter. Think harder about directory names and id's. Or maybe just give them fun names like `biden` and `police-stops`, and then an ordering. 

Upon reflection, we must have a recommended ordering, and given that, we hardly need a difficulty level. And no one will care if we have the logistic-causal or any other nonsense in the name.

Maybe remove file name, like postcards.qmd, from all show_file questions, at least after tutorial 5 or so. One less thing for tutorial writers to worry about. One more thing which forces students to think about what they are typing, rather than just copying/pasting our code.

Delete katex and broom.helpers from imports?





1) Talk about probability family. 2) Talk about link function. 3) LaTeX with parameters and error term. 4) LaTeX math with parameter values and no error term. 5) Verbal description of the model.

Update template_tutorial.Rmd. Get rid of DK stuff.

The inferences() function in marginaleffects seems useful. Also, we should make use of more marginaleffects functions. For example, instead of interpreting tidy() tables, might interpret averages() (?) and similiar functions, which are useful themselves and set the scene for the plots.



Deal with the word "render" in template_tutorial.Rmd. `Cmd/Ctrl + Shift + K` now runs Quarto preview, not Quarto render . . .

Edit RCM tutorial to remove all the make work.

Edit Probability tutorial to remove all the make work.

Finish Tests section of Cardinal Virtues vignette.



Optional: Read first nine chapters https://www.tmwr.org/. Go fast if you have seen this
material before. 

Choose a dataset which might be fun to use.

Make a new tutorial 151. New directory. Use the template. 

Start by making model. What kind? Flexible.
  
### Simulation, dice and beads

* Discuss tutorial which would simulate the NCAA basketball tournament. What are the odds of a 5th seed winning the whole thing? Follow the 538 approach of just simulating the whole tournament a lot. Or maybe something similar but simpler?

* Discuss simulating craps. Win with 7 or 11. Lose with 2, 3, or 12. Then roll until you make your "point" and win or "crap out" by rolling  a 7.

* Give the formula for the coin and President and height examples. The mathematical distribution is one, by definition, with a formula.

What does the Preceptor Table look like for dice and then for beads?

For dice, we have one row for each die and each point in time at which we might roll that die. If the Preceptor Table were filled in, we could answer any question because we would know that Die 1 rolled a 3, Die 2 a 4, and so on.

For beads, we have one row for each shovel result (8 reds or 6 reds or whatever) at each point in time. Again, if we had all the missing rows filled in, we could answer any question. 

I guess that you could do one row for each empty space in the shovel . . . Maybe there is a useful discuss to be had about it depending on what you care about. If your unit of analysis is the student, then you care about the test score for each student in a class. If the unit is the class, then maybe you only care about the average of the class as a whole.

Could be useful to use these simple examples to hammer home the theme of the DGM. We can create and use a DGM without doing any inference!


### Exploration Projects

Original idea for this comes from Jade. Key points:

* Ultimate standard for success of the course is the quality of student final projects. So, the more time that students practice making final projects, the better.

* We want students to have a professional portfolio. These projects can, perhaps with some more work, serve as starter elements of that portfolio.

* Students vary in terms of their talent and willingness to work hard. Exploration Projects provide an opportunity for skilled and diligent students to push themselves.

* Projects start with standard construction of a website, so require that students have completed the two Quarto websites tutorial. 

* We encourage the use of AI extensively. Indeed, a primary purpose of these projects is to force students to make greater use of AI tools. There is no more important skill to teach them.

* All the resulting URLs are gathered and shared with the class as a whole, with the best results highlighted.

* We specify the data that should be used for the plot, at least for the first few tutorials. Perhaps the naming convention is EP: Diamnds, EP: Crime, and so on --- where "EP" stands for Exploration Project and the name of the dataset to use follows the colon.

* Ideally, we might connect these projects to cool-looking professional work. That is, we find a nice looking New York Times data project, with some public data, and then encourage students to make something which looks just as good if not better.

### Possible Data Sets to Use for New Tutorials

These are all chosen to have thousands of observations and scores of variables, thereby 
allowing for machine learning models.

Source: https://vincentarelbundock.github.io/Rdatasets/articles/data.html

https://vincentarelbundock.github.io/Rdatasets/doc/openintro/labor_market_discrimination.html

https://vincentarelbundock.github.io/Rdatasets/doc/openintro/hfi.html

https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Caravan.html

https://vincentarelbundock.github.io/Rdatasets/doc/modeldata/ames.html

https://vincentarelbundock.github.io/Rdatasets/doc/Ecdat/Car.html

https://vincentarelbundock.github.io/Rdatasets/doc/AER/STAR.html

https://vincentarelbundock.github.io/Rdatasets/doc/sampleSelection/RandHIE.html

https://vincentarelbundock.github.io/Rdatasets/doc/modeldata/deliveries.html

https://vincentarelbundock.github.io/Rdatasets/doc/modeldata/hotel_rates.html

### Other Data Sets

Stereotype threat replication: https://osf.io/preprints/psyarxiv/qctkp



#### Other Items

ordinal package is being maintained, which is nice.


### Projects to Consider

* Consider switching categorical to multinomial and Bernoulli to binomial.

* Update 4 parameters so it does not produce these warning messages by default: https://rpubs.com/lelasengupta/four-parameters

* Explore gradetools: https://federicazoe.github.io/gradetools/index.html

* Deal with katex. Seems like all (?) Windows users are getting an error about needing the katex package. But nothing for Mac users. So, I added katex as an import, which is an absurd hack. Better approach?


* 



## Later

r-universe for making primer.tutorials easier to install; maybe this would allow Window users to not have to install RTools?

Maybe r2u is as good or better than caching. https://eddelbuettel.github.io/r2u/

https://github.com/eddelbuettel/r2u/blob/master/inst/scripts/add_cranapt_jammy.sh

https://github.com/eddelbuettel/tidycpp/blob/master/.github/workflows/ci.yaml

https://community.rstudio.com/t/output-directory-in-quarto-cli-not-respected/143762/3


## Other stuff


### Visualization Links

http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html
https://cran.r-project.org/web/packages/ggside/vignettes/ggside_basic_usage.html

https://ggplot2.tidyverse.org/articles/

[A Gentle Guide to the Grammar of Graphics](https://pkg.garrickadenbuie.com/gentle-ggplot2) or https://moderndive.com/2-viz.html#grammarofgraphics

Tidy Tuesday: https://github.com/rfordatascience/tidytuesday

gghighlights, ggsides, ggrepel



## Chapter 5 and Associated Tutorials




### Tutorials to add

Let's discuss the six broad categories of tutorials which we might add, especially to chapters 5 through 11.

First, we can just do more examples. Use different data with a different question, but all the same steps as in the chapter itself. Such examples will generally, like 082, do two analyses: one with all the data (to show the truth) and one in which representativeness fails in a way which we define, thereby showing how we can be led astray. Last step is to compare the answers from these two approaches, thus emphasizing the importance of humility.

Second, stand-alone tutorials on useful topics, like text modeling or networks or rtweet or whatever. These could go in any chapter and would not be restricted to having X number of parameters.

Third, we could cover many other model families, again perhaps not worrying too much about whether or not they have the "right" number of parameters. Simplest here would be other stan_glm families. That is, show a weird data set in which the outcome variable is something that should be fit with poisson or something, and then use family = poisson. Goal would be to emphasize that there are many possible models.



Obviously, we could also combine these in various ways. Upon reflction, we should save the machine learning examples for later chapters in which we have several righhand side variables. Indeed, we could have three machine learning tutorials in chapter 11.

* Compare results from rstanarm model to an approach, like we learned in Chapter 5, in which we do the analysis "by hand," creating the joint distribution and then the posterior distribution. This is easiest to do for Chapter 6. Indeed, you can just take the code from Chapter 5, make it continuous by sampling lots of possible values, and then compare to rstanarm. Should work fine. More ambitiously, we could do this for Chapter 7. This requires a three dimensional joint distribution because there are two unknown parameters and then a two dimensional posterior, with one dimension for mu and one for sigma. This is cool! But perhaps over kill.

* Expand the Getting Started tutorial and make it better connected to the Primer chapter. Students read the chapter and then do the tutorial. The tutorial ought to confirm that they have done everything that the chapter told them to do. Even though it is done in class, it could be a bit longer, so 10 or 15 questions.


* A "models" which would be a full dry run of their final projects. Download some data (maybe lots of little data files) with an R script. Clean the data in other R script. Make the model (a simple two parameter model) in another R script. Then, make a quarto website which uses the model to make pretty pictures which answer a couple of questions. Should show results using gtsummary to make pretty tables of model results. Might even show how stan_glm() models differ from lm() models. Or maybe run stan_glm() with option to get the lm() results. Example usage: https://ipums.github.io/pma-data-hub/posts/2021-07-01-covid-tables/

* Advanced plotting, ideally focussed on all a variety of different plotting approaches designed for modeling-type questions and answers. Maybe https://feddelegrand7.github.io/ddplot/.

* Would it be possible to have tutorials in the last few weeks which were, more or less, final project check-ins . . .

* A tutorial about working with textual data. Perhaps based on tidytext book. Also: https://datavizs21.classes.andrewheiss.com/example/13-example/

* Regression to the mean

* The garden of forking paths

* M/S errors


* An rtweet tutorial: https://github.com/ropensci/rtweet

* A Python tutorial. See the new features in learnr: "Added a new polyglot tutorial to learnr. This tutorial displays mixing R, python, and sql exercises. See run_tutorial("polyglot", "learnr") for a an example. (#397)"


### To discuss

* Another example set: https://openintrostat.github.io/ims-tutorials/

* Specify which versions of learnr (and other Github packages?) we want. Otherwise, you always get the head, which may not be desirable. Do we really still need to be using the development version of learnr? That makes me nervous! And why haven't they updated the version on CRAN for more than 15 months?

* Best single summary of tutorial tools/approaches: https://damien-datasci-blog.netlify.app/post/how-to-make-an-interactive-tutorial-to-teach-r-an-overview/


* Another way to host the tutorials: https://higgi13425.github.io/medical_r/posts/2020-12-27-creating-mini-learnr-apps-and-hosting-on-a-server/


* mention iter = 10000

### To explore later

* Powerful approach for hosting cool looking tutorials: https://github.com/ines/course-starter-r. One example of a tutorial using this approach:  https://github.com/noamross/gams-in-r-course

* Should our tutorials look more like this one? https://minecr.shinyapps.io/dsbox-05-moneyinpolitics/. I don't think so. Too many words, not enough typing.

* Explore the use of setup chunks that are referenced by name, rather than requiring that the code chunk names match up. Example: exercise.setup = "setupA"

* Put the number of exercises in the group header so that students know how long? Or maybe put in in the exercise header in exercise 5, 10 and so on.

* Can we give students a search box in the tutorial so that they can find answers to questions they have already done?


* Interesting discussion and some plausible claims: http://laderast.github.io/2020/09/15/getting-learnr-tutorials-to-run-on-mybinder-org/. Claims that "the .Rmd file containing the tutorial should be named the same as the directory it is in." But why?

* https://github.com/karthik/holepunch is interesting. But it also hasn't been updated in more than 7 months.

## Videos Worth Looking At?

Data Science Mini Projects: https://www.youtube.com/playlist?list=PLpdmBGJ6ELUJM6_vKQbpi9vGc65Sn0uPr
Draw Multiple Time Series in Same Plot: https://www.youtube.com/watch?v=FNXnJ_zT1gE
Barplot in R: https://www.youtube.com/watch?v=pYbuWU77QkU&feature=youtu.be

# Interestin approach for next summer

## Material from JSM 2021

Education section: https://matackett.github.io/open-stat-ds-ed/

Interesting discussion of using art to bring students into data science.

Consider the use of ggirl package for encouraging students to send someone an actual postcard.

### Later tutorials in later chapters

The first tutorial for each of the later chapters is easy. Just do more or less exactly what the chapter does. Recall that, one day, we expect to incorporate those questions directly into the chapter itself. So, the more that it just forces students to type in the same commands as in the chapter, the better. But, for the most part, the chapters are not that long! There is only about one tutorial worth of material.

What do we do for the other 5 or so tutorials for each chapter? Good question! Honestly, I am not sure. Here are some ideas:

* The second tutorial could be very similar to the first -- and, therefore, to the chapter. Just use a different variable(s) and/or a different tibble, but answer the same sorts of questions in the same way.

* Don't be repetitive in the written questions. It is fine, in the first tutorial for each chapter, to ask students to write a definition of the Preceptor Table. Indeed, we should always have that question in each first tutorial. But, we don't want that question in each of the 5 tutorials for a single chapter.

* Use written questions which do require different answers depending in the data/variable used. We can't resuse "Define a Preceptor Table" because that question has the same answer every time. Consider a different question:

> Write a paragraph which explores reasons why we should **not** consider the Preceptor Table and our data set as being drawn from the same population?

That is a good question, not least because it needs a different answer for each data science problem we confront. Another good example:

> Write a paragraph explaining why, even though the data is not a random sample, we may still consider it to be "respsentative" enough to move forward?

Again, this requires a different answer for each new tibble.

* We don't usually (ever?) ask questions about the four Cardinal Virtues directly. They are simply a pedagogical device we use to help students organize their work. But we do ask written questions about the key concepts (population, representativeness, validity) in each and every tutorial. These are difficult concepts with no "right" answers. We need to wrestle with them every week.

* A tutorial after the first might do a very similar exercise but with three differences. First, it can go faster, given that students have already seen the basics fairly slowly in the first tutorial. Second, it can add some complexity, make the modeling problem just a little more difficult than the basic case. Third, it can add some new magic. Perhaps it grabs data using a new package instead of just using another boring data set from **primer.data**. Perhaps it creates a nicer plot with some geoms we have not used before.

* If the main example is the chapter is one which uses a linear model, then tutorial 2 could use a logistic model and then tutorial 3 could use the third kind of model (which we have not chosen yet). Similarly, if the chapter (and first tutorial) does a predictive mode, then tutorial 3 should do a causal model.


* Another type of tutorial is one which uses fake data which has been manipulated to violate the assumptions which students are making. Show them Preceptor's Posterior and compare it to their own.

* Seems like you can't include LaTeX math in a R exercise message. Generates an error under R CMD check. Example of something which fails:

Add the formula to `model.qmd`, `$$ biden_i =  \mu + \epsilon_i $$`. `Cmd/Ctrl + Shift + K`. Ensure that the formula is looks correct. 

<!-- # ```{r courage-12} -->
<!-- # question_text(NULL, -->
<!-- # 	message = "$$ biden_i =  \mu + \epsilon_i $$", -->
<!-- # 	answer(NULL, correct = TRUE), -->
<!-- # 	allow_retry = FALSE, -->
<!-- # 	incorrect = NULL, -->
<!-- # 	rows = 6) -->
<!-- # ``` -->


Fix MacOs Github issues. I would like to see green!

## Packages to Delete/Reconsider

Why do we need to explicitly load katex at all? Shouldn't quarto or whatever take care of this for us?

Why do we need the hack of the primer.tutorials-package nonsense?

Even if we need katex, we do we need it in imports rather than just suggests? Maybe adding library(katex) to all the Rmd files would solve the problem?

Probably don't need rsconnect, and a bunch of other things in Suggests?