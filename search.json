[{"path":"https://ppbds.github.io/primer.tutorials/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2020 David Kane Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Cardinal Virtues","text":"world confronts us. Make decisions must. problem trying solve? Imagine running Governor Texas next election. campaign budget. goal win election. Winning election involves convincing people vote getting supporters vote. send postcards registered voters likely vote ? postcards say? Imagine charge ordering uniforms bootcamp recruits Marine Corps next year. many factors consider: cost different designs, number male female recruits, distributions heights weights, . order? Imagine historian trying understand 1992 US Presidential election. voted? vote ? vote ? might led vote differently? course, never going able answer questions. much hard! able make progress, learn something world help us make better decisions.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"question","dir":"Articles","previous_headings":"","what":"Question","title":"Cardinal Virtues","text":"motivated issue imagining specific person facing collection decisions, can move onto broad question , hope, relevant. Examples: voters respond postcards? height vary sex? explains individual voting decisions 1992 US Presidential election? order make progress, drill specific question, one specifies variables actually data. key refinement stage gone general terms variable specific definition, available data set access. Examples: causal effect voting behavior receiving postcard specifies neighbors voted last election? height young men women US? likelihood voting Bush/Clinton/Perot 1992 US Presidential election vary sex? specific variables, can construct statistical model. statistical model can used answer sorts questions. course, data must contain variables allow us answer question, otherwise need new question. Specifics help fix ideas start work project. Just start looking number mean can’t consider questions. interim goal provide answer specific question, along uncertainty answer. calculate , create series models, final version refer data generating mechanism (DGM). DGM, can answer specific question. can also answer lots similar questions, thereby allowing discuss broader topic much detail. chapter features sections sub-sections use . , three sub-sections Wisdom, four sub-sections Justice, three Courage two Temperance. Quantity Interest number want estimate. answer specific question. almost always calculate posterior probability distribution Quantity Interest since, real world, never know QoI precisely. Exploring general question require calculation many Quantities Interest. specific question, can start Cardinal Virtues. section begins one sentence summary component steps relevant virtue. , obviously, highly similar chapter chapter. OK! want reinforce steps path . battle plan survives first contact enemy intact. applies questions data use answer . questions evolve analysis continues. Ultimately, can answer questions data . questions may close ones started, rarely identical.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"wisdom","dir":"Articles","previous_headings":"","what":"Wisdom","title":"Cardinal Virtues","text":"Wisdom requires creation Preceptor Table, examination data, determination, using concept validity, whether can (reasonably!) assume two come population. Wisdom first Cardinal Virtue data science. Begin quantity interest. QoI causal effect simply forecast? units outcomes imply? Preceptor Table allow calculate QoI easily? Perform exploratory data analysis (EDA) data . valid consider data (theoretical) data Preceptor Table arisen population? , may continue. , attempt estimate QoI ends now. Preceptor Table smallest possible table rows columns , missing data, question easy answer. Predictive Models Causal Models different predictive models one outcome column. Causal models one (potential) outcome column need one potential outcome order estimate causal effect. first step data science problem determine QoI requires causal predictive model. don’t care Joe done counter-factual world got different treatment, care predicting Joe given treatment received, just need predictive model. Units determined original question, also determines QoI. rows, Preceptor Table data. Variables general term columns Preceptor Table data. fact, term even general since may refer data vectors like order answer question , sadly, available data. columns data subset variables might interested. outcome important variable. determined question/QoI. definition, must present data Preceptor Table. Different problems might answered data set, different variables playing role outcome case. Covariates general term variables outcome. variables, three different contexts might use term covariates. First, covariates variables might connection outcome, even included data. Second, covariates variables data outcome. Third, covariates can refer just subset variables data actually use model. second usage , obviously, subset first, third usage subset second. Units, outcomes covariates important parts every data science model. Causal, predictive, models also include least one treatment, just covariate can, least theory, manipulate. QoI determines units outcomes model. Potential Outcome outcome individual specified treatment. potential outcome just regular outcome case causal model. predictive model, just outcome. just another variable, one , context problem, interested explaining/modeling/predicting. causal model, hand, least two outcomes: outcome happens unit gets treatment outcome happens unit gets control. refer outcomes potential outcomes. Causal Effect difference two potential outcomes. Rubin Causal Model approach statistical analysis cause effect based framework potential outcomes. create Preceptor Table, answer series questions: Causal predictive? Look verbs like “cause” “affect” “influence.” Look question implies comparison, single individual unit, two states world, one unit receives treatment XX one unit gets treatment YY. Look discussion something can manipulate. Remember motto: causation without manipulation. look see question seeks compare two potential outcomes within unit, rather outcome two different units. none present, use predictive model. need know answer question outcome one value treatment, model predictive. case, treatment truly “treatment.” just covariate. Example: att_end women get treatment? predictive question, causal one, need know outcome treatment control individual woman. moment time question refers? Every question refers moment time, even moment stretches bit. set adults today different set 10 years ago, even yesterday. need refine original question. Assume referring July 1, 2020 even though, cases, people interested now. changed original question : proportion people make $100,000 liberal? July 1, 2020, proportion people made $100,000 liberal? units? question often makes fairly clear, least terms row corresponds , whether individuals, classrooms, countries, whatever. , questions often fail make clear total number rows. example question specify relevant population. people world? adults? adults United States? purpose paragraph refine question, make specific. Assume interested adults Chicago. question now : July 1, 2020, proportion adults Chicago made $100,000 liberal? back--forth question analysis standard part data science. rarely answer exact question started , especially question never specific enough answer without qualifications. Furthermore, data may allow us answer question, may enough answer related question. good enough boss/client/colleague asked original question? Maybe? won’t know ask. job data scientists simply answer question asked, help questioner determine question can answered data , question helps make decisions face. outcomes? (model causal, must least two potential outcomes. can’t figure , model probably predictive.) model predictive, one outcome. paragraph just name relevant variable. also starts discussion exactly might measure variable. consider underlying concept, “liberal,” process might operationalize concept. Perhaps using written survey YES/answer. Perhaps -person interview 1-7 Likert scale, answers 1 2 coded, us, “liberal.” details may may matter, least need discuss issue. covariates? Discussing covariates context Preceptor Table different discussing covariates context data. Recall Preceptor Table smallest possible table, don’t need include every relevant variable. need discuss variables necessary answer question. treatments, ? (“treatments” predictive models. covariates.) treatment covariate , least theory, can manipulate manipulation necessary answer question. , create Preceptor Table. case, Preceptor Table includes N rows, one every adult Chicago July 1, 2020. includes two columns: outcome (liberal) single covariate (income). Preceptor Table, missing data, trivial calculate percentage adults (make $100,000) liberal. Preceptor Table , really, smallest possible table solved problem. table single cell containing quantity interest! , obviously, stupid. Preceptor Table smallest possible table, rows corresponding units information, allows us answer question. can never look data much. – Mark Engerman always short section devoted exploratory data analysis. EDA include least one textual look data, usually using summary(), skim(), glimpse(), print() slice_sample() also available. also include least one graphic, almost always outcome variable y-axis one covariates x-axis. data set often include columns rows irrelevant question. columns rows removed, creating tibble used Courage section. name tibble often something convenient like ch_7. also makes sense include discussion data comes . definitions variables? chose sample? documentation? sort background sets stage examining validity. Validity consistency, lack thereof, columns data set corresponding columns Preceptor Table. order consider two data sets drawn population, columns one must valid correspondence columns . Validity, true (least reasonable), allows us construct Population Table, first step Justice. Validity discussions always one (short) paragraph relevant variable (outcome relevant covariates), examples validity might hold. Validity discussion finishes brief discussion along lines : “Despite concerns, assume validity hold.” section can longer course, depending many details discussed EDA. central point two (potentially!) completely different things: Preceptor Table data. Just two columns name mean thing. Indeed, often quite different! control Preceptor Table , lesser extent, original question, can adjust variables “closer” data actually . another example iterative nature data science. data close enough question, check boss/colleague/customer see can modify question order make match data Preceptor Table close enough validity hold. conclude Wisdom section summarizing hope use data answer question started . Example: Using data 2012 survey Boston-area commuters, seek understand relationship income political ideology Chicago similar cities 2020. particular, percentage individuals make $100,000 per year liberal? Note specific question morphed general examination “relationship” income political ideology. order answer specific question, always examine general relationship. always build model. can use model answer question started well related questions. thinking hard original question data, come question may possible answer data . Note Cardinal Virtue section finishes sentence two summarizing learned. sentences combined end analysis. One key products data science project paragraph summarizes key conclusions.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"preceptor-table","dir":"Articles","previous_headings":"","what":"Preceptor Table","title":"Cardinal Virtues","text":"Preceptor Table smallest possible table rows columns , missing data, question easy answer. Predictive Models Causal Models different predictive models one outcome column. Causal models one (potential) outcome column need one potential outcome order estimate causal effect. first step data science problem determine QoI requires causal predictive model. don’t care Joe done counter-factual world got different treatment, care predicting Joe given treatment received, just need predictive model. Units determined original question, also determines QoI. rows, Preceptor Table data. Variables general term columns Preceptor Table data. fact, term even general since may refer data vectors like order answer question , sadly, available data. columns data subset variables might interested. outcome important variable. determined question/QoI. definition, must present data Preceptor Table. Different problems might answered data set, different variables playing role outcome case. Covariates general term variables outcome. variables, three different contexts might use term covariates. First, covariates variables might connection outcome, even included data. Second, covariates variables data outcome. Third, covariates can refer just subset variables data actually use model. second usage , obviously, subset first, third usage subset second. Units, outcomes covariates important parts every data science model. Causal, predictive, models also include least one treatment, just covariate can, least theory, manipulate. QoI determines units outcomes model. Potential Outcome outcome individual specified treatment. potential outcome just regular outcome case causal model. predictive model, just outcome. just another variable, one , context problem, interested explaining/modeling/predicting. causal model, hand, least two outcomes: outcome happens unit gets treatment outcome happens unit gets control. refer outcomes potential outcomes. Causal Effect difference two potential outcomes. Rubin Causal Model approach statistical analysis cause effect based framework potential outcomes. create Preceptor Table, answer series questions: Causal predictive? Look verbs like “cause” “affect” “influence.” Look question implies comparison, single individual unit, two states world, one unit receives treatment XX one unit gets treatment YY. Look discussion something can manipulate. Remember motto: causation without manipulation. look see question seeks compare two potential outcomes within unit, rather outcome two different units. none present, use predictive model. need know answer question outcome one value treatment, model predictive. case, treatment truly “treatment.” just covariate. Example: att_end women get treatment? predictive question, causal one, need know outcome treatment control individual woman. moment time question refers? Every question refers moment time, even moment stretches bit. set adults today different set 10 years ago, even yesterday. need refine original question. Assume referring July 1, 2020 even though, cases, people interested now. changed original question : proportion people make $100,000 liberal? July 1, 2020, proportion people made $100,000 liberal? units? question often makes fairly clear, least terms row corresponds , whether individuals, classrooms, countries, whatever. , questions often fail make clear total number rows. example question specify relevant population. people world? adults? adults United States? purpose paragraph refine question, make specific. Assume interested adults Chicago. question now : July 1, 2020, proportion adults Chicago made $100,000 liberal? back--forth question analysis standard part data science. rarely answer exact question started , especially question never specific enough answer without qualifications. Furthermore, data may allow us answer question, may enough answer related question. good enough boss/client/colleague asked original question? Maybe? won’t know ask. job data scientists simply answer question asked, help questioner determine question can answered data , question helps make decisions face. outcomes? (model causal, must least two potential outcomes. can’t figure , model probably predictive.) model predictive, one outcome. paragraph just name relevant variable. also starts discussion exactly might measure variable. consider underlying concept, “liberal,” process might operationalize concept. Perhaps using written survey YES/answer. Perhaps -person interview 1-7 Likert scale, answers 1 2 coded, us, “liberal.” details may may matter, least need discuss issue. covariates? Discussing covariates context Preceptor Table different discussing covariates context data. Recall Preceptor Table smallest possible table, don’t need include every relevant variable. need discuss variables necessary answer question. treatments, ? (“treatments” predictive models. covariates.) treatment covariate , least theory, can manipulate manipulation necessary answer question. , create Preceptor Table. case, Preceptor Table includes N rows, one every adult Chicago July 1, 2020. includes two columns: outcome (liberal) single covariate (income). Preceptor Table, missing data, trivial calculate percentage adults (make $100,000) liberal. Preceptor Table , really, smallest possible table solved problem. table single cell containing quantity interest! , obviously, stupid. Preceptor Table smallest possible table, rows corresponding units information, allows us answer question.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"eda","dir":"Articles","previous_headings":"","what":"EDA","title":"Cardinal Virtues","text":"can never look data much. – Mark Engerman always short section devoted exploratory data analysis. EDA include least one textual look data, usually using summary(), skim(), glimpse(), print() slice_sample() also available. also include least one graphic, almost always outcome variable y-axis one covariates x-axis. data set often include columns rows irrelevant question. columns rows removed, creating tibble used Courage section. name tibble often something convenient like ch_7. also makes sense include discussion data comes . definitions variables? chose sample? documentation? sort background sets stage examining validity.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"validity","dir":"Articles","previous_headings":"","what":"Validity","title":"Cardinal Virtues","text":"Validity consistency, lack thereof, columns data set corresponding columns Preceptor Table. order consider two data sets drawn population, columns one must valid correspondence columns . Validity, true (least reasonable), allows us construct Population Table, first step Justice. Validity discussions always one (short) paragraph relevant variable (outcome relevant covariates), examples validity might hold. Validity discussion finishes brief discussion along lines : “Despite concerns, assume validity hold.” section can longer course, depending many details discussed EDA. central point two (potentially!) completely different things: Preceptor Table data. Just two columns name mean thing. Indeed, often quite different! control Preceptor Table , lesser extent, original question, can adjust variables “closer” data actually . another example iterative nature data science. data close enough question, check boss/colleague/customer see can modify question order make match data Preceptor Table close enough validity hold. conclude Wisdom section summarizing hope use data answer question started . Example: Using data 2012 survey Boston-area commuters, seek understand relationship income political ideology Chicago similar cities 2020. particular, percentage individuals make $100,000 per year liberal? Note specific question morphed general examination “relationship” income political ideology. order answer specific question, always examine general relationship. always build model. can use model answer question started well related questions. thinking hard original question data, come question may possible answer data . Note Cardinal Virtue section finishes sentence two summarizing learned. sentences combined end analysis. One key products data science project paragraph summarizes key conclusions.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"justice","dir":"Articles","previous_headings":"","what":"Justice","title":"Cardinal Virtues","text":"Justice concerns four topics: Population Table, stability, representativeness, unconfoundedness. Justice second Cardinal Virtue data science. Justice starts Population Table – data want , data actually , data population. row Population Table defined unique unit/time combination. explore three key issues. First, relationship among variables demonstrate stability, meaning model stable across different time periods? Second, rows associated data , separately, rows associated Preceptor Table, representative units population? Third, causal models , consider unconfoundedness. Population Table includes row unit/time combination underlying population Preceptor Table data drawn. Population Table can constructed validity assumption (mostly) true. includes rows Preceptor Table. also includes rows data set. usually rows well, rows represent unit/time combinations parts population. validity holds, can create Population Table. “Source” column highlights Population Table includes three categories rows: data, Preceptor Table, rest population, data Preceptor Table drawn. ... indicates rows population included either data Preceptor Table. “ID” column implicit, often included. , obvious row refers specific unit. don’t really care individual units, need label . always column, case “Year,” indicates moment time covariates recorded. given unit may appear multiple rows, row providing data different time. example, row Sarah 2012, 43, row Sarah 2020, 51, . Note Sarah might just member population, neither data Preceptor Table. might one . rarely concerned specific individual. row Population Table represents unique Unit/Time combination. “Outcome” column variable trying understand/explain/predict. always outcome column, although often just labelled variable name, “Income.” “Covariates” columns already discussed. Stability means relationship columns Population Table three categories rows: data, Preceptor Table, larger population drawn. assumption stability holds, relationships columns Population Table across time. First, relationship among columns moment time data relationship among columns entire table. Second, relationship among columns moment time Preceptor Table relationship among columns entire table. Stability, true, allows us go data population, population Preceptor Table. discuss least one example stability might hold case. examples almost always connected passage time. Whatever relationship political ideology income might held 2012, gathered data, might true either afterwards. Provide specific speculations might changed world. Regardless concerns, always conclude , although assumption stability might hold perfectly, world probably stable enough time period make inference possible. longer time period covered Preceptor Table (data), suspect assumption stability becomes. Representativeness, lack thereof, concerns two relationships among rows Population Table. first data rows. second rows Preceptor Table. Ideally, like Preceptor Table data random samples population. , assumption representativeness met. Sadly, almost never case. Stability looks across time periods. Representativeness looks within time periods. mention specific examples two potential problems. First, data representative population? Rarely! Second, rows associated Preceptor Table representative population? , almost never! Provide specific examples lack representativeness might problem, one large enough affect ability answer question. , continue analysis, always assume/pretend rows data Preceptor Table representative enough relevant time period within larger population drawn. Unconfoundedness means treatment assignment independent potential outcomes, condition pre-treatment covariates. model confounded true. assumption relevant causal models. describe model “confounded” true. easiest way ensure unconfoundedness assign treatment randomly. model predictive, unconfoundedness concern. Just mention fact sentence end section representativeness. , model causal, need section devoted topic. treatment assignment random, unconfoundedness guaranteed, although experienced researchers often worry exact process involved “random” assignment. , however, treatment assignment random, always concern correlated potential outcomes. Discuss least two scenarios might concern. , usual, conclude , although might issues confoundedness, probably small enough worry . Just Wisdom points us toward Population Table NN rows mean need keep NN rows, especially creating model covers rows hard/impossible. can just simplify claims making world removing rows. Getting rid rows usually necessitate adjustment question trying answer. , data science iterative process. Justice section concludes sentence two , despite problems core assumptions stability, representativeness unconfoundedness, can still proceed next steps assumptions hold enough. last step revisit key sentences Wisdom section. Recall: Using data 2012 survey Boston-area commuters, seek understand relationship income political ideology Chicago similar cities 2020. particular, percentage individuals make $100,000 per year liberal? sentences still correct, serious consideration assumptions stability, representativeness unconfoundedness require us modify ? answer, course, assumptions never perfect! , obligation add sentence two highlights () one two concerns. Examples: concern survey participants may perfectly representative underlying population. relationship income ideology may changed eight year period. need use technical terms like “stability.” However, readers understand “representative” means. key point honesty. obligation least mention possible concerns. new paragraph: Using data 2012 survey Boston-area commuters, seek understand relationship income political ideology Chicago similar cities 2020. particular, percentage individuals make $100,000 per year liberal? relationship income ideology may changed eight year period.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"population-table","dir":"Articles","previous_headings":"","what":"Population Table","title":"Cardinal Virtues","text":"Population Table includes row unit/time combination underlying population Preceptor Table data drawn. Population Table can constructed validity assumption (mostly) true. includes rows Preceptor Table. also includes rows data set. usually rows well, rows represent unit/time combinations parts population. validity holds, can create Population Table. “Source” column highlights Population Table includes three categories rows: data, Preceptor Table, rest population, data Preceptor Table drawn. ... indicates rows population included either data Preceptor Table. “ID” column implicit, often included. , obvious row refers specific unit. don’t really care individual units, need label . always column, case “Year,” indicates moment time covariates recorded. given unit may appear multiple rows, row providing data different time. example, row Sarah 2012, 43, row Sarah 2020, 51, . Note Sarah might just member population, neither data Preceptor Table. might one . rarely concerned specific individual. row Population Table represents unique Unit/Time combination. “Outcome” column variable trying understand/explain/predict. always outcome column, although often just labelled variable name, “Income.” “Covariates” columns already discussed.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"stability","dir":"Articles","previous_headings":"","what":"Stability","title":"Cardinal Virtues","text":"Stability means relationship columns Population Table three categories rows: data, Preceptor Table, larger population drawn. assumption stability holds, relationships columns Population Table across time. First, relationship among columns moment time data relationship among columns entire table. Second, relationship among columns moment time Preceptor Table relationship among columns entire table. Stability, true, allows us go data population, population Preceptor Table. discuss least one example stability might hold case. examples almost always connected passage time. Whatever relationship political ideology income might held 2012, gathered data, might true either afterwards. Provide specific speculations might changed world. Regardless concerns, always conclude , although assumption stability might hold perfectly, world probably stable enough time period make inference possible. longer time period covered Preceptor Table (data), suspect assumption stability becomes.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"representativeness","dir":"Articles","previous_headings":"","what":"Representativeness","title":"Cardinal Virtues","text":"Representativeness, lack thereof, concerns two relationships among rows Population Table. first data rows. second rows Preceptor Table. Ideally, like Preceptor Table data random samples population. , assumption representativeness met. Sadly, almost never case. Stability looks across time periods. Representativeness looks within time periods. mention specific examples two potential problems. First, data representative population? Rarely! Second, rows associated Preceptor Table representative population? , almost never! Provide specific examples lack representativeness might problem, one large enough affect ability answer question. , continue analysis, always assume/pretend rows data Preceptor Table representative enough relevant time period within larger population drawn.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"unconfoundedness","dir":"Articles","previous_headings":"","what":"Unconfoundedness","title":"Cardinal Virtues","text":"Unconfoundedness means treatment assignment independent potential outcomes, condition pre-treatment covariates. model confounded true. assumption relevant causal models. describe model “confounded” true. easiest way ensure unconfoundedness assign treatment randomly. model predictive, unconfoundedness concern. Just mention fact sentence end section representativeness. , model causal, need section devoted topic. treatment assignment random, unconfoundedness guaranteed, although experienced researchers often worry exact process involved “random” assignment. , however, treatment assignment random, always concern correlated potential outcomes. Discuss least two scenarios might concern. , usual, conclude , although might issues confoundedness, probably small enough worry . Just Wisdom points us toward Population Table NN rows mean need keep NN rows, especially creating model covers rows hard/impossible. can just simplify claims making world removing rows. Getting rid rows usually necessitate adjustment question trying answer. , data science iterative process. Justice section concludes sentence two , despite problems core assumptions stability, representativeness unconfoundedness, can still proceed next steps assumptions hold enough. last step revisit key sentences Wisdom section. Recall: Using data 2012 survey Boston-area commuters, seek understand relationship income political ideology Chicago similar cities 2020. particular, percentage individuals make $100,000 per year liberal? sentences still correct, serious consideration assumptions stability, representativeness unconfoundedness require us modify ? answer, course, assumptions never perfect! , obligation add sentence two highlights () one two concerns. Examples: concern survey participants may perfectly representative underlying population. relationship income ideology may changed eight year period. need use technical terms like “stability.” However, readers understand “representative” means. key point honesty. obligation least mention possible concerns. new paragraph: Using data 2012 survey Boston-area commuters, seek understand relationship income political ideology Chicago similar cities 2020. particular, percentage individuals make $100,000 per year liberal? relationship income ideology may changed eight year period.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"courage","dir":"Articles","previous_headings":"","what":"Courage","title":"Cardinal Virtues","text":"Courage starts math, explores models, creates Data Generating Mechanism. Courage third Cardinal Virtue data science. Justice gives us Population Table. Courage creates data generating mechanism. first specify mathematical formula connects outcome variable interested data . explore different models. need decide variables include estimate values unknown parameters. check models consistency data . avoid hypothesis tests. select one model, data generating mechanism. Courage begins discussion functional form using. usually straight-forward follows directly type outcome variable: continuous means linear model, two categories (binary) implies logistic, --two categories suggests multinomial logistic. provide mathematical formula model, using y x variables. don’t yet know number right-hand side variables include, much less ones. , formula generic. rest discussion broken three sections: “Models,” “Tests,” “Data Generating Mechanism.” exploring different models, need decide variables include estimate values unknown parameters. estimate models print model results. give another version math, use tbl_regression() yet. goal explore interpret different models. parameter’s estimated value 2 3 standard errors away zero, generally keep parameter (associated variable) model. , probably, variable “matters.” main exception rule parameter whose value close zero changes associated variable, within general range variable, can’t change value outcome much. Depending chapter, use different tools choose among different possible models. Interpreting meaning parameter estimates takes practice. Consider simple linear model. Let’s go example Q&, followed commentary: Q: Write sentence interpreting -0.83 estimate sexMale. : comparing men women, men 0.83 lower value att_end, meaning liberal immigration, relative women, conditional variables model. Whenever consider non-treatment variables, must never use terms like “cause,” “impact” . can’t make statement implies existence one potential outcome based changes non-treatment variables. can’t make claims within row effects. Instead, can compare across rows. Always use phrase “comparing X Y” something similar. phrase “conditional variables model” important. shortened “conditional model.” phrase acknowledges many, many possible models, just considering different combinations independent variables might include. one produce different coefficient sexmale. None true coefficient. claim make -0.83, specific number, always conditional fact assume model true, covariates, others, belong regression. mean always use phrase? . leave time. always understood knowledgeable readers. Q: Write sentence interpreting confidence interval sexMale. : know true value coefficient sexMale, can 95% confident lies somewhere -1.86 0.21. Bayesians, believe true value confidence credible uncertainty interval includes stated level. time parameters model direct relationship population parameter might interested. especially true complex /non-linear models. , cases, coefficient like β1\\beta_1 “mean” anything. , simple, small, linear models, sometimes happens parameter correspond something real. case, coefficient sexmale difference population average att_end men women, adjusting variables model. Q: Interpret 1.41 estimate treatmentTreated. : causal model, average causal effect receiving treatment hearing Spanish-speakers train platform, relative control, 1.41 higher value att_end, meaning treatment, relative control, makes one conservative immigration. : predictive model, , compare people receive treatment people receive control, treated people , average, 1.41 conservative attitude toward immigration, adjusting individual characteristics. interpretation treatment variable different interpretation standard covariate. key point thing causal (versus preditive) data set causal (versus predictive) R code formula. can use data set (R code!) causal predictive models. difference lies assumptions make. Q: Interpret 0.36 2.46 interval treatmentTreated coefficient. : best estimate average causal effect 1.41, meaning treated makes someone 1.41 units conservative immigration. Yet, true value lower higher. 95% certain true effect somewhere 0.36 2.46. Q: Interpret -0.01 estimate age. : compare one group people ten years older another, older group , average, attitude toward immigration 0.1 unit lower, .e., less conservative. Numeric variables harder binary variables longer just two well-defined groups compare . must create two groups . Fortunately, long interaction terms, can just pick two groups values variable. common two groups differ one unit variable. quite common use groups differ /less seems sensible /makes math easier. case, two groups differ 10 years makes sense reasons. non-linear models, linear models lots interaction terms? linear model, interpretations fairly straightforward. type model, math difficult head. can’t just look coefficient 5 know means magnitude. can tell direction, positive 5 means higher values covariate associated higher values outcome variable. , anything linear models, restrict direction significance interpretations. Q: Write sentence interpreting 0.37 estimate sexmale. : comparison women, men likely arrested. Categorical variables (NN categories), like sex (two values), always replaced (N−1N-1) 0/1 dummy variables like sexMale. can’t (easily) know big 0.37 . model non-linear, can’t (easily) determine whether men 1% 50% likely arrested. Q: Write sentence interpreting 1.07 1.31 confidence interval raceblack. : comparison Asian/Pacific Islanders, Blacks likely arrested. fact, likely arrested racial group. Dummy variables must always interpreted context base value variable, generally included intercept. example, base value “asian/pacific islander.” (base value first alphabetically default character variables. However, factor variable, can change setting order levels hand.) look two things confidence interval. First, exclude zero? , can’t sure relationship positive negative. Second, overlap confidence intervals dummy columns derived variable? , can sure ordering comparisons bigger. overlap, example raceother raceunknown, can’t sure average comparison go. estimate raceother larger estimate raceunknown, best guess members former group likely arrested. , confidence intervals overlap, good chance (5% certainly) ordering opposite. recommend verb “adjust” place “control” discussing effect including variables model. Example: “causal effect exposure Spanish-speakers 1.5, adjusting variables like age party.” word “adjusting” better word “controlling” demonstrates humility. advanced models, less relevant sorts interpretations. , don’t really care parameters, much less interpret . Parameters imaginary, like unicorns. care answers questions. Parameters tools answering questions. aren’t interesting --. modern world, parameters nuisance parameters. check models consistency data using posterior predictive testing. avoid hypothesis tests. Data Generating Mechanism (DGM) also called data generating model data generating process. true DGM reality world, physical process actually generates data observe. estimated DGM mathematical formula create models true DGM, can never know. Temperance, use estimated DGM draw inferences Quantities Interest. create final model, data generating mechanism. provide math model, using variable names instead y x start chapter. present final parameter estimates nicely, using gtsummary package. model made end Courage almost always complex answer simple question started , question rarely specifies values covariates included model. covariates treatments part initial question(s) must included model, otherwise can’t answer questions . DGM section ends clear statement English, paragraph, describing model. , two sentences student say presentation describing model. first sentence specifies model, including making clear units, outcome key covariates. (need use terms “units,” “outcomes,” .) second sentence tells us something model, generally relationship one covariates outcome variable. general, discussion specific numbers uncertainty. First, cares? Parameter estimates boring irrelevant. Second, Temperance section answer original question. Example: modeled liberal, binary TRUE/FALSE variable, logistic function income. Individuals higher income likely liberal. Update concluding paragraph addition: Using data 2012 survey Boston-area commuters, seek understand relationship income political ideology Chicago similar cities 2020. particular, percentage individuals make $100,000 per year liberal? relationship income ideology may changed eight year period. modeled liberal, binary TRUE/FALSE variable, logistic function income. Individuals higher income likely liberal. Feel free use “” instead “” project solo.","code":"linear_reg(engine = \"lm\") |>   fit(att_end ~ sex + treatment + age, data = trains) |>   tidy(conf.int = TRUE, digits = 2) |>   select(term, estimate, conf.low, conf.high) # A tibble: 4 × 4   term             estimate conf.low conf.high   <chr>               <dbl>    <dbl>     <dbl> 1 (Intercept)        9.58     7.51     11.6 2 sexMale           -0.829   -1.86      0.207 3 treatmentTreated   1.41     0.364     2.46 4 age               -0.0143  -0.0572    0.0286 logistic_reg(engine = \"glm\") |>   fit(as.factor(arrested) ~ sex + race, data = stops) |>   tidy(conf.int = TRUE) |>   select(term, estimate, conf.low, conf.high) # A tibble: 7 × 4   term         estimate conf.low conf.high   <chr>           <dbl>    <dbl>     <dbl> 1 (Intercept)   -2.56    -2.69     -2.44 2 sexmale        0.368    0.352     0.385 3 raceblack      1.19     1.07      1.31 4 racehispanic   0.805    0.674     0.939 5 raceother      0.337   -0.0537    0.700 6 raceunknown   -0.0824  -0.262     0.0965 7 racewhite      0.928    0.806     1.05"},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"models","dir":"Articles","previous_headings":"","what":"Models","title":"Cardinal Virtues","text":"exploring different models, need decide variables include estimate values unknown parameters. estimate models print model results. give another version math, use tbl_regression() yet. goal explore interpret different models. parameter’s estimated value 2 3 standard errors away zero, generally keep parameter (associated variable) model. , probably, variable “matters.” main exception rule parameter whose value close zero changes associated variable, within general range variable, can’t change value outcome much. Depending chapter, use different tools choose among different possible models. Interpreting meaning parameter estimates takes practice. Consider simple linear model. Let’s go example Q&, followed commentary: Q: Write sentence interpreting -0.83 estimate sexMale. : comparing men women, men 0.83 lower value att_end, meaning liberal immigration, relative women, conditional variables model. Whenever consider non-treatment variables, must never use terms like “cause,” “impact” . can’t make statement implies existence one potential outcome based changes non-treatment variables. can’t make claims within row effects. Instead, can compare across rows. Always use phrase “comparing X Y” something similar. phrase “conditional variables model” important. shortened “conditional model.” phrase acknowledges many, many possible models, just considering different combinations independent variables might include. one produce different coefficient sexmale. None true coefficient. claim make -0.83, specific number, always conditional fact assume model true, covariates, others, belong regression. mean always use phrase? . leave time. always understood knowledgeable readers. Q: Write sentence interpreting confidence interval sexMale. : know true value coefficient sexMale, can 95% confident lies somewhere -1.86 0.21. Bayesians, believe true value confidence credible uncertainty interval includes stated level. time parameters model direct relationship population parameter might interested. especially true complex /non-linear models. , cases, coefficient like β1\\beta_1 “mean” anything. , simple, small, linear models, sometimes happens parameter correspond something real. case, coefficient sexmale difference population average att_end men women, adjusting variables model. Q: Interpret 1.41 estimate treatmentTreated. : causal model, average causal effect receiving treatment hearing Spanish-speakers train platform, relative control, 1.41 higher value att_end, meaning treatment, relative control, makes one conservative immigration. : predictive model, , compare people receive treatment people receive control, treated people , average, 1.41 conservative attitude toward immigration, adjusting individual characteristics. interpretation treatment variable different interpretation standard covariate. key point thing causal (versus preditive) data set causal (versus predictive) R code formula. can use data set (R code!) causal predictive models. difference lies assumptions make. Q: Interpret 0.36 2.46 interval treatmentTreated coefficient. : best estimate average causal effect 1.41, meaning treated makes someone 1.41 units conservative immigration. Yet, true value lower higher. 95% certain true effect somewhere 0.36 2.46. Q: Interpret -0.01 estimate age. : compare one group people ten years older another, older group , average, attitude toward immigration 0.1 unit lower, .e., less conservative. Numeric variables harder binary variables longer just two well-defined groups compare . must create two groups . Fortunately, long interaction terms, can just pick two groups values variable. common two groups differ one unit variable. quite common use groups differ /less seems sensible /makes math easier. case, two groups differ 10 years makes sense reasons. non-linear models, linear models lots interaction terms? linear model, interpretations fairly straightforward. type model, math difficult head. can’t just look coefficient 5 know means magnitude. can tell direction, positive 5 means higher values covariate associated higher values outcome variable. , anything linear models, restrict direction significance interpretations. Q: Write sentence interpreting 0.37 estimate sexmale. : comparison women, men likely arrested. Categorical variables (NN categories), like sex (two values), always replaced (N−1N-1) 0/1 dummy variables like sexMale. can’t (easily) know big 0.37 . model non-linear, can’t (easily) determine whether men 1% 50% likely arrested. Q: Write sentence interpreting 1.07 1.31 confidence interval raceblack. : comparison Asian/Pacific Islanders, Blacks likely arrested. fact, likely arrested racial group. Dummy variables must always interpreted context base value variable, generally included intercept. example, base value “asian/pacific islander.” (base value first alphabetically default character variables. However, factor variable, can change setting order levels hand.) look two things confidence interval. First, exclude zero? , can’t sure relationship positive negative. Second, overlap confidence intervals dummy columns derived variable? , can sure ordering comparisons bigger. overlap, example raceother raceunknown, can’t sure average comparison go. estimate raceother larger estimate raceunknown, best guess members former group likely arrested. , confidence intervals overlap, good chance (5% certainly) ordering opposite. recommend verb “adjust” place “control” discussing effect including variables model. Example: “causal effect exposure Spanish-speakers 1.5, adjusting variables like age party.” word “adjusting” better word “controlling” demonstrates humility. advanced models, less relevant sorts interpretations. , don’t really care parameters, much less interpret . Parameters imaginary, like unicorns. care answers questions. Parameters tools answering questions. aren’t interesting --. modern world, parameters nuisance parameters.","code":"linear_reg(engine = \"lm\") |>   fit(att_end ~ sex + treatment + age, data = trains) |>   tidy(conf.int = TRUE, digits = 2) |>   select(term, estimate, conf.low, conf.high) # A tibble: 4 × 4   term             estimate conf.low conf.high   <chr>               <dbl>    <dbl>     <dbl> 1 (Intercept)        9.58     7.51     11.6 2 sexMale           -0.829   -1.86      0.207 3 treatmentTreated   1.41     0.364     2.46 4 age               -0.0143  -0.0572    0.0286 logistic_reg(engine = \"glm\") |>   fit(as.factor(arrested) ~ sex + race, data = stops) |>   tidy(conf.int = TRUE) |>   select(term, estimate, conf.low, conf.high) # A tibble: 7 × 4   term         estimate conf.low conf.high   <chr>           <dbl>    <dbl>     <dbl> 1 (Intercept)   -2.56    -2.69     -2.44 2 sexmale        0.368    0.352     0.385 3 raceblack      1.19     1.07      1.31 4 racehispanic   0.805    0.674     0.939 5 raceother      0.337   -0.0537    0.700 6 raceunknown   -0.0824  -0.262     0.0965 7 racewhite      0.928    0.806     1.05"},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"interpreting-parameters","dir":"Articles","previous_headings":"","what":"Interpreting Parameters","title":"Cardinal Virtues","text":"Interpreting meaning parameter estimates takes practice. Consider simple linear model. Let’s go example Q&, followed commentary: Q: Write sentence interpreting -0.83 estimate sexMale. : comparing men women, men 0.83 lower value att_end, meaning liberal immigration, relative women, conditional variables model. Whenever consider non-treatment variables, must never use terms like “cause,” “impact” . can’t make statement implies existence one potential outcome based changes non-treatment variables. can’t make claims within row effects. Instead, can compare across rows. Always use phrase “comparing X Y” something similar. phrase “conditional variables model” important. shortened “conditional model.” phrase acknowledges many, many possible models, just considering different combinations independent variables might include. one produce different coefficient sexmale. None true coefficient. claim make -0.83, specific number, always conditional fact assume model true, covariates, others, belong regression. mean always use phrase? . leave time. always understood knowledgeable readers. Q: Write sentence interpreting confidence interval sexMale. : know true value coefficient sexMale, can 95% confident lies somewhere -1.86 0.21. Bayesians, believe true value confidence credible uncertainty interval includes stated level. time parameters model direct relationship population parameter might interested. especially true complex /non-linear models. , cases, coefficient like β1\\beta_1 “mean” anything. , simple, small, linear models, sometimes happens parameter correspond something real. case, coefficient sexmale difference population average att_end men women, adjusting variables model. Q: Interpret 1.41 estimate treatmentTreated. : causal model, average causal effect receiving treatment hearing Spanish-speakers train platform, relative control, 1.41 higher value att_end, meaning treatment, relative control, makes one conservative immigration. : predictive model, , compare people receive treatment people receive control, treated people , average, 1.41 conservative attitude toward immigration, adjusting individual characteristics. interpretation treatment variable different interpretation standard covariate. key point thing causal (versus preditive) data set causal (versus predictive) R code formula. can use data set (R code!) causal predictive models. difference lies assumptions make. Q: Interpret 0.36 2.46 interval treatmentTreated coefficient. : best estimate average causal effect 1.41, meaning treated makes someone 1.41 units conservative immigration. Yet, true value lower higher. 95% certain true effect somewhere 0.36 2.46. Q: Interpret -0.01 estimate age. : compare one group people ten years older another, older group , average, attitude toward immigration 0.1 unit lower, .e., less conservative. Numeric variables harder binary variables longer just two well-defined groups compare . must create two groups . Fortunately, long interaction terms, can just pick two groups values variable. common two groups differ one unit variable. quite common use groups differ /less seems sensible /makes math easier. case, two groups differ 10 years makes sense reasons. non-linear models, linear models lots interaction terms? linear model, interpretations fairly straightforward. type model, math difficult head. can’t just look coefficient 5 know means magnitude. can tell direction, positive 5 means higher values covariate associated higher values outcome variable. , anything linear models, restrict direction significance interpretations. Q: Write sentence interpreting 0.37 estimate sexmale. : comparison women, men likely arrested. Categorical variables (NN categories), like sex (two values), always replaced (N−1N-1) 0/1 dummy variables like sexMale. can’t (easily) know big 0.37 . model non-linear, can’t (easily) determine whether men 1% 50% likely arrested. Q: Write sentence interpreting 1.07 1.31 confidence interval raceblack. : comparison Asian/Pacific Islanders, Blacks likely arrested. fact, likely arrested racial group. Dummy variables must always interpreted context base value variable, generally included intercept. example, base value “asian/pacific islander.” (base value first alphabetically default character variables. However, factor variable, can change setting order levels hand.) look two things confidence interval. First, exclude zero? , can’t sure relationship positive negative. Second, overlap confidence intervals dummy columns derived variable? , can sure ordering comparisons bigger. overlap, example raceother raceunknown, can’t sure average comparison go. estimate raceother larger estimate raceunknown, best guess members former group likely arrested. , confidence intervals overlap, good chance (5% certainly) ordering opposite. recommend verb “adjust” place “control” discussing effect including variables model. Example: “causal effect exposure Spanish-speakers 1.5, adjusting variables like age party.” word “adjusting” better word “controlling” demonstrates humility. advanced models, less relevant sorts interpretations. , don’t really care parameters, much less interpret . Parameters imaginary, like unicorns. care answers questions. Parameters tools answering questions. aren’t interesting --. modern world, parameters nuisance parameters.","code":"linear_reg(engine = \"lm\") |>   fit(att_end ~ sex + treatment + age, data = trains) |>   tidy(conf.int = TRUE, digits = 2) |>   select(term, estimate, conf.low, conf.high) # A tibble: 4 × 4   term             estimate conf.low conf.high   <chr>               <dbl>    <dbl>     <dbl> 1 (Intercept)        9.58     7.51     11.6 2 sexMale           -0.829   -1.86      0.207 3 treatmentTreated   1.41     0.364     2.46 4 age               -0.0143  -0.0572    0.0286 logistic_reg(engine = \"glm\") |>   fit(as.factor(arrested) ~ sex + race, data = stops) |>   tidy(conf.int = TRUE) |>   select(term, estimate, conf.low, conf.high) # A tibble: 7 × 4   term         estimate conf.low conf.high   <chr>           <dbl>    <dbl>     <dbl> 1 (Intercept)   -2.56    -2.69     -2.44 2 sexmale        0.368    0.352     0.385 3 raceblack      1.19     1.07      1.31 4 racehispanic   0.805    0.674     0.939 5 raceother      0.337   -0.0537    0.700 6 raceunknown   -0.0824  -0.262     0.0965 7 racewhite      0.928    0.806     1.05"},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"tests","dir":"Articles","previous_headings":"","what":"Tests","title":"Cardinal Virtues","text":"check models consistency data using posterior predictive testing. avoid hypothesis tests.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"data-generating-mechanism","dir":"Articles","previous_headings":"","what":"Data Generating Mechanism","title":"Cardinal Virtues","text":"Data Generating Mechanism (DGM) also called data generating model data generating process. true DGM reality world, physical process actually generates data observe. estimated DGM mathematical formula create models true DGM, can never know. Temperance, use estimated DGM draw inferences Quantities Interest. create final model, data generating mechanism. provide math model, using variable names instead y x start chapter. present final parameter estimates nicely, using gtsummary package. model made end Courage almost always complex answer simple question started , question rarely specifies values covariates included model. covariates treatments part initial question(s) must included model, otherwise can’t answer questions . DGM section ends clear statement English, paragraph, describing model. , two sentences student say presentation describing model. first sentence specifies model, including making clear units, outcome key covariates. (need use terms “units,” “outcomes,” .) second sentence tells us something model, generally relationship one covariates outcome variable. general, discussion specific numbers uncertainty. First, cares? Parameter estimates boring irrelevant. Second, Temperance section answer original question. Example: modeled liberal, binary TRUE/FALSE variable, logistic function income. Individuals higher income likely liberal. Update concluding paragraph addition: Using data 2012 survey Boston-area commuters, seek understand relationship income political ideology Chicago similar cities 2020. particular, percentage individuals make $100,000 per year liberal? relationship income ideology may changed eight year period. modeled liberal, binary TRUE/FALSE variable, logistic function income. Individuals higher income likely liberal. Feel free use “” instead “” project solo.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"temperance","dir":"Articles","previous_headings":"","what":"Temperance","title":"Cardinal Virtues","text":"Temperance uses Data Generating Mechanism answer questions began. Humility reminds us answer always lie. can also use DGM calculate many similar quantities interest, displaying results graphically. Temperance fourth Cardinal Virtue data science. Courage gave us data generating mechanism. Temperance guides us use DGM — “model” — created answer questions began. create posteriors quantities interest. modest claims make. posteriors create never “truth.” assumptions made create model never perfect. Yet decisions made flawed posteriors almost always better decisions made without . two sub-sections Temperance : Questions Answers, Humility. important monitor language. believe changes election_age “cause” changes lived_after. obvious. words phrases — like “associated ” “change ” — close causal. wary use. Always think terms comparisons using predictive model. can’t change election_age individual candidate. can compare two candidates (two groups candidates). go back question(s) started journey. discuss question evolved, back--forth process try ensure data question ask close enough make process plausible. revisit Preceptor Table, least conceptually. emphasize DGM allows us fill missing outcomes Preceptor Table, thereby allowing us answer questions. Key issue connection DGM (either true estimated) Preceptor Table. connection tricky! even sure understand . DGM can used “fill ” missing elements Preceptor Table, always associated uncertainty. Even true DGM, don’t know att_end Joe treatment, just posterior variable, way make draws. Idea: Use DGM create one complete Preceptor Table. draw, Joe 6 att_end. , another draw. Joe 5. thousand draws. thousand Preceptor Tables. Calculate Quantity Interest Preceptor Table. 1,000 values posterior QoI. great make cool animation , perhaps simple example. fun similar animation chapter. Great summer project! use data generating mechanism Courage answer question. , obviously, core Temperance section. walk student several plots created marginaleffects package. plots generally increasing complexity. always tell student plot create giving exact code. possible, knowledge drop tries connect plot table regression results interpreted . Example: Example 1  plot shows expected value attitudes toward immigration, conditional model, women men. Women higher (conservative) attitudes toward immigration, adjusting age treatment. consistent negative estimated coefficient sexMale -0.83. Example 2  plot shows expected value attitudes toward immigration, conditional model, exposed treatment (Spanish-speakers train platform) control. Treated individuals higher (conservative) attitudes toward immigration, adjusting age sex consistent positive estimated coefficient treatmentTreated 1.41. Example 3  plot shows expected value attitudes toward immigration, conditional model, individuals different ages. Younger people higher (conservative) attitudes toward immigration, adjusting treatment sex consistent negative estimated coefficient age -0.01. Example 4  plot shows expected value attitudes toward immigration, conditional model, individuals different treatment assignments, ages sexes. often just interested comparisons predictions. tempting think can deduce comparisons just subtracting one prediction another. mostly works center distribution definitely work confidence interval. Fortunately, marginaleffects provides plot_comparison() function purpose. Example 5  plot shows expected value difference attitudes toward immigration Treated Control, conditional model. Treated higher (conservative) attitudes toward immigration, adjusting age sex. consistent negative estimated coefficient treatmentTreated 1.41. relationship plot_predictions() plot_comparisons() subtle, central point , want look difference ratio function one expected value, must use plot_comparisons(). comments plot_comparisons(): values condition argument determine structure plot. first value x-axis, second color third separates plots different panes. value variables argument specifies variable around comparisons organized. model rich enough — meaning enough terms/interactions/non-linearities — won’t enough complexity complex call plot_comparisons(). section always concludes one sentence summary final conclusion. summary include technical terms. meant non-statisticians. something might say explaining take-away conclusion non-statistician. always feature least one number, uncertainty associated number. Example: 55% (±\\pm 2%) people make $100,000 per year liberal. people making $100,000 per year, 55% liberal, although true number low 53% high 57%. cases, like , feature numbers natural interpretation. know percentages . many outcomes measured units difficult interpret. example: causal effect smaller class size math exam scores 10 points. reader know 10 points big small effect doesn’t know anything range scores students get exam. common approach problem “standardize” causal effect dividing standard deviation outcome. example, standard deviation math exam scores 50, re-write : standardized causal effect smaller class size math exam scores 0.2. Depending field, variety terms describing raw causal effect divided standard deviation, including “sigmas” — derived use Greek letter σ\\sigma symbol standard deviation. , might also write: causal effect smaller class size math exam scores 0.2 sigmas. raw effect size 10 20% standard deviation (50). 50, speak instead one “one sigma” one standard deviation. Another common term divide---standard deviation standardization “effect size.” : effect size smaller class size math exam scores 0.2. another approach tackling problem scale natural interpretation. Consider: causal effect hearing Spanish-speakers conservative attitude toward immigration, change 1.5 (±\\pm 0.5) 15 point scale. correct, far goes, idea 1.5 “big” “small” change. need perspective. causal effect hearing Spanish-speakers conservative attitude toward immigration, change 1.5 (±\\pm 0.5) 15 point scale. perspective, difference Democrats Republicans scale 2.1. Terminology important. best words depend audience. example involves describe uncertainty, interval around best estimate quantity interest. terminology — 1.5 (±\\pm 0.5) — works well general audience. may want precise meaning interval. Consider options: 95% interval 0.5 1.5. use word “interval,” without associated adjective, way avoid entire debate. meaning almost certainly Bayesian one: 95% percentile range posterior true causal effect goes 0.5 1.5. 95% confidence interval 0.5 1.5. adjective “confidence” used two different sorts people. First Frequentists, whose philosophy traditional approach statistics still control institutions like College Board. Frequentist meaning , followed approach 100 similar problems , 95% time, confidence interval include true value. don’t understand , don’t worry. never work Frequentist. second sort person uses adjective “confidence” someone actually Bayesian, like us, doesn’t care annoying Frequentists. 95% credible interval 0.5 1.5. adjective “credible” Bayesian analogue “confidence.” Bayesians don’t want annoy Frequentists often replace “confidence” “uncertainty” polite. , Bayesians, meaning always : 95% chance true value 0.5 1.5. main takeaway vast majority people care use “confidence interval” “credible interval” “uncertainty interval.” interpret phrases Bayesian way: X% chance — X often 95 can take values — true value lies within interval. Depending context, might one Quantity Interest discuss. must least one. now ready provide entire concluding paragraph. Using data 2012 survey Boston-area commuters, seek understand relationship income political ideology Chicago similar cities 2020. relationship income ideology may changed eight year period. modeled status liberal political orientation, binary TRUE/FALSE variable, logistic function income. Individuals higher income likely liberal. people making $100,000 per year, 55% liberal, although true number low 53% high 57%. Note deleted rhetorical question — “particular, percentage individuals make $100,000 per year liberal?” — start paragraph. longer necessary. final result data science project paragraph like one. Data science begins question data. ends paragraph , ideally, graphics. course, real data science projects never involve single question. Instead, starting question leads create DGM can answer also can answer lots lots questions. cool. fact, often possible create graphic answers lots questions . ideal. (Michigan postcard example great.) really good data science project always ends cool graphic answers lots questions paragraph like one picks one answer highlight. Questions Answers section ends final paragraph. Temperance guides us use DGM answer questions began. Humility section always begins single sentence, something along lines : can never know truth. time, hope collect serious quotations along theme. answered question, now (quickly) review reasons answer might wrong. Review specific concerns validity, stability, representativeness, (causal model) unconfoundedness. concerns remain. Review three levels “truth”: Knowing entries Preceptor Table, knowing true DGM, using estimated DGM. (explanation can become sophisticated chapters progress.) can never know entries Preceptor Table. knowledge reserved God. assumptions correct, DGM true, accurately describes way world works. better way predict future, model past, use . Sadly, case toy examples involving things like coins dice. hope DGM close true DGM , since assumption never perfectly correct, DGM always different. estimated magnitude importance difference matter judgment. problem concluding paragraph implies DGM truth, rather just imperfect approximation true DGM. two main ways DGM might wrong. First, central portion estimate, 55% case, might wrong. might biased low high. hard know , aware. second way DGM might wrong, relative true DGM, uncertainty interval, 4% 53% 57%, might . might narrow wide. reality, however, almost certainly narrow, relative true DGM. Problems assumptions, inevitable, almost always make confidence intervals narrow. Given concerns, provide new final paragraph. paragraph just like one ended Questions Answers section, (perhaps) different mean estimate (almost always) wider confidence interval. later chapters also estimate different (plausible) DGM show answer provides question. answer always different one concluding paragraph. (Ideally, choose small change model produces large change estimates QoI.) Last line every chapter always: “world always uncertain models us believe.”","code":"fit_attitude <- linear_reg(engine = \"lm\") |>   fit(att_end ~ sex + treatment + age, data = trains) plot_predictions(fit_attitude,                  condition = \"sex\") plot_predictions(fit_attitude,                  condition = \"treatment\") plot_predictions(fit_attitude,                  condition = \"age\") plot_predictions(fit_attitude,                  condition = c(\"treatment\", \"age\", \"sex\")) plot_comparisons(fit_attitude,                  variables = \"treatment\",                  condition = \"treatment\")"},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"questions-and-answers","dir":"Articles","previous_headings":"","what":"Questions and Answers","title":"Cardinal Virtues","text":"go back question(s) started journey. discuss question evolved, back--forth process try ensure data question ask close enough make process plausible. revisit Preceptor Table, least conceptually. emphasize DGM allows us fill missing outcomes Preceptor Table, thereby allowing us answer questions. Key issue connection DGM (either true estimated) Preceptor Table. connection tricky! even sure understand . DGM can used “fill ” missing elements Preceptor Table, always associated uncertainty. Even true DGM, don’t know att_end Joe treatment, just posterior variable, way make draws. Idea: Use DGM create one complete Preceptor Table. draw, Joe 6 att_end. , another draw. Joe 5. thousand draws. thousand Preceptor Tables. Calculate Quantity Interest Preceptor Table. 1,000 values posterior QoI. great make cool animation , perhaps simple example. fun similar animation chapter. Great summer project! use data generating mechanism Courage answer question. , obviously, core Temperance section. walk student several plots created marginaleffects package. plots generally increasing complexity. always tell student plot create giving exact code. possible, knowledge drop tries connect plot table regression results interpreted . Example: Example 1  plot shows expected value attitudes toward immigration, conditional model, women men. Women higher (conservative) attitudes toward immigration, adjusting age treatment. consistent negative estimated coefficient sexMale -0.83. Example 2  plot shows expected value attitudes toward immigration, conditional model, exposed treatment (Spanish-speakers train platform) control. Treated individuals higher (conservative) attitudes toward immigration, adjusting age sex consistent positive estimated coefficient treatmentTreated 1.41. Example 3  plot shows expected value attitudes toward immigration, conditional model, individuals different ages. Younger people higher (conservative) attitudes toward immigration, adjusting treatment sex consistent negative estimated coefficient age -0.01. Example 4  plot shows expected value attitudes toward immigration, conditional model, individuals different treatment assignments, ages sexes. often just interested comparisons predictions. tempting think can deduce comparisons just subtracting one prediction another. mostly works center distribution definitely work confidence interval. Fortunately, marginaleffects provides plot_comparison() function purpose. Example 5  plot shows expected value difference attitudes toward immigration Treated Control, conditional model. Treated higher (conservative) attitudes toward immigration, adjusting age sex. consistent negative estimated coefficient treatmentTreated 1.41. relationship plot_predictions() plot_comparisons() subtle, central point , want look difference ratio function one expected value, must use plot_comparisons(). comments plot_comparisons(): values condition argument determine structure plot. first value x-axis, second color third separates plots different panes. value variables argument specifies variable around comparisons organized. model rich enough — meaning enough terms/interactions/non-linearities — won’t enough complexity complex call plot_comparisons(). section always concludes one sentence summary final conclusion. summary include technical terms. meant non-statisticians. something might say explaining take-away conclusion non-statistician. always feature least one number, uncertainty associated number. Example: 55% (±\\pm 2%) people make $100,000 per year liberal. people making $100,000 per year, 55% liberal, although true number low 53% high 57%. cases, like , feature numbers natural interpretation. know percentages . many outcomes measured units difficult interpret. example: causal effect smaller class size math exam scores 10 points. reader know 10 points big small effect doesn’t know anything range scores students get exam. common approach problem “standardize” causal effect dividing standard deviation outcome. example, standard deviation math exam scores 50, re-write : standardized causal effect smaller class size math exam scores 0.2. Depending field, variety terms describing raw causal effect divided standard deviation, including “sigmas” — derived use Greek letter σ\\sigma symbol standard deviation. , might also write: causal effect smaller class size math exam scores 0.2 sigmas. raw effect size 10 20% standard deviation (50). 50, speak instead one “one sigma” one standard deviation. Another common term divide---standard deviation standardization “effect size.” : effect size smaller class size math exam scores 0.2. another approach tackling problem scale natural interpretation. Consider: causal effect hearing Spanish-speakers conservative attitude toward immigration, change 1.5 (±\\pm 0.5) 15 point scale. correct, far goes, idea 1.5 “big” “small” change. need perspective. causal effect hearing Spanish-speakers conservative attitude toward immigration, change 1.5 (±\\pm 0.5) 15 point scale. perspective, difference Democrats Republicans scale 2.1. Terminology important. best words depend audience. example involves describe uncertainty, interval around best estimate quantity interest. terminology — 1.5 (±\\pm 0.5) — works well general audience. may want precise meaning interval. Consider options: 95% interval 0.5 1.5. use word “interval,” without associated adjective, way avoid entire debate. meaning almost certainly Bayesian one: 95% percentile range posterior true causal effect goes 0.5 1.5. 95% confidence interval 0.5 1.5. adjective “confidence” used two different sorts people. First Frequentists, whose philosophy traditional approach statistics still control institutions like College Board. Frequentist meaning , followed approach 100 similar problems , 95% time, confidence interval include true value. don’t understand , don’t worry. never work Frequentist. second sort person uses adjective “confidence” someone actually Bayesian, like us, doesn’t care annoying Frequentists. 95% credible interval 0.5 1.5. adjective “credible” Bayesian analogue “confidence.” Bayesians don’t want annoy Frequentists often replace “confidence” “uncertainty” polite. , Bayesians, meaning always : 95% chance true value 0.5 1.5. main takeaway vast majority people care use “confidence interval” “credible interval” “uncertainty interval.” interpret phrases Bayesian way: X% chance — X often 95 can take values — true value lies within interval. Depending context, might one Quantity Interest discuss. must least one. now ready provide entire concluding paragraph. Using data 2012 survey Boston-area commuters, seek understand relationship income political ideology Chicago similar cities 2020. relationship income ideology may changed eight year period. modeled status liberal political orientation, binary TRUE/FALSE variable, logistic function income. Individuals higher income likely liberal. people making $100,000 per year, 55% liberal, although true number low 53% high 57%. Note deleted rhetorical question — “particular, percentage individuals make $100,000 per year liberal?” — start paragraph. longer necessary. final result data science project paragraph like one. Data science begins question data. ends paragraph , ideally, graphics. course, real data science projects never involve single question. Instead, starting question leads create DGM can answer also can answer lots lots questions. cool. fact, often possible create graphic answers lots questions . ideal. (Michigan postcard example great.) really good data science project always ends cool graphic answers lots questions paragraph like one picks one answer highlight. Questions Answers section ends final paragraph.","code":"fit_attitude <- linear_reg(engine = \"lm\") |>   fit(att_end ~ sex + treatment + age, data = trains) plot_predictions(fit_attitude,                  condition = \"sex\") plot_predictions(fit_attitude,                  condition = \"treatment\") plot_predictions(fit_attitude,                  condition = \"age\") plot_predictions(fit_attitude,                  condition = c(\"treatment\", \"age\", \"sex\")) plot_comparisons(fit_attitude,                  variables = \"treatment\",                  condition = \"treatment\")"},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"plots-from-marginaleffects","dir":"Articles","previous_headings":"","what":"Plots from marginaleffects","title":"Cardinal Virtues","text":"walk student several plots created marginaleffects package. plots generally increasing complexity. always tell student plot create giving exact code. possible, knowledge drop tries connect plot table regression results interpreted . Example: Example 1  plot shows expected value attitudes toward immigration, conditional model, women men. Women higher (conservative) attitudes toward immigration, adjusting age treatment. consistent negative estimated coefficient sexMale -0.83. Example 2  plot shows expected value attitudes toward immigration, conditional model, exposed treatment (Spanish-speakers train platform) control. Treated individuals higher (conservative) attitudes toward immigration, adjusting age sex consistent positive estimated coefficient treatmentTreated 1.41. Example 3  plot shows expected value attitudes toward immigration, conditional model, individuals different ages. Younger people higher (conservative) attitudes toward immigration, adjusting treatment sex consistent negative estimated coefficient age -0.01. Example 4  plot shows expected value attitudes toward immigration, conditional model, individuals different treatment assignments, ages sexes. often just interested comparisons predictions. tempting think can deduce comparisons just subtracting one prediction another. mostly works center distribution definitely work confidence interval. Fortunately, marginaleffects provides plot_comparison() function purpose. Example 5  plot shows expected value difference attitudes toward immigration Treated Control, conditional model. Treated higher (conservative) attitudes toward immigration, adjusting age sex. consistent negative estimated coefficient treatmentTreated 1.41. relationship plot_predictions() plot_comparisons() subtle, central point , want look difference ratio function one expected value, must use plot_comparisons(). comments plot_comparisons(): values condition argument determine structure plot. first value x-axis, second color third separates plots different panes. value variables argument specifies variable around comparisons organized. model rich enough — meaning enough terms/interactions/non-linearities — won’t enough complexity complex call plot_comparisons(). section always concludes one sentence summary final conclusion. summary include technical terms. meant non-statisticians. something might say explaining take-away conclusion non-statistician. always feature least one number, uncertainty associated number. Example: 55% (±\\pm 2%) people make $100,000 per year liberal. people making $100,000 per year, 55% liberal, although true number low 53% high 57%.","code":"fit_attitude <- linear_reg(engine = \"lm\") |>   fit(att_end ~ sex + treatment + age, data = trains) plot_predictions(fit_attitude,                  condition = \"sex\") plot_predictions(fit_attitude,                  condition = \"treatment\") plot_predictions(fit_attitude,                  condition = \"age\") plot_predictions(fit_attitude,                  condition = c(\"treatment\", \"age\", \"sex\")) plot_comparisons(fit_attitude,                  variables = \"treatment\",                  condition = \"treatment\")"},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"scaling-the-qoi","dir":"Articles","previous_headings":"","what":"Scaling the QoI","title":"Cardinal Virtues","text":"cases, like , feature numbers natural interpretation. know percentages . many outcomes measured units difficult interpret. example: causal effect smaller class size math exam scores 10 points. reader know 10 points big small effect doesn’t know anything range scores students get exam. common approach problem “standardize” causal effect dividing standard deviation outcome. example, standard deviation math exam scores 50, re-write : standardized causal effect smaller class size math exam scores 0.2. Depending field, variety terms describing raw causal effect divided standard deviation, including “sigmas” — derived use Greek letter σ\\sigma symbol standard deviation. , might also write: causal effect smaller class size math exam scores 0.2 sigmas. raw effect size 10 20% standard deviation (50). 50, speak instead one “one sigma” one standard deviation. Another common term divide---standard deviation standardization “effect size.” : effect size smaller class size math exam scores 0.2. another approach tackling problem scale natural interpretation. Consider: causal effect hearing Spanish-speakers conservative attitude toward immigration, change 1.5 (±\\pm 0.5) 15 point scale. correct, far goes, idea 1.5 “big” “small” change. need perspective. causal effect hearing Spanish-speakers conservative attitude toward immigration, change 1.5 (±\\pm 0.5) 15 point scale. perspective, difference Democrats Republicans scale 2.1.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"confidencecredibleuncertainty-intervals","dir":"Articles","previous_headings":"","what":"Confidence/Credible/Uncertainty Intervals","title":"Cardinal Virtues","text":"Terminology important. best words depend audience. example involves describe uncertainty, interval around best estimate quantity interest. terminology — 1.5 (±\\pm 0.5) — works well general audience. may want precise meaning interval. Consider options: 95% interval 0.5 1.5. use word “interval,” without associated adjective, way avoid entire debate. meaning almost certainly Bayesian one: 95% percentile range posterior true causal effect goes 0.5 1.5. 95% confidence interval 0.5 1.5. adjective “confidence” used two different sorts people. First Frequentists, whose philosophy traditional approach statistics still control institutions like College Board. Frequentist meaning , followed approach 100 similar problems , 95% time, confidence interval include true value. don’t understand , don’t worry. never work Frequentist. second sort person uses adjective “confidence” someone actually Bayesian, like us, doesn’t care annoying Frequentists. 95% credible interval 0.5 1.5. adjective “credible” Bayesian analogue “confidence.” Bayesians don’t want annoy Frequentists often replace “confidence” “uncertainty” polite. , Bayesians, meaning always : 95% chance true value 0.5 1.5. main takeaway vast majority people care use “confidence interval” “credible interval” “uncertainty interval.” interpret phrases Bayesian way: X% chance — X often 95 can take values — true value lies within interval.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"final-paragraph","dir":"Articles","previous_headings":"","what":"Final Paragraph","title":"Cardinal Virtues","text":"Depending context, might one Quantity Interest discuss. must least one. now ready provide entire concluding paragraph. Using data 2012 survey Boston-area commuters, seek understand relationship income political ideology Chicago similar cities 2020. relationship income ideology may changed eight year period. modeled status liberal political orientation, binary TRUE/FALSE variable, logistic function income. Individuals higher income likely liberal. people making $100,000 per year, 55% liberal, although true number low 53% high 57%. Note deleted rhetorical question — “particular, percentage individuals make $100,000 per year liberal?” — start paragraph. longer necessary. final result data science project paragraph like one. Data science begins question data. ends paragraph , ideally, graphics. course, real data science projects never involve single question. Instead, starting question leads create DGM can answer also can answer lots lots questions. cool. fact, often possible create graphic answers lots questions . ideal. (Michigan postcard example great.) really good data science project always ends cool graphic answers lots questions paragraph like one picks one answer highlight. Questions Answers section ends final paragraph.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/articles/cardinal_virtues.html","id":"humility","dir":"Articles","previous_headings":"","what":"Humility","title":"Cardinal Virtues","text":"Temperance guides us use DGM answer questions began. Humility section always begins single sentence, something along lines : can never know truth. time, hope collect serious quotations along theme. answered question, now (quickly) review reasons answer might wrong. Review specific concerns validity, stability, representativeness, (causal model) unconfoundedness. concerns remain. Review three levels “truth”: Knowing entries Preceptor Table, knowing true DGM, using estimated DGM. (explanation can become sophisticated chapters progress.) can never know entries Preceptor Table. knowledge reserved God. assumptions correct, DGM true, accurately describes way world works. better way predict future, model past, use . Sadly, case toy examples involving things like coins dice. hope DGM close true DGM , since assumption never perfectly correct, DGM always different. estimated magnitude importance difference matter judgment. problem concluding paragraph implies DGM truth, rather just imperfect approximation true DGM. two main ways DGM might wrong. First, central portion estimate, 55% case, might wrong. might biased low high. hard know , aware. second way DGM might wrong, relative true DGM, uncertainty interval, 4% 53% 57%, might . might narrow wide. reality, however, almost certainly narrow, relative true DGM. Problems assumptions, inevitable, almost always make confidence intervals narrow. Given concerns, provide new final paragraph. paragraph just like one ended Questions Answers section, (perhaps) different mean estimate (almost always) wider confidence interval. later chapters also estimate different (plausible) DGM show answer provides question. answer always different one concluding paragraph. (Ideally, choose small change model produces large change estimates QoI.) Last line every chapter always: “world always uncertain models us believe.”","code":""},{"path":"https://ppbds.github.io/primer.tutorials/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David Kane. Author, maintainer.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"David Kane. 2023. 'primer.tutorials'. R package version 1.2.2, <https://github.com/PPBDS/primer.tutorials>.","code":"@Manual{,   title = {primer.tutorials},   author = {David Kane},   year = {2023},   url = {https://github.com/PPBDS/primer.tutorials}, }"},{"path":[]},{"path":"https://ppbds.github.io/primer.tutorials/index.html","id":"about-this-package","dir":"","previous_headings":"","what":"About this package","title":"Tutorials for Preceptor's Primer for Bayesian Data Science","text":"primer.tutorials provides tutorials used Primer Bayesian Data Science.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tutorials for Preceptor's Primer for Bayesian Data Science","text":"can install development version GitHub : suggested updates installation, though latest versions packages, recommended update . packages need compilation, feel free answer “”. restart R session restart RStudio.","code":"# install.packages(\"remotes\") remotes::install_github(\"PPBDS/primer.tutorials\")"},{"path":"https://ppbds.github.io/primer.tutorials/index.html","id":"accessing-tutorials","dir":"","previous_headings":"","what":"Accessing tutorials","title":"Tutorials for Preceptor's Primer for Bayesian Data Science","text":"order access tutorials, start loading package.   can access tutorials via Tutorial pane top right tab RStudio. find Tutorial pane find tutorial called “Getting Started” remember restart R session installing package. Click “Start tutorial”. don’t see tutorials, try clicking “Home” button – little house symbol thin red roof upper right.      order expand window, can drag enlarge tutorial pane inside RStudio. order open pop-window, click “Show New Window” icon next home icon. may notice Jobs tab lower left create output tutorial starting . RStudio running code create tutorial. accidentally clicked “Start Tutorial” like stop job running, can click back arrow Jobs tab, press red stop sign icon. work saved RStudio sessions, meaning can complete tutorial multiple sittings. completed tutorial, follow instructions tutorial Submit page (’re student) submit downloaded rds file instructed.","code":"library(primer.tutorials)"},{"path":"https://ppbds.github.io/primer.tutorials/index.html","id":"re-installation","dir":"","previous_headings":"","what":"Re-installation","title":"Tutorials for Preceptor's Primer for Bayesian Data Science","text":"Since tutorials constantly updated, likely updates come use tutorials. wish stay --date latest version, recommended regularly re-install tutorial package running following 2 lines code R Console: version updates dependency packages please follow considerations discussed Installation section. remember RESTART R SESSION re-installed package.","code":"remove.packages(\"primer.tutorials\") remotes::install_github(\"PPBDS/primer.tutorials\")"},{"path":"https://ppbds.github.io/primer.tutorials/reference/primer.tutorials-package.html","id":null,"dir":"Reference","previous_headings":"","what":"primer.tutorials: Tutorials for Preceptor's Primer for Bayesian Data Science — primer.tutorials-package","title":"primer.tutorials: Tutorials for Preceptor's Primer for Bayesian Data Science — primer.tutorials-package","text":"Collection tutorials use Preceptor's Primer Bayesian Data Science. Makes extensive use tools 'tutorial.helpers' package.","code":""},{"path":[]},{"path":"https://ppbds.github.io/primer.tutorials/reference/primer.tutorials-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"primer.tutorials: Tutorials for Preceptor's Primer for Bayesian Data Science — primer.tutorials-package","text":"Maintainer: David Kane dave.kane@gmail.com (ORCID)","code":""},{"path":[]},{"path":"https://ppbds.github.io/primer.tutorials/news/index.html","id":"primertutorials-122","dir":"Changelog","previous_headings":"","what":"primer.tutorials 1.2.2","title":"primer.tutorials 1.2.2","text":"Return primer.tutorials name repo package.","code":""},{"path":"https://ppbds.github.io/primer.tutorials/news/index.html","id":"primertutorials-121","dir":"Changelog","previous_headings":"","what":"primer.tutorials 1.2.1","title":"primer.tutorials 1.2.1","text":"Delete outline rtweet tutorial. Delete three Appendix tutorials. Added NEWS.md file track changes package. Move prep_rstudio_settings() r4ds.tutorials. Move Getting Started tutorial tutorial.helpers. Move several tutorials — RStudio Code, RStudio Github, Terminal, Quarto Websites Getting Help — r4ds.tutorials.","code":""}]
