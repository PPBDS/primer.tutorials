---
title: Five Parameters
author: David Kane and Satvika Upperla
tutorial:
  id: 091-five-parameters
output:
  learnr::tutorial:
    progressive: yes
    allow_skip: yes
runtime: shiny_prerendered
description: "Tutorial #091 for Preceptor's Primer"
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(gt)

library(tidyverse)
library(tidymodels)
library(marginaleffects)
library(primer.data)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 



x <- governors |> 
  filter(year > 1945) |> 
  select(last_name, year, state, sex, lived_after, election_age, region)

# fit_years <- linear_reg(engine = "lm") |> 
#   fit(lived_after ~ election_age*sex, data = x)
# write_rds(fit_years, "data/fit_years.rds")
fit_years <- read_rds("data/fit_years.rds")
```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

<!-- Change the title to include the word predictive? -->

<!-- Still a couple of XX's to fix. -->


## Introduction
### 

This tutorial supports [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

The world confronts us. Make decisions we must.

<!-- DK: Not sure this works? Predictive or causal? Or a mix of both? -->

Imagine that you are considering running for mayor. One thing you might be interested in is how long candidates for political office live. Politics seems stressful. How many years will you live after the election?

## The Question
### 

*The power to question is the basis of all human progress.* - Indira Gandhi

<!-- XX: Write a few sentences, but no more than a paragraph, which connects your larger problem, as discussed above, to a question which you might be able to answer. That answer won't solve your larger problem! But it should make it more likely that you will deal with the larger problem more intelligently, that your decisions will be better than they otherwise would have been if, counterfactually, you had not completed this data science project. -->

### Exercise 1

Load [**tidyverse**](https://www.tidyverse.org/) package.

```{r the-question-1, exercise = TRUE}

```

```{r the-question-1-hint-1, eval = FALSE}
library(tidyverse)
```

```{r the-question-1-test, include = FALSE}
library(tidyverse)
```

### 

We will be working with information about candidates for governor in the United States. The data was collected for “[Longevity Returns to Political Office](https://doi.org/10.1017/psrm.2019.63)” by Sebastian Barfort, Robert Klemmensen, and Erik Gahner Larsen ([pdf](https://github.com/PPBDS/primer.data/blob/master/inst/papers/governors.pdf)).

### Exercise 2

Load the [**primer.data**](https://ppbds.github.io/primer.data/) package.

```{r the-question-2, exercise = TRUE}

```

```{r the-question-2-hint-1, eval = FALSE}
library(primer.data)
```

```{r the-question-2-test, include = FALSE}
library(primer.data)
```

### 

A version of the data from Barfort et al (2020) is available in the `governors` tibble, which is included in the **primer.data** package.

### Exercise 3

After loading **primer.data** in your Console, type `?governors` in the Console, and paste in the Description below.

```{r the-question-3}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

The abstract of the paper that the tibble is based on: 

> Does political office cause worse or better longevity prospects? Two perspectives in the literature offer contradicting answers. First, increased income, social status, and political connections obtained through holding office can increase longevity. Second, increased stress and working hours associated with holding office can have detrimental effects on longevity. To provide causal evidence, we exploit a regression discontinuity design with unique data on the longevity of candidates for US gubernatorial office. The results show that politicians winning a close election live 5–10 years longer than candidates who lose.

### Exercise 4

Longevity i.e., how long people live, is the broad topic of this tutorial. Given this topic, which variable in `governors` should we use as our outcome variable? 

```{r the-question-4}
question_text(NULL,
	message = "It would be most logical to use `lived_after`.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

<!-- We will use `lived_after` as our outcome variable. -->

<!-- Should the 'x' variable below be replaced with 'governors' to represent the data? --> 

```{r}
ggplot(x, aes(x = lived_after)) +
  geom_histogram(fill = "steelblue", color = "black", bins = 30) +  # Adjusting the colors and bin size
  labs(
    title = "Distribution of Years Lived After Election",
    x = "Years Lived After Election",
    y = "Count"
  ) +
  theme_minimal(base_size = 15) +  # Increasing the base text size for readability
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 18),  # Centering and styling the title
    axis.title.x = element_text(size = 14),  # Adjusting x-axis label size
    axis.title.y = element_text(size = 14),  # Adjusting y-axis label size
    axis.text = element_text(size = 12)  # Adjusting axis text size
  ) +
  scale_x_continuous(breaks = seq(0, max(x$lived_after, na.rm = TRUE), by = 5))  # Custom breaks for x-axis
```


### Exercise 5

Let's imagine a brand new variable which **does not exists** in the data. This variable should be binary, meaning that it only takes on one of two values. It should also, at least in theory, by manipulable. In other words, if the value of the variable is "3," or whatever, then it generates one potential outcome and if it is "9," or whatever, it generates another potential outcome.

Describe this imaginary variable and how might we manipulate its value.

For now, ignore the treatment variable, `win_margin`, used by Barfort et al., although we will be using that later in the analysis. The point of this exercise is to reinforce our understanding of the [Rubin Causal Model](https://ppbds.github.io/primer/rubin-causal-model.html).


```{r the-question-5}
question_text(NULL,
	message = "We will use `exercise` as a treatment variable. If given a value of 1, the candidate exercises regularly. If 0, they don't exercise.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Any data set can be used to construct a causal model as long as there is at least one covariate that we can, at least in theory, manipulate. It does not matter whether or not anyone did, in fact, manipulate it. 

### Exercise 6

Given our (imaginary) treatment variable `exercise`, how many potential outcomes are there for each candidate? Explain why.


```{r the-question-6}
question_text(NULL,
	message = "There are two potential outcomes because the treatment variable `exercise` takes on two possible values: exercise or not exercising.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The same data set can be used to create, separately, lots and lots of different models, both causal and predictive. We can just use different outcome variables and/or specify different treatment variables. This is a *conceptual* framework we apply to the data. It is never inherent in the data itself.

### Exercise 7

In a few sentences, specify the two different values for the imaginary treatment variable `exercise`, for a single unit, guess at the potential outcomes which would result, and then determine the causal effect for that unit given those guesses.

```{r the-question-7}
question_text(NULL,
	message = "For a given candidate, assume that the value of the treatment variable might be 1, exercising regularly or 0, not exercising. If the candidate gets 1, then years lived after the election would be 25. If the candidate gets 0, then years lived would be 20. The causal effect on the outcome of a treatment of 1 versus 0 is 25 - 20 --- i.e., the difference between two potential outcomes --- which equals 5, which is the causal effect for this canidate.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The definition of a causal effect is the difference between two potential outcomes. Of course, you can't just say that the causal effect is 5. The exact value depends on which potential outcome comes first in the subtraction and which second. There is, perhaps, a default sense in which the causal effect is defined as treatment minus control. 

Any causal connection means exploring the *within row* difference between two potential outcomes. We don't need to look at any other rows to have that conversation.

### Exercise 8

Let's consider a *predictive* model. Which variable in `governors` do you think might have an important connection to `lived_after`? 


```{r the-question-8}
question_text(NULL,
	message = "The covariate that is the most connected to `lived_after` is probably `election_age`. If this were a predictive model, we would seek to predict how long a governor would live based, among other things, on what age they were when the election happened.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

With a predictive model, there is only one outcome for each individual unit. There are not two potential outcomes because we are not considering any of the covariates to be a treatment variable. We assuming that the values of all covariates are "fixed." 

There are no "treatments" in predictive models. There are only covariates.

### Exercise 9

Specify two different groups of governors which have specific value for `election_age` and which might have different average values for the `lived_after`.  

```{r the-question-9}
question_text(NULL,
	message = "For governors, the covariate age can be used to define two distinct groups. Group 1 consists of younger candidates aged 40-50. This group is expected to have a higher average `lived_after`, perhaps around 40 years. Group 2 includes older candidates aged 60-70. This group is expected to have a lower average `lived_after`, probably closer to 20 years. ",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In predictive models, do not use words like "cause," "influence," "impact," or anything else which suggests causation. The best phrasing is in terms of "differences" between groups of units with different values for the covariate of interest.

### Exercise 10

Write a predictive question which connects the outcome variable `lived_after` to `election_age`, the covariate of interest. 

```{r the-question-10}
question_text(NULL,
	message = "What is the difference is years lived after the election between younger candidates and older candidates?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The answer to this question is your "Quantity of Interest." 

Our Quantity of Interest might appear too specific, too narrow to capture the full complexity of the topic. There are many, many numbers which we are interested in, many numbers that we want to know. But we don't need to list them all here! We just need to choose one of them since our goal is just to have a specific number which helps to guide us in the creation of the Preceptor Table and, then, the model.


## Wisdom
### 

*Patience is the companion of wisdom.* - Saint Augustine

Our question:

> *How long do political candidates live after the election?*

Note that this question is not exactly the same as the question with which we ended the previous section. And that is OK! Your data science workflow needs to be flexible, to adjust to the data as you work with it and the models as you create them.

### Exercise 1

In your own words, describe the key components of Wisdom when working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The central problem for Wisdom is: Can we use data from `governors` to predict the variables/relationships for current candidates for governor?


### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, we can easily calculate the quantity of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table does not include all the covariates which you will eventually include in your model. It only includes covariates which you need to answer your question.

### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem. Use words like "units," "outcomes," and "covariates."

```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will considered a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This problem is predictive, at least at first blush. We are trying to determine how long candidates live after the election, knowing that different sorts of candidates, as defined by various covariates, have different life expectancies.

### Exercise 4

Create a Github repo called `life-expectancy`. Make sure to click the "Add a README file" check box.

Connect the Github repo to a project on your computer. Use a folder name which matches your repo name.

Select `File -> New File -> Quarto Document ...`. Provide a title -- `"Life Expectancy for Political Candidates"` -- and an author (you). Render the document and save it as `candidates.qmd`.

Edit the `.gitignore` by adding `candidates_files`. Save and push.

In the Console, run:

```         
show_file(".gitignore")
```

CP/CR.

```{r wisdom-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 7)
```

### 

We model units, but only we really care about aggregates.

### Exercise 5

What are the units for this problem?

```{r wisdom-5}
question_text(NULL,
	message = "Individual candidates",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Specifying the Preceptor Table forces us to think clearly about the units and outcomes implied by the question. The resulting discussion sometimes leads us to modify the question with which we started. No data science project follows a single direction. We always backtrack. There is always dialogue.

### Exercise 6

What is the outcome variable for this problem?

```{r wisdom-6}
question_text(NULL,
	message = "lived_after",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We might also combine `lived_after` and `election_age` to calculate a total number of years lived for each candidate. For many models, this would produce more or less the same answer. But, for other models, it would not.


### Exercise 7

What are some covariates which you think might be useful for this problem, regardless of whether or not they might be included in the data?

```{r wisdom-7}
question_text(NULL,
	message = "Longevity of someone's parents are good predictors for her own lifespan. A polygenic risk score for longevity might also be useful.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 4)
```

### 

The term "covariates" is used in at least three ways in data science. First, it is all the variables which might be useful, regardless of whether or not we have the data. Second, it is all the variables for which we have data. Third, it is the set of variables in the data which we end up using in the model.

### Exercise 8

What are the treatments, if any, for this problem?

```{r wisdom-8}
question_text(NULL,
	message = "Since this is a predictive model there is no treatment per se. Any variable which one might consider a treatment is just another covariate in this context. Barfort et al consider winning/losing a close election to be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Remember that a treatment is just another covariate which, for the purposes of this specific problem, we are assuming can be manipulated, thereby, creating two or more different potential outcomes for each unit.

### Exercise 9

What moment in time does the Preceptor Table refer to?

```{r wisdom-9}
question_text(NULL,
	message = "The Preceptor Table refers to now, today, because we are trying to help someone make a decision about running for office. We want to help her better understand the likelihood of various outcomes.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

```{r}
ggplot(x, aes(x = election_age, y = lived_after, color = sex)) +
  geom_point() + 
  labs(title = "Years Lived After Election vs. Election Age",
       x = "Election Age",
       y = "Years Lived After Election") +
  theme_minimal()
```

> *You can never look at the data too much. -- Mark Engerman*

### Exercise 10

Define a causal effect. (Note that the model in this tutorial is predictive, not causal. We just want to make sure you understand what a causal model is.)

```{r wisdom-10}
question_text(NULL,
	message = "A causal effect is the difference between two potential outcomes.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

According to the Rubin Causal Model, there must be two (or more) potential outcomes for any discussion of causation to make sense. This is simplest to discuss when the treatment only has two different values, thereby generating only two potential outcomes. 

### Exercise 11

What is the fundamental problem of causal inference?

```{r wisdom-11}
question_text(NULL,
	message = "The fundamental problem of causal inference is that we can only observe one potential outcome.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

This project is mainly related to predictive modeling so causal interference questions could be moved to avoid confusion. 

### 

If the treatment variable is continuous (like income), then there are lots and lots of potential outcomes, one for each possible value of the treatment variable. 

### Exercise 12

How does the motto "No causation without manipulation" apply in this problem?

```{r wisdom-12}
question_text(NULL,
	message = "The motto does not apply because this is a predictive, not causal, model.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Again, we are trying to answer a predictive question about a specific person's longevity. Barfort et al, however, were trying to calculate the causal effect on lifespan of winning a close election. The exact same data can be used to answer very different questions.

### Exercise 13

Describe in words the Preceptor Table for this problem.

```{r wisdom-13}
question_text(NULL,
	message = "The rows (units) are individual candidates for political office. The outcome is number of years lived after the election. Key covariates include sex, age at the election and party.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table for this problem looks something like this:

```{r}
#| echo: false

tibble(ID = c("Candidate 1", "Candidate 2", "...", "Candidate 10", "Candidate 11", "...", "Candidate N"),
       lived_after = c("12", "7", "...", "10", "11", "...", "6"),
       year_elected = c("2000", "2012", "...", "2012", "2024", "...", "2050"),
       election_age = c("63", "47", "...", "52", "75", "...", "68"),
       sex = c("Female", "Male", "...", "Female", "Female", "...", "Male")) |>
  gt() |>
  tab_header(title = "Preceptor Table") |>
  cols_label(ID = md("ID"),
             lived_after = md("Years Lived After"),
             year_elected = md("Year of Election"),
             election_age = md("Age at Election"),
             sex = md("Sex")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(ID))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(ID))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Outcome", columns = c(lived_after)) |>
  tab_spanner(label = "Covariates", columns = c(sex, year_elected, election_age))
```

Like all aspects of a data science problem, the Preceptor Table evolves as we continue our work. 

### Exercise 14

In your QMD, load the **tidyverse** and the **primer.data** packages in a new code chunk. Render the file.

Notice that the file does not look good because the code is visible and there are annoying messages. To take care of this, add `#| message: false` to remove all the messages in the setup chunk. Also add the following to the YAML header to remove all code echos from the file:

```         
execute: 
  echo: false
```

In the Console, run:

```         
show_file("candidates.qmd", start = -5)
```

CP/CR.

```{r wisdom-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

### 

Render again. Everything looks nice because we have added code to make the file look better and more professional.

### Exercise 15

In the Console, type `governors` and hit `Enter`.

```{r wisdom-15, exercise = TRUE}

```

```{r wisdom-15-hint-1, eval = FALSE}
governors
```

```{r wisdom-15-test, include = FALSE}
governors
```

###

````
> governors
A tibble: 3,587 × 13
   state    year first_name last_name party      sex    died         ...
   <chr>   <int> <chr>      <chr>     <chr>      <chr>  <date>       ...
 1 Alabama  1851 Henry      Collier   Democrat   Male   1855-08-28   ...
 ...
````

The data goes back to the 1850s. Should we include these observations? There is no right answer to that question! In general, the more data that we have, the better that our models will be. But we also know that the world has changed a great deal since the middle of the 19th century. A model built only on more recent data might be better than one built on all the data precisely because it can avoid being biased by those changes.

### Exercise 16

Pipe `governors` to `filter(year > 1945)`

```{r wisdom-16, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r wisdom-16-hint-1, eval = FALSE}
governors |> 
    filter(year > 1945)
```

```{r wisdom-16-test, include = FALSE}
governors |> 
    filter(year > 1945)
```

###

````
> governors |> 
+     filter(year > 1945)
A tibble: 1,090 × 13
   state    year first_name last_name party      sex    died        ...
   <chr>   <int> <chr>      <chr>     <chr>      <chr>  <date>      ...
 1 Alabama  1946 James      Folsom    Democrat   Male   1987-11-21  ...
 ...
````

The assumption of *stability*, which we will discuss more below, means that the relationship between the variables in the data should be the same as the relationship among those same variables in the Preceptor Table. The assumption is much more plausible if the data is not "too" far away, in time, from the Preceptor Table. Restricting the data to the post-World War II period is a common approach for trying to make the stability assumption more plausible.

### Exercise 17

Continue the pipe with `select(last_name, year, state, sex, lived_after, election_age, region)`.

```{r wisdom-17, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

<!-- Hints with select() in them give me trouble, for unclear reasons . . . -->

```{r wisdom-17-test, include = FALSE}
governors |> 
  filter(year > 1945) |> 
  select(last_name, year, state, sex, lived_after, election_age, region)
```

###

````
> governors |> 
+   filter(year > 1945) |> 
+   select(last_name, year, state, sex, lived_after, election_age, region)
# A tibble: 1,090 × 7
   last_name  year state   sex    lived_after election_age region
   <chr>     <int> <chr>   <chr>        <dbl>        <dbl> <chr> 
 1 Folsom     1946 Alabama Male         41.0          38.1 South 
 2 Ward       1946 Alabama Male          2.12         78.5 South 
 3 Persons    1950 Alabama Male         14.6          48.7 South 
 4 Abernethy  1954 Alabama Male         13.3          46.5 South 
 ...
````

We have lost more than 2/3 of the observations because of our restriction to the post 1945 period. Is that a reasonable trade-off for increasing the match between the data and the Preceptor Table? There is no "right" answer to that question. Use your own judgment.

### Exercise 18

In your own words, define "validity" as we use the term.

```{r wisdom-18}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Validity is always about the *columns* in the Preceptor Table and the data. Just because columns from these two different tables have the same *name* does not mean that they are the same *thing*.

### Exercise 19

Provide one reason why the assumption of validity might not hold for the outcome variable `lived_after` or for one of the covariates. Use the words "column" or "columns" in your answer.

```{r wisdom-19}
question_text(NULL,
	message = "As Barfort et al discuss, the information about birth and death dates for *losing* candidates isn't nearly as well-documented as it is for *winning* candidates. The errors in the `lived_after` column in our data make this variable correspond less well to the years-lived-after-the-election column in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In order to consider the Preceptor Table and the data to be drawn from the same population, the columns from one must have a *valid correspondence* with the columns in the other. Validity, if true (or at least reasonable), allows us to construct the Population Table, which is the first step in Justice.

Because we control the Preceptor Table and, to a lesser extent, the original question, we can adjust those variables to be “closer” to the data that we actually have. This is another example of the iterative nature of data science. If the data is not close enough to the question, then we check with our boss/colleague/customer to see if we can modify the question in order to make the match between the data and the Preceptor Table close enough for validity to hold.

### Exercise 20

Over the course of this tutorial, we will be creating a summary paragraph. The purpose of this exercise is to write the first two sentences of that paragraph.

The first sentence is a general statement about the overall topic, mentioning both the general class of the outcome variable and of at least one of the covariates. It is **not** connected to the initial "Imagine that you are XX" which set the stage for this project. That sentence can be rhetorical. It can be trite, or even a platitude. The purpose of the sentence to let the reader know, gently, about our topic.

The second sentence does two things. First, it introduces the data source. Second, it introduces the specific question. The sentence can't be that long. Important aspects of the data include when/where it was gather, how many observations it includes and the organization (if famous) which collected it.

Type your two sentences below.

```{r wisdom-20}
question_text(NULL,
	message = "Running for political office is stressful. Using data from over 1,000 candidates for governor since 1945 in the United States, we seek to create a model for forecasting longevity for political candidates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Read our answer. It will not be the same as yours. You can, if you want, change your answer to incorporate some of our ideas. Do not copy/paste our answer exactly. Add your two sentences, edited or otherwise, to your QMD, `Command/Ctrl + Shift + K`, and then commit/push.

## Justice
### 

*The arc of the moral universe is long, but it bends toward justice.* - Theodore Parker

### Exercise 1

In your own words, name the four key components of Justice when working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Justice is about concerns that you (or your critics) might have, reasons why the model you create might not work as well as you hope. 

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Population Table is almost always much bigger than the combination of the Preceptor Table and the data because, if we can really assume that both the Preceptor Table and the data are part of the same population, than that population must cover a broad universe of time and units since the Preceptor Table and the data are, themselves, often far apart from each other.

### Exercise 3

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-3}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

*The longer the time period covered by the Preceptor Table (and the data), the more suspect the assumption of stability becomes.* This is why removing the data from before 1945 might actually make our model better that it would have been if we had included it.

### Exercise 4

Provide one reason why the assumption of stability might not be true in this case.

```{r justice-4}
question_text(NULL,
	message = "Running for election as a woman was a very different proposition in 1950 than it is today, so the relationship between sex and years lived after the election may have changed.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A change in time or the distribution of the data does not, in and of itself, demonstrate a violation of stability. Stability is about the parameters: $\beta_0$, $\beta_1$ and so on. Stability means these parameters are the same in the data as they are in the population as they are in the Preceptor Table.

### Exercise 5

We use our data to make inferences about the overall population. We use information about the population to make inferences about the Preceptor Table: `Data -> Population -> Preceptor Table`. In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-5}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationships among the rows in the Population Table. The first is between the data and the other rows. The second is between the other rows and the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case.

### Exercise 6

We do not use the data, directly, to estimate missing values in the Preceptor Table. Instead, we use the data to learn about the overall population. Provide one reason, involving the relationship between the data and the population, for why the assumption of representativeness might not be true in this case. 

```{r justice-6}
question_text(NULL,
	message = "We are interested all sorts of political offices: mayors, governors, senators and so on. Ideally, we would like our data to include people who have run for all these positions. But our data only includes candidates for governor. It is not representative of the larger population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The reason that representativeness is important is because, when it is violated, the estimates for the model parameters might be biased. 

### Exercise 7

We use information about the population to make inferences about the Preceptor Table. Provide one reason, involving the relationship between the population and the Preceptor Table, for why the assumption of representativeness might not be true in this case.

```{r justice-7}
question_text(NULL,
	message = "Even if our data about governors is representative of the larger population of all political offices, our Preceptor Table is not a random draw from that population. We are only interested in mayors because the person who came to us is considering a mayoral campaign. Mayors are not a representative sample of all candidates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

<!-- The tutorial often switches between mayoral and gubernatorial elections. These differences could be removed to make the tutorial easier to understand for students. -->

### 

Stability looks across time periods. Representativeness looks within time periods, for the most part. 

### Exercise 8

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-8}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This assumption is only relevant for causal models. We describe a model as "confounded" if this is not true. The easiest way to ensure unconfoundedness is to assign treatment randomly.

### Exercise 9

Write one sentence which highlights a potential weakness in your model. This will almost always be derived from possible problems with the assumptions discussed above. We will add this sentence to our summary paragraph. So far, our version of the summary paragraph looks like this:

> Running for political office is stressful. Using data from over 1,000 candidates for governor since 1945 in the United States, we seek to create a model for forecasting longevity for political candidates.

Of course, your version will be somewhat different.

```{r justice-9}
question_text(NULL,
	message = "Because our data includes only candidates for governor, our estimated model might not work well when applied to candidates for other positions, like mayor.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Add a weakness sentence to the summary paragraph in your QMD. You can modify your paragraph as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`, and then commit/push.


## Courage
### 

*Courage is being scared to death, but saddling up anyway.* - John Wayne

<!-- 

5) Choose among models. In early tutorials, this might just involve looking at coefficient values/significance. Later, we might use a more formal approach from easystats. At least one model should be checked for posterior prediction problems.

5a) Run the equivalent of pp_check on the last model, just to confirm that things looks good.

6) Once we have our DGM, we can create the LaTeX math: we have the mathematical formula which specifies exactly which variables to include and how to transform them. All the parameters replaced by our estimates and with the error term dropped. The dependent variable wears a hat. This is our data generating mechanism.

7) Produce a two sentence summary. Add it to the quarto doc. The first sentence gives the form of the model, including a reminder as to the distribution of the dependent variable. (Hmm. Is that right? The distribution of the dependent variable in the data might not be exactly the same as the distribution of the predictions. Compare the 3 -- 15 integer values of att_end to the normal values from hat att_end.) The second sentence tells us something about the model, generally involving the sign of one of the covariates.

The Quarto document should include the last two descriptions: the DGM and a two sentence description of the DGM. 

When we have a model, like random forest, without a simple mathematical structure, we still need the written description. Indeed, it is even more important in this case. Would it be useful to also have a diagram of some type which explains what a random forest is, perhaps a PNG which could be included in the document?

It is important that tutorial writers use AI to create excellent answers, which we then share with students.
-->

### Exercise 1

In your own words, describe the components of the virtue of Courage for analyzing data.

```{r courage-1}
question_text(NULL,
	message = "Courage starts with math, explores models, and then creates the data generating mechanism.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A statistical model consists of two parts: the *probability family* and the *link function*. The probability family is the probability distribution which generates the randomness in our data. The link function is the mathematical formula which links our data to the unknown parameters in the probability distribution. 

### Exercise 2

Load the [**tidymodels**](https://www.tidymodels.org/) package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(tidymodels)
```

```{r courage-2-test, include = FALSE}
library(tidymodels)
```

### 

The probability family is determined by the outcome variable $Y$, which is `lived_after` in this case.

Since `lived_after` is a continuous variable, the probability family is Normal, also known as Gaussian.

$$Y \sim N(\mu, \sigma^2)$$


### Exercise 3

Load the [**broom**](https://broom.tidymodels.org/) package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(broom)
```

```{r courage-3-test, include = FALSE}
library(broom)
```

### 

The link function, the basic mathematical structure of the model, is (mostly) determined by the type of outcome variable. 

For a continuous outcome variable, we use a linear model for the link function:

$$\mu = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots$$

### Exercise 4

Use AI to come up with a $\LaTeX$ representation of the mathematical structure of the model, with $Y$ as the dependent variable and $X_1$, $X_2$ and so on as the independent variables. This version will not have the values of any parameters since we have not, yet, estimated them. Confirm that the code works by placing it in your QMD and then rendering. Paste that $\LaTeX$ code below.

```{r courage-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###

Our answer:

$$Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_n X_n + \epsilon$$

with $\epsilon \sim \mathcal{N}(0, \sigma^2)$.

Which we created with $\LaTeX$ code that looks like this:

````
$$Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_n X_n + \epsilon$$

with $\epsilon \sim \mathcal{N}(0, \sigma^2)$.
````

We use generic variables --- $Y$, $X_1$ and so on --- because our purpose is to describe the general mathematical structure of the model, independent of the specific variables we will eventually choose to use.

### Exercise 5

Add `library(tidymodels)` and `library(broom)` to the `setup` code chunk in your QMD. `Command/Ctrl + Shift + K`.

At the Console, run:

```
tutorial.helpers::show_file("candidates.qmd", pattern = "tidymodels|broom")
```

CP/CR.

```{r courage-5}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Having decided on the basic mathematical structure of the model, a choice mostly driven by the distribution of our outcome variable, we now turn toward estimating the model.



### Exercise 6

Because our outcome variable is continuous, start to create the model by using `linear_reg(engine = "lm")`.

```{r courage-6, exercise = TRUE}

```

```{r courage-6-hint-1, eval = FALSE}
linear_reg(engine = "lm")
```

```{r courage-6-test, include = FALSE}
linear_reg(engine = "lm")
```

### 

The *[tidymodels](https://www.tidymodels.org/)* framework is the most popular one in the R world for estimating models. *[Tidy Modeling with R](https://www.tmwr.org/)* by Max Kuhn and Julia Silge is a great book introduction.

### Exercise 7

Continue the pipe to `fit(lived_after ~ sex, data = x)`.

```{r courage-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-7-hint-1, eval = FALSE}
... |> 
  fit(... ~ sex, ... = x)
```

```{r courage-7-test, include = FALSE}
linear_reg(engine = "lm") |> 
  fit(lived_after ~ sex, data = x)
```

### 

````
Call:
stats::lm(formula = lived_after ~ sex, data = data)

Coefficients:
(Intercept)      sexMale  
      16.00        12.45  
````

Recall that a categorical variable (whether character or factor) like `sex` is turned into a $0/1$ "dummy" variable which is then re-named something like $sexMale$. After all, we can't have words --- like "Male" or "Female" --- in a mathematical formula, hence the need for dummy variables.

### Exercise 8

Continue the pipe with `tidy(conf.int = TRUE)`.

```{r courage-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-8-hint-1, eval = FALSE}
...
  tidy(... = TRUE)
```

```{r courage-8-test, include = FALSE}
linear_reg(engine = "lm")|> 
  fit(lived_after ~ sex, data = x) |> 
  tidy(conf.int = TRUE)
```

### 

````
  term        estimate std.error statistic      p.value conf.low conf.high
  <chr>          <dbl>     <dbl>     <dbl>        <dbl>    <dbl>     <dbl>
1 (Intercept)     16.0      2.90      5.52 0.0000000419    10.3       21.7
2 sexMale         12.4      2.93      4.25 0.0000228        6.71      18.2
````

If the candidate is female, then the value of `sexMale` is 0, meaning that the expected value for years lived after the election is about 16. However, if the candidate is male, then `sexMale` equal 1 and the expected years lived is 28.4.

And that is surprising! Normally, we think of women as living longer than men. Perhaps there is something that this model leaves out?

<!-- DK: Could add a question about this? -->

### Exercise 9

Change the call to `fit()` to `fit(lived_after ~ region, data = x)` and drop the call to `tidy()`.

```{r courage-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-9-hint-1, eval = FALSE}
... |> 
  fit(... ~ region, ... = x)
```

```{r courage-9-test, include = FALSE}
linear_reg(engine = "lm") |> 
  fit(lived_after ~ region, data = x) 
```

### 

````
Call:
stats::lm(formula = lived_after ~ region, data = data)

Coefficients:
    (Intercept)  regionNortheast      regionSouth       regionWest  
        28.3983          -0.2544          -0.2685          -0.2426  
````

The same dummy variable approach applies to a categorical covariate with $N$ values. Such cases produce $N-1$ dummy $0/1$ variables. The presence of an intercept in most models means that we can't have $N$ categories. The "missing" category is incorporated into the intercept. Since `region` has four values --- "Midwest," "Northeast," "South," and "West"  --- the model creates three 0/1 dummy variables, giving them names like $regionNortheast$ and $regionSouth$. The results for the *first* category (which is "Midwest" in this case)  are included in the intercept, which becomes the reference case, relative to which the other coefficients are applied.

### Exercise 10

Add back the call to `tidy(conf.int = TRUE)`.

```{r courage-10, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-10-hint-1, eval = FALSE}
... |> 
  fit(lived_after ~ region, data = x) |> 
  tidy(... = TRUE)
```

```{r courage-10-test, include = FALSE}
linear_reg(engine = "lm")|> 
  fit(lived_after ~ region, data = x) |> 
  tidy(conf.int = TRUE)
```

### 

````
 term            estimate std.error statistic   p.value conf.low conf.high
  <chr>              <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl>
1 (Intercept)       28.4       0.769    36.9   3.90e-194    26.9      29.9 
2 regionNortheast   -0.254     1.18     -0.216 8.29e-  1    -2.56      2.05
3 regionSouth       -0.269     1.10     -0.244 8.07e-  1    -2.43      1.89
4 regionWest        -0.243     1.12     -0.216 8.29e-  1    -2.44      1.96
````

Candidates from the Midwest, the category for which a dummy variable is not created (because it is the first alphabetically), live 28.4 years on average after the election. But candidates from other regions live about that long as well. Notice how the 95% confidence intervals for those coefficients include 0. So, we probably don't need to include `region` in the model.

### Exercise 11

Change the call to `fit()` to `fit(lived_after ~ sex + election_age, data = x)`.

```{r courage-11, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-11-hint-1, eval = FALSE}
... |> 
  fit(... ~ sex + election_age, ... = x)
  ...
```

```{r courage-11-test, include = FALSE}
linear_reg(engine = "lm") |> 
  fit(lived_after ~ sex + election_age, data = x) |> 
  tidy(conf.int = TRUE)
```

### 

````
term         estimate std.error statistic  p.value conf.low conf.high
(Intercept)    66.0      3.33       19.8  6.15e-75   59.4      72.5  
sexMale         6.21     2.46        2.53 1.16e- 2    1.39     11.0  
election_age   -0.848    0.0388    -21.9  4.44e-88   -0.924    -0.772
````

The more variables we add, the more difficult it is to interpret the meaning of any particular coefficient. But interpretation also becomes less important. We don't really care about coefficients. We care about using our model to estimate quantities of interest.

In this case, the coefficient of `sexMale` is 50% lower than before, presumably because female candidates tend to be older and, by including `election_age`, we have adjusted for that difference.

### Exercise 12

Change the formula in the call to `fit()` to `lived_after ~ sex + election_age + sex*election_age`.

```{r courage-12, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-12-hint-1, eval = FALSE}
... |> 
  fit(... ~ sex + election_age + sex*election_age, data = x)
  ...
```

```{r courage-12-test, include = FALSE}
linear_reg(engine = "lm") |> 
  fit(lived_after ~ sex + election_age + sex*election_age, data = x) |> 
  tidy(conf.int = TRUE)
```

### 

````
term                 estimate std.error statistic p.value conf.low conf.high
(Intercept)           19.3       22.0       0.878  0.380   -23.9     62.5   
sexMale               53.3       22.1       2.41   0.0161    9.92    96.7   
election_age          -0.0563     0.371    -0.152  0.879    -0.785    0.672 
sexMale:election_age  -0.800      0.373    -2.14   0.0323   -1.53    -0.0676
````

Because the 95% confidence interval for the coefficient of the interaction between `sexMale` and `election_age`, we should keep the interaction. And, whenever we include interaction terms, we always keep the component terms as well, regardless of their statistical significance. 


### Exercise 13

Behind the scenes of this tutorial, an object called `fit_years` has been created which is the result of the code above. Type `fit_years` and hit "Run Code." This generates the same results as using `print(fit_years)`.


```{r courage-13, exercise = TRUE}

```

```{r courage-13-hint-1, eval = FALSE}
fit_years
```

```{r courage-13-test, include = FALSE}
# fit_years
```

### 

In data science, **we deal with words, math, and code, but the most important of these is code.** We created the mathematical structure of the model and then wrote a model formula in order to estimate the unknown parameters. 


### Exercise 14

Create a new code chunk in your QMD. Add a code chunk option: `cache: true`. Copy/paste the code from above for estimating the model into the code chunk, assigning the result to `fit_years`. 

`Command/Ctrl + Shift + K`. It may take some time to render your QMD, depending on how complex your model is. But, by including `cache: true` you cause Quarto to cache the results of the chunk. The next time you render your QMD, as long as you have not changed the code, Quarto will just load up the saved fitted object.

To confirm, `Command/Ctrl + Shift + K` again. It should be quick.

At the Console, run:

```
tutorial.helpers::show_file("candidates.qmd", start = -8)
```

CP/CR.

```{r courage-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 8)
```

### 

<!-- DK: Should this be a separate question? -->

Add `*_cache` to `.gitignore` file. Commit and push. Cached objects are often large. They don't belong on Github.

### Exercise 15

Pass the $\LaTeX$ from the basic model you created above and the result of the fitting process to an AI and ask it for the $\LaTeX$ for the fitted model. Add it to your QMD.

`Command/Ctrl + Shift + K` to make sure it works. Fit it if not. 

At the Console, run:

```
tutorial.helpers::show_file("candidates.qmd", start = -3)
```

CP/CR.

```{r courage-15}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Our formula looks like:

$$\widehat{\text{att_end}} = 8.45 + 1.55 \cdot \text{treatment}_{\text{Treated}}$$

It was created with:

````
$$\widehat{\text{att_end}} = 8.45 + 1.55 \cdot \text{treatment}_{\text{Treated}}$$
````

Note the differences. First, we have replaced the parameters with our best estimates. Second, we have dropped the error term because this is a formula for predicting the value for our outcome variable. Third, the left-hand side variable is $\widehat{\text{att_end}}$ instead of $\text{att_end}$ because this formula generates our estimated `att_end`. A hat indicates an estimated value.

This is our data generating mechanism.

### Exercise 16

<!-- DK: Is tidy() what we want? Could use easystats. Do we need to load up broom above? -->

Run `tidy()` on `fit_years` with the argument `conf.int` set equal to `TRUE`. The returns 95% intervals for all the parameters in our model.

```{r courage-16, exercise = TRUE}

```

```{r courage-16-hint-1, eval = FALSE}
tidy(..., conf.int = ...)
```

```{r courage-16-test, include = FALSE}
# tidy(fit_years, conf.int = TRUE)
```

### 

`tidy()` is part of the [**broom**](https://broom.tidymodels.org/) package, used to summarize information from a wide variety of models.

### Exercise 17

Create a new code chunk in your QMD. Ask AI to help you make a nice looking table from the tibble which is returned by `tidy()` Insert that code into the QMD. 


`Command/Ctrl + Shift + K`. 

Make sure it works. You might need to add some new libraries, e.g., **knitr**, **gt**, **kable**, **flextable**, et cetera, to the `setup` code chunk.

At the Console, run:

```
tutorial.helpers::show_file("candidates.qmd", end = -10)
```

CP/CR.


```{r courage-17}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 12)
```

At the very least, yor table should include a title and a caption with the data source. The more you use AI, the better you will get at doing so.

### Exercise 18

Add a sentence to your project summary. 

Explain the structure of the model. Something like: "I/we model XX [the concept of the outcome, not the variable name], [insert description of values of XX], as a [linear/logistic/multinomial/ordinal] function of XX [and maybe other covariates]." 

Recall the beginning of our version of the summary:

> XX: Include what we suggested at the end of Justice

```{r courage-18}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Read our answer. It will not be the same as yours. You can, if you want, change your answer to incorporate some of our ideas. Do not copy/paste our answer exactly. Add your two sentences, edited or otherwise, to summary paragraph portion of your QMD. `Command/Ctrl + Shift + K`, and then commit/push.

## Temperance
### 

*Temperance is the greatest of all virtues. It subdues every passion and emotion, and almost creates a Heaven upon Earth.* - Joseph Smith Jr.

### Exercise 1

In your own words, describe the use of Temperance in data science.

```{r temperance-1}
question_text(NULL,
	message = "Temperance uses the data generating mechanism to answer the question with which we began. Humility reminds us that this answer is always a lie. We can also use the DGM to calculate many similar quantities of interest, displaying the results graphically.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Courage gave us the data generating mechanism. Temperance guides us in the use of the DGM — or the “model” — we have created to answer the question(s) with which we began. We create posteriors for the quantities of interest. 

### Exercise 2

Before using the DGM, we should make sure that we can interpret it.

Recall the values for the parameters in our data generating mechanism:

```{r}
fit_years |> 
	tidy(conf.int = TRUE) |> 
	select(term, estimate, conf.low, conf.high)
```

Interpret 19.3, the estimate for the `(Intercept)`.

```{r temperance-2}
question_text(NULL,
	message = "For female candidates, the terms which include `sexMale` and  `election_age:sexMale` are zeroed out. 19.3 would be the expected years lived after the election for candidates who are age 0 at the election, which is, of course, nonsense.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

Dummy variables must always be interpreted in the context of the base value for that variable, which is generally included in the intercept. For example, the base value here is "Female." (The base value is the first alphabetically by default for character variables. However, if it is a factor variable, you can change that by setting the order of the levels by hand.)

### Exercise 3

```{r}
fit_years |> 
	tidy(conf.int = TRUE) |> 
	select(term, estimate, conf.low, conf.high)
```

Interpret -0.06, the estimate for the coefficient for `election_age`.

```{r temperance-3}
question_text(NULL,
	message = "The older you are at the time of the election (i.e., the larger the value for `election_age`), the fewer years you can expect to live after the election. The negative value makes sense. The magnitude of 0.06 suggests that, if we compare two groups of female candidates --- so that `election_age:sexMale` is zeroed out --- who differ in age by twenty years, then the older group might live about one year less since -0.06 * 20 = -1.2. That seems much too small!",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

Whenever we consider non-treatment variables, we must never use terms like "cause," "impact" and so on. We can't make any statement which implies the existence of more than one potential outcome based on changes in non-treatment variables. We can't make any claims about within row effects. Instead, we can only compare across rows. Always use the phrase "when comparing X and Y" or something very similar.

### Exercise 4

```{r}
fit_years |> 
	tidy(conf.int = TRUE) |> 
	select(term, estimate, conf.low, conf.high)
```

Interpret -0.8, the estimate for the coefficient of `election_age:sexMale`.

```{r temperance-4}
question_text(NULL,
	message = "Relative to female candidates, male candidates who are older die much earlier than younger candidates. The -0.8 estimate suggests that male candidates who are twenty years older, live 16 years less after the election, compared to their younger peers. This seems much more plausible than the 1 year estimate for female candidates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

Numeric variables are harder to use in comparisons than binary variables because there are no longer just two well-defined groups to compare with each other. We must create those two groups ourselves. Fortunately, as long as there are no interaction terms, we can just pick two groups with any values for the variable. The most common two groups differ by one unit of the variable. But it is quite common to use groups which differ by more/less if doing so seems sensible and/or if it makes the math easier.

### Exercise 5

```{r}
fit_years |> 
	tidy(conf.int = TRUE) |> 
	select(term, estimate, conf.low, conf.high)
```

Interpret [-1.5, -0.07], the confidence interval for the estimate of the coefficient of `election_age:sexMale`.

```{r temperance-5}
question_text(NULL,
	message = "Our best estimate is that male candidates who are 20 years younger will live 16 years longer than their older male peers. But that is just an estimate. We are uncertain. It would not be surprising if the true value were as low as 1.4 years or as high as 30 years.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

In looking at a confidence interval, we first check whether or not it excludes zero.  If not, then we can't be sure if the relationship is positive or negative. For female candidates, the confidence interval includes zero, so we are not sure (absurdly!) if younger candidates live longer. This is probably a sign that we don't have enough observations for females. 

### Exercise 6

In the end, we don't really care about parameters, much less how to interpret them. Parameters are *imaginary*, like unicorns. We care about answers to our questions. Parameters are tools for answering questions. They aren't interesting in-and-of themselves. *In the modern world, all parameters are nuisance parameters.* 

Load the [**marginaleffects**](https://marginaleffects.com/) package.

```{r temperance-6, exercise = TRUE}

```

<!-- DK: This is throwing an error, as if it is trying to run this code (which then fails) even though it is a hint. This happened above in the select() call as well. Is there some code above which is causing hint code to be run when it shouldn't be?

```{r temperance-6-hint-1, eval = FALSE}
library(...)
``` 
-->

```{r temperance-6-test, include = FALSE}
library(marginaleffects)
```

### 

We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.

### Exercise 7

What is the specific question we are trying to answer? 

```{r temperance-7}
question_text(NULL,
	message = "How long do political candidates live after the election?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Data science projects almost always begin with a broad topic of interest. Yet, in order to make progress, we need to drill down to a specific question. This leads to the creation of a data generating mechanism, which can now be used to answer lots of questions, thus allowing us to explore the original topic more broadly.


### Exercise 8

Run this code:

```
plot_predictions(fit_years, 
				 by = "sex")
```             


```{r temperance-8, exercise = TRUE}

```


```{r temperance-8-test, include = FALSE}
plot_predictions(fit_years, 
				 by = "sex")
```

### 

This graphic shows our estimates for the number of years lived after the election for male and female candidates. 

* The ?plot_predictions page notes that "The by argument is used to plot marginal predictions, that is, predictions made on the original data, but averaged by subgroups."

* There is much more uncertainty for female candidates than for male candidates because there are so few females in the data.

* Male candidates live longer than female candidates. That is surprising since, in general, women live longer than men. One explanation might be that, in our data, female candidates are older.

### Exercise 9

Run this code:

```
plot_predictions(fit_years,
				condition = c("election_age"))
```             

```{r temperance-9, exercise = TRUE}

```

```{r temperance-9-test, include = FALSE}
plot_predictions(fit_years, 
				 condition = c("election_age"))
```

### 

This graphic shows our estimates for the number of years lived after the election for candidates of different ages. 

* The ?plot_predictions page notes that "The condition argument is used to plot conditional predictions."

* The older you are at the election, the fewer years you can expect to live after the election.

* Note that, when using the `by` argument, you can only use categorical predictors. 


### Exercise 10

Run this code:

```
plot_predictions(fit_years, 
				 by = c("election_age", "sex"))
```             

```{r temperance-10, exercise = TRUE}

```


```{r temperance-10-test, include = FALSE}
plot_predictions(fit_years, 
				 by = c("election_age", "sex"))
```

### 

This is a good example of a plot which provides answer to the question with which we started: 

> *How long do political candidates live after the election?*

For a specific values of the covariates `sex` and `election_age`, you can simply consult the graphic to see how many more years we would expect them to live, and the uncertainty associated with that estimate.

### Exercise 11

Work interactively with your QMD to make a beautiful version of this plot. Your title should highlight the key variables. Your subtitle should describe the key takeaway, the sentence/conclusion which readers will, you hope, remember. Your caption should mention the data source. Your axis labels should look nice.

This plot is not directly connected to your question. It answers lots of questions! It might be used by lots of different people. 

Copy the code for your plot here:

```{r temperance-11}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 20)
```

###

Data science often involves this-back-and-forth style of work. First, we need to make a single chunk of code, in this case, a new plot, work well. This requires interactive work between the QMD and the Console. Second, we need to ensure that the entire QMD runs correctly on its own.

### Exercise 12

Finalize the new graphics code chunk in your QMD.

`Command/Ctrl + Shift + K` to ensure that it all works as intended. Don't forget to add `library(marginaleffects)` to your `setup` code chunk.

At the Console, run:

```
tutorial.helpers::show_file("candidates.qmd", start = -8)
```

CP/CR.

```{r temperance-12}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 10)
```


### 

Again, this model is obviously flawed. I don't believe that a female political candidate who ise 50 years old should expect to live fewer years after the election than a male candidate. I don't think that the the relationship between `election_age` and `lived_after` is, for female candidates, nearly as flat as it appears.

No model is perfect, but this one seems not very good!

### Exercise 13

Write the last sentence of your summary paragraph. It describes at least one quantity of interest (QoI) and provides a measure of uncertainty about that QoI. (It is OK if this QoI is not the one that you began with. The focus of a data science project often changes over time.)

```{r temperance-13}
question_text(NULL,
	message = "A 50-year-old male political candidate can expect to live about 30 years after the election, plus-or-minus about 1 year.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Add a final sentence to your summary paragraph in your QMD as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`.

### Exercise 14

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval, if you think either might be warranted.

```{r temperance-14}
question_text(NULL,
	message = "There is clearly something weird about the data for female candidates. But, at the same time, we are trying to make a claim for candidates in general, not just male candidates. So, I would change the conclusion to: a 50-year-old political candidates can expect to live another 18 years, plus-or-minus 4 years.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We have treated this as a predictive model. But is it? The original question talks about "you" considering a run for office. You are not a political candidate yet. You don't really want to know how long you will live if you run for office. You almost certainly want to know the **causal effect** of running for office: the difference between `lived_after` if you run and `lived_after` if you do not. If so, we need to redo all the work, estimating a causal model instead of a predictive one.

### Exercise 15

Rearrange the material in your QMD so that the order is graphic, paragraph, math and table. Doing so, of course, requires sensible judgment. For example, the code chunk which creates the fitted model must occur before the chunk which creates the graphic. `Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("candidates.qmd")
```

CP/CR.

```{r temperance-15}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

This is the version of your QMD file which your teacher is most likely to take a close look at.

### Exercise 16

Publish your rendered QMD to GitHub Pages. Copy/paste the resulting url below.

```{r temperance-16}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Commit/push everything.

### Exercise 17

Copy/paste the url to your Github repo.

```{r temperance-17}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

A Bayesian model, using something like the **brms** package, would probably work better for this problem.

## Summary
### 

This tutorial supports [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

<!-- XX: Give your final plot and our summary paragraph. And a note indicating how this information might be helpful to the Imagine person we created at the start. Or maybe do that in the last few questions in Temperance? -->


```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
