---
title: Stops
author: Sanaka Dash, David Kane, and Satvika Upperla
tutorial:
  id: stops
output:
  learnr::tutorial:
    progressive: yes
    allow_skip: yes
runtime: shiny_prerendered
description: 'Tutorial: Stops'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(gt)

library(tidyverse)
library(tidymodels)
library(broom)
library(marginaleffects)
library(primer.data)
library(equatiomatic)
library(tidytext)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

# Creates a model used for a plot in Wisdom-6

fit_arrested <- linear_reg() |>
    set_engine("lm") |>
    fit(arrested ~ zone, data = stops)

# Creates new df with 4 entries for race & converts sex and race to be capitalized

x <- stops |>
  filter(race %in% c("black", "white")) |>
  mutate(race = str_to_title(race), 
         sex = str_to_title(sex))

# Store the model from Courage

fit_stops <- linear_reg() |>
    set_engine("lm") |>
    fit(arrested ~ sex + race*zone, data = x)

```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```




## Introduction
### 

This tutorial supports [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

The world confronts us. Make decisions we must.

Imagine you’re a member of your city’s police department, and you believe strongly in fair and equal treatment for everyone. You want to ensure that a person’s race or age doesn’t unfairly affect their chances of being arrested during a traffic stop. 

### Exercise 1

What are the four [Cardinal Virtues](https://en.wikipedia.org/wiki/Cardinal_virtues), in order, which we use to guide our data science work?

```{r introduction-1}
question_text(NULL,
	message = "Wisdom, Justice, Courage, and Temperance.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

###

Why do we ask this, and a score more other questions, in each tutorial? Because the best way to (try to) ensure that students remember these concepts more than a few months after the course ends is [spaced repetition](https://en.wikipedia.org/wiki/Spaced_repetition), although we focus more on the repetition than on the spacing.


## The Question
### 

*The power to question is the basis of all human progress.* - Indira Gandhi


### Exercise 1

Load **tidyverse**.

```{r the-question-1, exercise = TRUE}

```

```{r the-question-1-hint-1, eval = FALSE}
library(tidyverse)
```

```{r the-question-1-test, include = FALSE}
library(tidyverse)
```

### 

The data that we will use was sourced from the [Open Policing project](https://openpolicing.stanford.edu/findings/). Based at Stanford University, the project aims to improve police accountability and transparency by providing data on traffic stops across the United States. They have many downloadable datasets, and our data is specifically derived from their [New Orleans dataset.](https://openpolicing.stanford.edu/data/)


### Exercise 2

Load the **primer.data** package.

```{r the-question-2, exercise = TRUE}

```

```{r the-question-2-hint-1, eval = FALSE}
library(primer.data)
```

```{r the-question-2-test, include = FALSE}
library(primer.data)
```

### 

A version of the data from the Open Policing project is available in the `stops` tibble.


### Exercise 3

After loading **primer.data** in your Console, type `?stops` in the Console, and paste in the Description below.

```{r the-question-3}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

`stops` contains data from over 400,000 traffic stops in New Orleans from July 1, 2011 to July 18, 2018. The dataset includes information about the date, time, and location of each stop, as well as demographic details about the driver and the outcomes of the stop.


### Exercise 4

Arrests in traffic stops are the broad topic of this tutorial. Given that topic, which variable in `stops` should we use as our outcome variable? 

```{r the-question-4}
question_text(NULL,
	message = "We should be using the `arrested` variable.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

`arrested` is a binary variable indicating whether or not an arrest was made during the traffic stop. 


### Exercise 5

Let's imagine a brand new treatment variable which **does not exists** in the data. This variable should be binary, meaning that it only takes 2 values (TRUE/FALSE, etc.). It should also, at least in theory, be manipulable. In other words, if the value of the variable is "X," or whatever, then it generates one potential outcome and if it is "Y," or whatever, it generates another potential outcome.

How might we manipulate this variable?

```{r the-question-5}
question_text(NULL,
	message = "Imagine a variable called `mask`, indicating whether or not the person is wearing a mask. We can manipulate this, at least in theory, by giving out masks to half the motorists that we plan on studying, and seeing if the mask affects their chances of getting arrested.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

There can be many good answers for a question like this. However, for the rest of this section, you should stick with our treatment variable of `mask`.

Recall that in a treatment variable, when manipulated, we look for the difference in arrest rate to see whether or not wearing a mask results in a higher chance of getting arrested.

All of this stuff is a *conceptual* framework we apply to the data. It is never inherent in the data itself.

The same data set can be used to create, separately, lots and lots of different models, both causal and predictive. We can just use different outcome variables and/or specify different treatment variables.


### Exercise 6

Essentially, we are asking:

> What is the causal effect of wearing a mask on getting arrested?

Given this choice of treatment variable `mask`, how many potential outcomes are there for each arrest? Explain why.

```{r the-question-6}
question_text(NULL,
	message = "There are 2 potential outcomes because the treatment variable `mask` takes on 2 posible values: either wearing a mask and getting arrested or not wearing one and getting arrested.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The same data set can be used to create, separately, lots and lots of different models, both causal and predictive. We can just use different outcome variables and/or specify different treatment variables. This is a *conceptual* framework we apply to the data. It is never inherent in the data itself.

### Exercise 7

In a few sentences, specify the two different values for the imaginary treatment variable `mask`, for a single unit, guess at the potential outcomes which would result, and then determine the causal effect for that unit given those guesses.

```{r the-question-7}
question_text(NULL,
	message = "For each person, there are only two possible values for arrested: 0 (meaning not arrested) and 1 (meaning arrested). So, there might be a person who, if she had been wearing a mask, would have been arrested, but, since she was not wearing a mask, she was not arrested. For a given arrest, assume that the value of the treatment variable might be `is wearing a mask` or `isn't wearing a mask`. If the person `is wearing a mask`, and gets arrested, but the person `isn't wearing a mask`, and does not get arrested. The causal effect on the outcome of a treatment of `mask = TRUE` versus `mask = FALSE` is getting arrested the difference between two potential outcomes --- which is the causal effect.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The definition of a causal effect is the difference between two potential outcomes. Of course, you can't just say that the causal effect is 10. The exact value depends on which potential outcome comes first in the subtraction and which second. There is, perhaps, a default sense in which the causal effect is defined as treatment minus control. 

Any causal connection means exploring the *within row* difference between two potential outcomes. We don't need to look at any other rows to have that conversation.

<!-- DK: Discuss how the causal effect is not a number, so you can't use "subtraction" when it says "difference." Review the relevant portion of the template_tutorial. -->

### Exercise 8

Let's consider a *predictive* model. Which variable in `stops` do you think might have an important connection to `arrested`? (If you don't see a reasonable variable in the data, you can just name a variable which *might have been* included in the data.)

```{r the-question-8}
question_text(NULL,
	message = "Let's consider the variable `race`. Does race have an effect on teh rate people get arrested at?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

If you don't care what Joe would have done in a counter-factual world in which we got a different treatment, if all you care about is predicting what Joe does *given the treatment he received*, then you just need a predictive model.

Using the same variable allows us to see the true differences between the two model types, based on similar questions and the same variables. Of course, you may have said something else, and that is completely fine, but we should stick with `mask` for the rest of this section.


### Exercise 9

Specify two different groups of people which have different values for race and which might have different average values for the arrest  

```{r the-question-9}
question_text(NULL,
	message = "Consider two groups, the first with a value for race of white and the second with value black. Those two groups might have different average values for the outcome variable.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In predictive models, do not use words like "cause," "influence," "impact," or anything else which suggests causation. The best phrasing is in terms of "differences" between groups of units with different values for a covariate of interest.

### Exercise 10

Write a predictive question which connects the outcome variable `arrested` to `race`, the covariate of interest for the rest of this tutorial.

```{r the-question-10}
question_text(NULL,
	message = "What is the difference in arrest rate between Black and White drivers adjusting for other variables?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The answer to this question is your "Quantity of Interest." 

Our Quantity of Interest might appear too specific, too narrow to capture the full complexity of the topic. There are many, many numbers in which we are interested, many numbers that we want to know. But we don't need to list them all here! We just need to choose one of them since our goal is just to have a specific number which helps to guide us in the creation of the Preceptor Table and, then, the model.


## Wisdom
### 

*The only true wisdom is in knowing you know nothing.* - Socrates

Recall our question:

> What is the difference in arrest rate between Black and White drivers adjusting for other variables?


### Exercise 1

In your own words, describe the key components of Wisdom when working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Open Policing project also has [visual maps](https://openpolicing.stanford.edu/explore/) regarding traffic stops. Sadly, there isn't one for New Orleans, but observe how different parts of Hartford, CT pull over different races of people!


### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, we can easily calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table does not include all the covariates which you will eventually including in your model. It only includes covariates which you need to answer your question.


### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem. Use words like "units," "outcomes," and "covariates."

```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 4

Create a Github repo called `stops`. Make sure to click the "Add a README file" check box.

Connect the `stops` Github repo to an R project on your computer. Name the R project `stops` also.

Select `File -> New File -> Quarto Document ...`. Provide a title (`"Stops"`) and an author (you). Render the document and save it as `stops.qmd`.

Edit the `.gitignore` by adding `*Rproj`. Save and commit this in the Git tab. Push the commit.

In the Console, run:

```         
show_file(".gitignore")
```

CP/CR.

```{r wisdom-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Remove everything below the YAML header from `stops.qmd` and render the file. `Command/Ctrl + Shift + K` renders the file, this automatically saves the file as well.


### Exercise 5

What are the units for this problem?

```{r wisdom-5}
question_text(NULL,
	message = "The units are the races of the people that have been pulled over.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Specifying the Preceptor Table forces us to think clearly about the units and outcomes implied by the question. The resulting discussion sometimes leads us to modify the question with which we started. No data science project follows a single direction. We always backtrack. There is always dialogue.


### Exercise 6

What is the outcome variable for this problem?

```{r wisdom-6}
question_text(NULL,
	message = "Our outcome variable is `arrested`.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

The outcome variable that we really care about is often not the outcome variable which our data includes. This compromise --- working with what we *have* rather than what we really *want* --- is a part of most data science work in the real world.

### Exercise 7

What are some covariates which you think might be useful for this problem, regardless of whether or not they might be included in the data?

```{r wisdom-7}
question_text(NULL,
	message = "We obviously need `race`. However, other characteristics like the person's age, sex, and the type of car they're driving might also affect `race`. It would also be ebenficial to see if the zone of the officer impacts the arrest rates, so we should also use the variable `zone`.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

For your information, the term "covariates" is used in at least three ways in data science. First, it is all the variables which might be useful, regardless of whether or not we have the data. Second, it is all the variables which we have data for. Third, it is the set of covariates which we end up using in the model.


### Exercise 8

What are the treatments, if any, for this problem?

```{r wisdom-8}
question_text(NULL,
	message = "Our key covariates would be `race`, `sex`, `age`, and `zone`.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Note that because we're creating a Predictive model, there is no treatment variable per se. However, we still have key covariates.


### Exercise 9

What moment in time does the Preceptor Table refer to?

```{r wisdom-9}
question_text(NULL,
	message = "Our Preceptor Table should represent traffic stops somewhere about the late 2000s to the mid 2010s for maximum compatibility with our data.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###


```{r}
plot_predictions(fit_arrested,
                      newdata = expand_grid(zone = unique(x$zone)),
                      condition = c("zone")) +
  coord_flip() +
  scale_x_reordered() +
  labs(x = "Zone", 
       y = "Estimated Arrest Probability", 
       title = "Predicted Arrest Rate of New Orleans Motorists by Zones",
       subtitle = "The bars represent the 95% Confidence Intervals.",
       caption = "Data from the Open Policing Project")
```

> *You can never look at the data too much. -- Mark Engerman*

### Exercise 10

Define causal effect. Note that the model in this tutorial is predictive, not causal. We just want to make sure you understand what a causal model is.

```{r wisdom-10}
question_text(NULL,
	message = "A causal effect is the difference between two potential outcomes.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

According to the Rubin Causal Model, there must be two (or more) potential outcomes for any discussion of causation to make sense. This is simplest to discuss when the treatment only has two different values, thereby generating only two potential outcomes. 

### Exercise 11

What is the fundamental problem of causal inference?

```{r wisdom-11}
question_text(NULL,
	message = "The fundamental problem of causal inference is that we can only observe one potential outcome.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If the treatment variable is continuous (like income), then there are lots and lots of potential outcomes, one for each possible value of the treatment variable. 

### Exercise 12

How does the motto "No causal inference without manipulation." apply in this problem?

```{r wisdom-12}
question_text(NULL,
	message = "The motto does not apply because this is a predictive, not causal, model.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 13

Describe in words the Preceptor Table for this problem.

```{r wisdom-13}
question_text(NULL,
	message = "On the far left, our Preceptor Table must have some way of idenitfying the people. Then, we would have a column called `arrested` (our outcome variable) and following this would be our covariate columns: `race`, `sex`, and `zone`.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table for this problem looks something like this:

```{r}
tibble(ID = c("1", "2", "...", "10", "11", "...", "105,852,176"),
       arrested = c("TRUE", "FALSE", "FALSE", "FALSE", "TRUE", "FALSE", "FALSE"),
       sex = c("M", "F", "...", "F", "F", "...", "M"),
       race = c("Black", "White", "...", "Black", "White", "Black", "Black"),
       zone = c("...", "B", "M", "...", "W", "...", "A"))|>

  gt() |>
  tab_header(title = "Preceptor Table") |>
  cols_label(ID = md("ID"),
             arrested = md("Arrested"),
             sex = md("Sex"),
             race = md("Race"),
             zone = md("Zone")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(ID))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"),
            locations = cells_column_labels(columns = c(ID))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Outcome", columns = c(arrested)) |>
  tab_spanner(label = "Covariate", columns = c(sex, race, zone))
```

Like all aspects of a data science problem, the Preceptor Table evolves as we work on the problem. For example, at the start, we aren't sure what right-hand side variables will be included in the model, so we are not yet sure which covariates must be in the Preceptor Table.


### Exercise 14

In your QMD, load the **tidyverse** and the **primer.data** packages in a new code chunk. Render the file.

Notice that the file does not look good because the code is visible and there are annoying messages. To take care of this, add `#| message: false` to remove all the messages in the `setup` chunk. Also add the following to the YAML header to remove all code echos from the whole file:

```         
execute: 
  echo: false
```

In the Console, run:

```         
show_file("XX.qmd", start = -5)
```

CP/CR.

```{r wisdom-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

### 

Render again. Everything looks nice because we have added code to make the file look better and more professional.


### Exercise 15

In your own words, define "validity" as we use the term.

```{r wisdom-15}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Validity is always about the *columns* in the Preceptor Table and the data. Just because columns from these two different tables have the same *name* does not mean that they are the same *thing*.

### Exercise 16

<!-- XX: For the validity questions, specifics matter. There is always a reason why the outcome column in the data is not the same as the outcome columns in the Preceptor Table, even in the case of simple sampling. For example, consider a historical question connecting sex with presidential vote. Our data is a subset of our Preceptor Table. We have information on a few thousand voters and want to draw inferences about millions of other voters in the same election. But, even in this case, the outcome columns are different. The data is who people told a survey who they voted for. The Preceptor Table is who people actually did vote for. Those are not the same things. If they, in your view, are different enough than validity is violated. -->

Provide one reason why the assumption of validity might not hold for the outcome variable `XX` or for one of the covariates. Use the words "column" or "columns" in your answer.

```{r wisdom-16}
question_text(NULL,
	message = "Although we know that an arrest in our dataset means an actual arrest, we don't know if that's the case with the Preceptor Table. What if arrests in the Preceptor Table also include detainments, which aren't full arrests? in this case, we would see a lot of entries for arrests in our `arrested` column in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In order to consider the Preceptor Table and the data to be drawn from the same population, the columns from one must have a *valid correspondence* with the columns in the other. Validity, if true (or at least reasonable), allows us to construct the Population Table, which is the first step in Justice.

Because we control the Preceptor Table and, to a lesser extent, the original question, we can adjust those variables to be “closer” to the data that we actually have. This is another example of the iterative nature of data science. If the data is not close enough to the question, then we check with our boss/colleague/customer to see if we can modify the question in order to make the match between the data and the Preceptor Table close enough for validity to hold.

Despite these potential problems, we will assume that validity holds since it, mostly (?), does.

### Exercise 17

Over the course of this tutorial, we will be creating a summary paragraph. The purpose of this exercise is to write the first two sentences of that paragraph.

The first sentence is a general statement about the overall topic, mentioning both the general class of the outcome variable and of at least one of the covariates. It is **not** connected to the initial "Imagine that you are XX" which set the stage for this project. That sentence can be rhetorical. It can be trite, or even a platitude. The purpose of the sentence is to let the reader know, gently, about our topic.

The second sentence does two things. First, it introduces the data source. Second, it introduces the specific question. The sentence can't be that long. Important aspects of the data include when/where it was gathered, how many observations it includes and the organization (if famous) which collected it.

Type your two sentences below.

<!-- XX: Example:  -->

<!-- XX: Sending postcards and other mailings to registered voters is a traditional part of US political campaigns. Using data from a 2006 experiment in Michigan, we seek to explore the likely causal effects of sending postcards to voters in the current gubernatorial campaign in Texas. -->


```{r wisdom-17}
question_text(NULL,
	message = "Using data from a study of New Orleans drivers, we seek to understand the relationship between driver race and the probabilty of getting arrested during a traffic stop.In particular, what is the probability of a Black motorist getting arrested during a traffic stop, and how does this compare to that of a White motorist?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Read our answer. It will not be the same as yours. You can, if you want, change your answer to incorporate some of our ideas. Do not copy/paste our answer exactly. Add your two sentences, edited or otherwise, to your QMD, `Command/Ctrl + Shift + K`, and then commit/push.


Note that in this step, we are converting the strings to titles, so that they remain capitalized throughout our graph. This is important as later, we will have to capitalize `"Black"` to match what we did in this step.

### Exercise 18

We have saved this pipeline to the following object:

```
x <- stops |>
  filter(race %in% c("black", "white")) |>
  mutate(race = str_to_title(race), 
         sex = str_to_title(sex))
```

Create a new code chunk in `stops.qmd`. Add `#| label: eda`. Copy/Paste the code for the `x` object. Render and run `tutorial.helpers::show_file("stops.qmd", chunk = "last")`. CP/CR.

```{r wisdom-18}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

We will use this cleaned up data in Courage when we make our model.

## Justice
### 

*Justice delayed is justice denied.* - William E. Gladstone


### Exercise 1

In your own words, name the four key components of Justice for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Justice is about concerns that you (or your critics) might have, reasons why the model you create might not work as well as you hope. 

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Population Table is almost always much bigger than the combination of the Preceptor Table and the data because, if we can really assume that both the Preceptor Table and the data are part of the same population, than that population must cover a broad universe of time and units since the Preceptor Table and the data are, themselves, often far apart from each other.

### Exercise 3

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-3}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability is all about *time*. Is the relationship among the columns in the Population Table stable over time? In particular, is the relationship --- which is another way of saying "mathematical formula" --- at the time the data was gathered the same as the relationship at the (generally later) time references by the Preceptor Table.


### Exercise 4

Provide one reason why the assumption of stability might not be true in this case.

```{r justice-4}
question_text(NULL,
	message = "We don't know the exact time period of the Preceptor Table, so we don't know if any laws were passed between the time periods of both data sources that affected the basis of arrests during traffic stops. Therefore, we don't know if the arrests reported in the `arrested` column in both data sources were made on the same basis and whether or not both data sources had the same arrest rate.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A change in time or the distribution of the data does not, in and of itself, demonstrate a violation of stability. Stability is about the parameters: $\beta_0$, $\beta_1$ and so on. Stability means these parameters are the same in the data as they are in the population as they are in the Preceptor Table.

### Exercise 5

We use our data to make inferences about the overall population. We use information about the population to make inferences about the Preceptor Table: `Data -> Population -> Preceptor Table`. In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-5}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationships among the rows in the Population Table. The first is between the data and the other rows. The second is between the other rows and the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case.

### Exercise 6

We do not use the data, directly, to estimate missing values in the Preceptor Table. Instead, we use the data to learn about the overall population. Provide one reason, involving the relationship between the data and the population, for why the assumption of representativeness might not be true in this case.

```{r justice-6}
question_text(NULL,
	message = "The dataset `stops` is a heavily modified version of the data from the actual study, and therefore has left out nearly 3.1 million entries from the real data, shortening it to roughly 400,000 entries. The deletion of the entries may have led to a misrepresentation of the population, in that a lot of the current data may only be fr0om select areas with select conditions present, and could be from biased officers who are more likely to arrest drivers compared to other officers in the zone. This would mess up our final predictions because it would be providing values that are unrealistic to the area, causing our entire model to be unreastic.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The reason that representativeness is important is because, when it is violated, the estimates for the model parameters might be biased. 

### Exercise 7

We use information about the population to make inferences about the Preceptor Table. Provide one reason, involving the relationship between the population and the Preceptor Table, for why the assumption of representativeness might not be true in this case.


```{r justice-7}
question_text(NULL,
	message = "Our data may not be collected fairly, in that some of the data could have just been collected from corrupt officers who would be more likely to arrest drivers than other officers in the zone. The opposite could be inferred as well. This, again, would mess up our final predictions because it would be providing values that are unrealistic to the area, causing our entire model to be unreastic.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 8

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-8}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This assumption is only relevant for causal models. We describe a model as "confounded" if this is not true. The easiest way to ensure unconfoundedness is to assign treatment randomly.


### Exercise 9

Summarize the state of your work so far in two or three sentences. Make reference to the data you have and to the question you are trying to answer. Feel free to copy from your answer at the end of the Wisdom Section. Mention one specific problem which casts doubt on your approach. 

```{r justice-9}
question_text(NULL,
	message = "Using data from a study of New Orleans drivers, we seek to understand the relationship between driver race and the probabilty of getting arrested during a traffic stop. However, our data from both our Preceptor Table and our dataset may not fully represent the population as both may not be from the same time frame and some of our data may come from biased officers, who may target certain groups of individuals.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit the summary paragraph in `stops.qmd` as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`, and then commit/push.


## Courage
### 

*Courage is the commitment to begin without any guarantee of success.* - Johann Wolfgang von Goethe


Recall that we ar mainly comparing the difference between the two values of `race` (a `character` column) on our outcome variable `arrested` (an `integer` column). We will also be analyzing the affects of `sex` and `zone`, which are `character` variables and `age`, which is an `integer` variable.


### Exercise 1

In your own words, describe the components of the virtue of Courage for analyzing data.

```{r courage-1}
question_text(NULL,
	message = "Courage starts with math, explores models, and then creates the data generating mechanism.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A statistical model consists of two parts: the *probability family* and the *link function*. The probability family is the probability distribution which generates the randomness in our data. The link function is the mathematical formula which links our data to the unknown parameters in the probability distribution. 

### Exercise 2

Load the **tidymodels** package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(tidymodels)
```

### 

Because `arrested` is a binary variable, we assume that the outcome of getting arrested (or not) is produced from a Bernoulli distribution.

$$ arrested_i  \sim Bernoulli(\rho) $$

Note that "binomial" is another, more common, word for Bernoulli.


### Exercise 3

Load the **broom** package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(broom)
```

### 

Because we are using a Bernoulli distribution, the link function is logit. That is:

$$\rho = \frac{1}{1 + e^{-(\beta_0 +\beta_1 x_1 + \dots)}}$$

### Exercise 4

<!-- XX: The first (of three) versions of the model is a mathematical formula which includes parameters like \beta_1 as well as the error term. This model does not, yet, specify exactly which variables are included on the left-hand side, much less any transformations which are required.  -->

Use AI to come up with a $\LaTeX$ representation of the mathematical structure of the model, with $Y$ as the dependent variable and $X_1$, $X_2$ and so on as the independent variables. This version will not have the values of any parameters since we have not, yet, estimated them. Confirm that the $\LaTeX$ code works by placing it in your QMD and then rendering. Paste that $\LaTeX$ code below.

```{r courage-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###
Our answer: 
$$P(Y = 1) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_n X_n)}}$$

with $Y \sim \text{Bernoulli}(\rho)$, where $\rho$ is the probability above.

### Exercise 5

Add `library(tidymodels)` and `library(broom)` to the `setup` code chunk in `stops.qmd`. `Command/Ctrl + Shift + K`.

At the Console, run:

```
tutorial.helpers::show_file("stops.qmd", pattern = "library")
```

CP/CR.

```{r courage-5}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Having decided on the basic mathematical structure of the model, a choice mostly driven by the distribution of our outcome variable, we now turn toward estimating the model.

### Exercise 6

Because our outcome variable is binary, start to create the model by using `linear_reg(engine = "lm")`.

```{r courage-6, exercise = TRUE}

```

```{r courage-6-hint-1, eval = FALSE}
linear_reg(engine = "...")
```

```{r courage-6-test, include = FALSE}
linear_reg(engine = "lm")
```

**Note:** This will give you an error that we will be fixing later.

### 

The *[tidymodels](https://www.tidymodels.org/)* framework is the most popular one in the R world for estimating models. *[Tidy Modeling with R](https://www.tmwr.org/)* by Max Kuhn and Julia Silge is a great introduction.

 <!--SU: based on teh template tutorial we dont need this formula anymore correct?-->
### Exercise 7

Continue the pipe to `fit(arrested ~ sex, data = x)`.

```{r courage-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-7-hint-1, eval = FALSE}
... |> 
  fit(arrested ~ ..., data = ...)
```

```{r courage-7-test, include = FALSE}
linear_reg() |>
  set_engine("lm") |>
  fit(arrested ~ sex, data = x)
```

### 

Recall that a categorical variable (whether character or factor) like `sex` is turned into a $0/1$ "dummy" variable which is then re-named something like $sex{Male}$. After all, we can't have words --- like "Male" or "Female" --- in a mathematical formula, hence the need for dummy variables.

### Exercise 8

Continue the pipe with `tidy(conf.int = TRUE)`.

```{r courage-8, exercise = TRUE}

```

```{r courage-8-hint-1, eval = FALSE}
linear_reg() |>
  set_engine("lm") |>
  fit(arrested ~ sex, data = x) |>
  tidy(... = TRUE)
```

```{r courage-8-test, include = FALSE}
linear_reg() |>
  set_engine("lm") |>
  fit(arrested ~ sex, data = x) |>
  tidy(conf.int = TRUE)
```

### 

The meaning of the magnitude of the coefficient values is much harder to interpret in logistic models than in linear models. But the fact that the coefficient of sexMale is positive means that men are more likely to be arrested than women, and the fact that the confidence interval excludes zero means that we can be fairly certain of that claim.

### Exercise 9

Change the call to `fit()` to `fit(arrested ~ race, data = XX)`.

```{r courage-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-9-hint-1, eval = FALSE}
linear_reg() |>
  set_engine("lm") |>
  fit(arrested ~ ..., data = x) 
```

```{r courage-9-test, include = FALSE}
linear_reg() |>
  set_engine("lm") |>
  fit(arrested ~ race, data = x) 
```

###

The same dummy variable approach applies to a categorical covariate with $N$ values. Such cases produce $N-1$ dummy $0/1$ variables. The presence of an intercept in most models means that we can't have $N$ categories. The "missing" category is incorporated into the intercept. If `race` has three values --- "black", "hispanic", and "white" --- the model creates two 0/1 dummy variables, giving them names like $race_{hispanic}$ and $race_{white}$. The results for the *first* category are included in the intercept, which becomes the reference case, relative to which the other coefficients are applied.

### Exercise 10

Add back the call to `tidy(conf.int = TRUE)`.

```{r courage-10, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-10-hint-1, eval = FALSE}
linear_reg() |>
  set_engine("lm") |>
  fit(arrested ~ race, data = x) |>
   tidy(conf.int = TRUE)

```

```{r courage-10-test, include = FALSE}
linear_reg() |>
  set_engine("lm") |>
  fit(arrested ~ race, data = x) |>
  tidy(conf.int = TRUE)
```

### 

White respondents, the group for which a dummy variable is created here (raceWhite), are less likely to be arrested than respondents of other races. The coefficient is −0.0438, and the 95% confidence interval ranges from −0.0469 to −0.0408, which does not include 0. That means this difference is statistically significant — we can be fairly confident it's not due to random chance.

The exact size of the coefficient is harder to interpret since we’re working with a logistic model, but the direction is clear: identifying as white is associated with a lower probability of getting arrested. 

### Exercise 11

Change the call to `fit()` to `fit(arrested ~ sex + race, data = x)`.

```{r courage-11, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-11-hint-1, eval = FALSE}
... |> 
  fit(... ~ sex + ..., ... = x) |>
  ...
```

```{r courage-11-test, include = FALSE}
linear_reg(engine = "lm") |> 
  fit(arrested ~ sex + race, data = x) |> 
  tidy(conf.int = TRUE)
```

### 

````
  term        estimate std.error statistic   p.value conf.low conf.high
  <chr>          <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl>
1 (Intercept)   0.204    0.00130     157.  0           0.201     0.206 
2 sexMale       0.0631   0.00149      42.4 0           0.0601    0.0660
3 raceWhite    -0.0450   0.00154     -29.1 2.40e-186  -0.0480   -0.0419
````

The more variables we add, the more difficult it is to interpret the meaning of any particular coefficient. But interpretation also becomes less important. We don't really care about coefficients. We care about using our model to estimate quantities of interest.

In this case, the coefficient for `raceWhite` is slightly more negative than before, presumably because we’ve now included `sex`, and men are somewhat more likely to be arrested. By adjusting for `sex`, we’re isolating the effect of race more precisely — and the effect of being white remains statistically significant and negative.

### Exercise 12

Change the formula in the call to `fit()` to `arrested ~ sex + race*zone`.

```{r courage-12, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-12-hint-1, eval = FALSE}
... |> 
  fit(arrested ~ sex + race*zone, data = x) |>
  ...
```

```{r courage-12-test, include = FALSE}
linear_reg(engine = "lm") |> 
  fit(arrested ~ sex + race*zone, data = x) |> 
  tidy(conf.int = TRUE)
```

### 

````
 term        estimate std.error statistic  p.value conf.low conf.high
   <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>
 1 (Intercept)  0.177     0.00346    51.3   0         0.171     0.184  
 2 sexMale      0.0614    0.00149    41.4   0         0.0585    0.0644 
 3 raceWhite   -0.0445    0.00634    -7.02  2.25e-12 -0.0570   -0.0321 
 4 zoneB        0.0146    0.00513     2.85  4.42e- 3  0.00455   0.0247 
 5 zoneC        0.00610   0.00426     1.43  1.52e- 1 -0.00225   0.0145 
 6 zoneD        0.0781    0.00418    18.7   6.20e-78  0.0699    0.0862 
 7 zoneE        0.00190   0.00465     0.409 6.82e- 1 -0.00721   0.0110 
 8 zoneF       -0.00271   0.00483    -0.561 5.75e- 1 -0.0122    0.00675
 9 zoneG        0.0309    0.00500     6.18  6.46e-10  0.0211    0.0407 
10 zoneH        0.0757    0.00479    15.8   3.42e-56  0.0663    0.0851 
````

We included the interaction between race and zone because the effect of race on the likelihood of being arrested may differ depending on the zone. For example, the coefficient for raceWhite:zoneD is negative and its confidence interval excludes zero, suggesting that white individuals may be treated differently in that zone compared to others. And because we’ve included interaction terms, we keep the main effects for both race and zone as well, even if not all of them are individually significant.


### Exercise 13

Behind the scenes of this tutorial, an object called `fit_stops` has been created which is the result of the code above. Type `fit_years` and hit "Run Code." This generates the same results as using `print(fit_years)`.


```{r courage-13, exercise = TRUE}

```

```{r courage-13-hint-1, eval = FALSE}
fit_stops
```

```{r courage-13-test, include = FALSE}
# fit_stops
```

### 

In data science, **we deal with words, math, and code, but the most important of these is code.** We created the mathematical structure of the model and then wrote a model formula in order to estimate the unknown parameters. 

### Exercise 14

### Exercise 15

Load the **[easystats](https://easystats.github.io/easystats/)** package.

```{r courage-15, exercise = TRUE}

```

```{r courage-15-hint-1, eval = FALSE}
library(...)
```

```{r courage-15-test, include = FALSE}
library(easystats)
```

###

We don't add **easystats** to the QMD because we are only using it for an interactive check of our fitted model. However, the [easystats ecosystem](https://easystats.github.io/easystats/) has a variety of interesting functions and packages which you might want to explore.

### Exercise 16

### Exercise 17

In the Console, run `check_predictions(extract_fit_engine(fit_stops))`. CP/CR.

```{r courage-17, exercise = TRUE}

```

```{r courage-17-hint-1, eval = FALSE}
check_predictions(extract_fit_engine(...))
```

```{r courage-17-test, include = FALSE}
check_predictions(extract_fit_engine(fit_stops))
```

###

```{r}
check_predictions(extract_fit_engine(fit_stops))
```

The purpose of `check_predictions()` is to compare your actual data (in green) with data that has been simulated from your fitted model, i.e., from your data generating mechanism. If your DGM is reasonable, then data simulated from it should not look too dissimilar from your actual data. Of course, it won't look exactly the same because of randomness, both in the world and in your simulation. But the actual data should be within the range of outcomes that your DGM simulates with `check_predictions()`.

### Exercise 18

Ask AI to create $\LaTeX$ code for this model, including our variable names and estimates for all the coefficients. Because this is a fitted model, the dependent variable will have a "hat" and the formula will not include an error term. 

Add the code to your QMD. `Cmd/Ctrl + Shift + K`.

Make sure the resulting display looks good. For example, you don't want an absurd number of figures to the right of the decimal. If the model is too long, you will need to spread it across several lines. You may need to go back-and-forth with the AI a few times.

Once the $\LaTeX$ code looks good, paste it below.

```{r courage-18}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

###

Our formula looks like:

$$
\widehat{\text{arrested}} = 0.177 
+ 0.0614 \cdot \text{sex}_{\text{Male}} 
- 0.0445 \cdot \text{race}_{\text{White}} 
+ 0.0146 \cdot \text{zone}_{\text{B}} 
+ 0.00610 \cdot \text{zone}_{\text{C}} 
+ 0.0781 \cdot \text{zone}_{\text{D}} 
+ 0.00190 \cdot \text{zone}_{\text{E}} 
- 0.00271 \cdot \text{zone}_{\text{F}} 
+ 0.0309 \cdot \text{zone}_{\text{G}} 
+ 0.0757 \cdot \text{zone}_{\text{H}} 
+ \text{(interaction terms for race and zone)}
$$

It was created with:

````
$$
\widehat{\text{arrested}} = 0.177 
+ 0.0614 \cdot \text{sex}_{\text{Male}} 
- 0.0445 \cdot \text{race}_{\text{White}} 
+ 0.0146 \cdot \text{zone}_{\text{B}} 
+ 0.00610 \cdot \text{zone}_{\text{C}} 
+ 0.0781 \cdot \text{zone}_{\text{D}} 
+ 0.00190 \cdot \text{zone}_{\text{E}} 
- 0.00271 \cdot \text{zone}_{\text{F}} 
+ 0.0309 \cdot \text{zone}_{\text{G}} 
+ 0.0757 \cdot \text{zone}_{\text{H}} 
+ \text{(interaction terms for race and zone)}
$$
````

Note the differences. First, we have replaced the parameters with our best estimates. Second, we have dropped the error term because this is a formula for predicting the value of our outcome variable. Third, the left-hand side variable is $\widehat{\text{arrested}}$ instead of $\text{arrested}$ because this formula generates our estimated arrested. A hat indicates an estimated value.

**This is our data generating mechanism.**

A data generating mechanism is just a formula, something which we can write down and implement with computer code.

### Exercise 19

Create a new code chunk in your QMD. Add a code chunk option: `#| cache: true`. Copy/paste the code from above for estimating the model into the code chunk, assigning the result to `fit_stops`. 

`Command/Ctrl + Shift + K`. It may take some time to render your QMD, depending on how complex your model is. But, by including `#| cache: true` you cause Quarto to cache the results of the chunk. The next time you render your QMD, as long as you have not changed the code, Quarto will just load up the saved fitted object.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", start = -8)
```

CP/CR.

```{r courage-19}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 8)
```

### 

To confirm, `Command/Ctrl + Shift + K` again. It should be quick.

### Exercise 20

Add `*_cache` to `.gitignore` file. Cached objects are often large. They don't belong on Github.

At the Console, run:

```
tutorial.helpers::show_file(".gitignore")
```

CP/CR.

```{r courage-20}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

###

Because of the change in your `.gitignore` (assuming that you saved it), the cache directory should not appear in the Source Control panel because Git is ignoring it, as instructed. Commit and push. 

### Exercise 21

In the Console, run `tidy()` on `fit_stops` with the argument `conf.int` set equal to `TRUE`. The returns 95% intervals for all the parameters in our model.

```{r courage-21, exercise = TRUE}

```

```{r courage-21-hint-1, eval = FALSE}
tidy(..., conf.int = ...)
```

```{r courage-21-test, include = FALSE}
# tidy(fit_stops, conf.int = TRUE)
```

### 

`tidy()` is part of the [**broom**](https://broom.tidymodels.org/) package, used to summarize information from a wide variety of models.

### Exercise 22

Create a new code chunk in your QMD. Ask AI to help you make a nice looking table from the tibble which is returned by `tidy()`. You don't have to include all the variables which `tidy()` produces. We often just show the estimate and the confidence intervals.

Insert that code into the QMD. 

`Command/Ctrl + Shift + K`. 

Make sure it works. You might need to add some new libraries, e.g., **[tinytable](https://vincentarelbundock.github.io/tinytable/)**, **[knitr](https://yihui.org/knitr/)**, **[gt](https://gt.rstudio.com/)**, **[kableExtra](https://haozhu233.github.io/kableExtra/)**, **[flextable](https://davidgohel.github.io/flextable/)**, **[modelsummary](https://modelsummary.com/)**, et cetera, to the `setup` code chunk, if you use any functions from these packages, all of which have strengths and weaknesses for making tables.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", end = -10)
```

CP/CR.

```{r courage-22}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 12)
```

###


At the very least, your table should include a title and a caption with the data source. The more you use AI, the better you will get at doing so.

### Exercise 23

Add a sentence to your project summary. 

Explain the structure of the model. Something like: "I/we model XX [the concept of the outcome, not the variable name], [insert description of values of XX], as a [linear/logistic/multinomial/ordinal] function of XX [and maybe other covariates]." 

<!-- DK: Add discussion of easystats::report()? -->

Recall the beginning of our version of the summary:

> [XX: Include what we suggested at the end of Justice.]

```{r courage-23}
question_text(NULL,
	message = "Using data from a study of New Orleans drivers, we seek to understand the relationship between driver race and the probabilty of getting arrested during a traffic stop. However, our data from both our Preceptor Table and our dataset may not fully represent the population as both may not be from the same time frame and some of our data may come from biased officers, who may target certain groups of individuals. However, these concerns don't appear to be valid in a substantial manner in either dataset, allowing us to continue in our process. We modeled `arrested` as a linear function of both `sex` and the product of `race` and `zone`. From this, we examined that Males are less likely of getting arrested than Females.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Read our answer. It will not be the same as yours. You can, if you want, change your answer to incorporate some of our ideas. Do not copy/paste our answer exactly. Add your two sentences, edited or otherwise, to the summary paragraph portion of your QMD. `Command/Ctrl + Shift + K`, and then commit/push.

## Temperance
### 

*Temperance is a bridle of gold; he, who uses it rightly, is more like a god than a man.* - Robert Burton

### Exercise 1

In your own words, describe the use of Temperance in data science.

```{r temperance-1}
question_text(NULL,
	message = "Temperance uses the data generating mechanism to answer the questions with which we began. Humility reminds us that this answer is always a lie. We can also use the DGM to calculate many similar quantities of interest, displaying the results graphically.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Courage gave us the data generating mechanism. Temperance guides us in the use of the DGM — or the “model” — we have created to answer the questions with which we began. We create posteriors for the quantities of interest. We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.

### Exercise 2

Before using the DGM, we should make sure that we can interpret it.

Recall the values for the parameters in our data generating mechanism:

Write a sentence interpreting the 0.06 estimate for sexMale

```{r}
# fit_stops |> 
# 	tidy(conf.int = TRUE) |> 
#	select(term, estimate, conf.low, conf.high)
```

```{r temperance-2}
question_text(NULL,
	message = "When comparing men with women, men have a 0.06 higher value for arrested, meaning that they are more likely to get arrested, relative to women, conditional on the other variables in the model.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

### Exercise 3

Write a sentence interpreting the -0.04 estimate for raceWhite

```{r}
# fit_stops |> 
# 	tidy(conf.int = TRUE) |> 
#	select(term, estimate, conf.low, conf.high)
```

```{r temperance-3}
question_text(NULL,
	message = "When comparing White people with Black people, White people have a lower value for arrested, meaning that they are less likely to get arrested, relative to Black people conditional on the other variables in the model.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

### Exercise 4

Write a sentence interpreting the 0.18 estimate for Intercept

```{r}
# fit_stops |> 
# 	tidy(conf.int = TRUE) |> 
#	select(term, estimate, conf.low, conf.high)
```

```{r temperance-4}
question_text(NULL,
	message = "The intercept represents the baseline predicted value of the outcome when all the predictor variables are at their reference levels. In our case this means that there is a 18% chance that a Black female living in Zone A will get arrested",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

 Dummy variables must always be interpreted in the context of the base value for that variable, which is generally included in the intercept. For example, the base value here is "black femal" (The base value is the first alphabetically by default for character variables. However, if it is a factor variable, you can change that by setting the order of the levels by hand.)

### Exercise 5


In the end, we don't really care about parameters, much less how to interpret them. Parameters are *imaginary*, like unicorns. We care about answers to our questions. Parameters are tools for answering questions. They aren't interesting in-and-of themselves. *In the modern world, all parameters are nuisance parameters.* 

Load the [**marginaleffects**](https://marginaleffects.com/) package.

```{r temperance-5, exercise = TRUE}

```

```{r temperance-5-hint-1, eval = FALSE}
library(...)
```

```{r temperance-5-test, include = FALSE}
library(marginaleffects)
```

### 

We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.

### Exercise 6

What is the general topic we are investigating? What is the specific question we are trying to answer? 

```{r temperance-6}
question_text(NULL,
	message = "We are generally investigating the likelihood of getting arrested during a Traffic Stop in New Orleans. We are specifically interested in the probabilty of arrest for a Black driver.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Data science projects almost always begin with a broad topic of interest. Yet, in order to make progress, we need to drill down to a specific question. This leads to the creation of a data generating mechanism, which can now be used to answer lots of questions, thus allowing us to explore the original topic broadly.

### Exercise 7

Run this code:

```
plot_predictions(fit_stops, condition = c("sex", "race"))
```       

```{r temperance-7, exercise = TRUE}

```

```{r temperance-7-test, include = FALSE}

```

### 

This plot shows predicted probabilities of being arrested by sex and race, with vertical lines representing uncertainty (95% confidence intervals). Black males have the highest predicted probability (around 0.32), and White females the lowest (around 0.24). While the estimates are fairly precise—indicated by the short confidence intervals—there is still some overlap, especially between Black and White males, suggesting some uncertainty in how distinct those groups are.

### Exercise 8

<!-- XX: After you have run several marginaleffects functions, it is time to finish up, to create your final plot. In this question, have them run the final marginaleffects function, the one that will form the basis of the final plot. -->

Run this code:

```
plot_predictions(fit_stops$fit,
                 newdata = "balanced",
                 condition = c("zone", "race", "sex"),
                 draw = FALSE) |> as_tibble() |> 
  group_by(zone, sex) |>
  mutate(sort_order = estimate[race == "Black"]) |>
  ungroup() |>
  mutate(zone = reorder_within(zone, sort_order, sex)) |>
  ggplot(aes(x = zone, 
             color = race)) +
  geom_errorbar(aes(ymin = conf.low, 
                    ymax = conf.high), 
                width = 0.2,
                position = position_dodge(width = 0.5)) +
  geom_point(aes(y = estimate), 
             size = 1, 
             position = position_dodge(width = 0.5)) +
  facet_wrap(~ sex, scales = "free_x") +
  scale_x_reordered() +
  theme(axis.text.x = element_text(size = 8)) +
  scale_y_continuous(labels = percent_format())
```       

```{r temperance-8, exercise = TRUE}

```

```{r temperance-8-test, include = FALSE}

```

### 

This plot shows The Predicted Arrest Rate of New Orleans Motorists by Zones, by Zone and Estimated Arrest Probability. From this plot we can see that Black motorists are more likely to get arrested during a traffic stop than White motorists.

### Exercise 9

Work interactively with your QMD to make a beautiful version of this plot. Your title should highlight the key variables. Your subtitle should describe the key takeaway, the sentence/conclusion which readers will, you hope, remember. Your caption should mention the data source. Your axis labels should look nice.

This plot is not directly connected to your question. It answers lots of questions! It might be used by lots of different people. 

Copy the code for your plot here: `plot_predictions(fit_stops$fit,
                 newdata = "balanced",
                 condition = c("zone", "race", "sex"),
                 draw = FALSE) |> as_tibble() |> 
  group_by(zone, sex) |>
  mutate(sort_order = estimate[race == "Black"]) |>
  ungroup() |>
  mutate(zone = reorder_within(zone, sort_order, sex)) |>
  ggplot(aes(x = zone, 
             color = race)) +
  geom_errorbar(aes(ymin = conf.low, 
                    ymax = conf.high), 
                width = 0.2,
                position = position_dodge(width = 0.5)) +
  geom_point(aes(y = estimate), 
             size = 1, 
             position = position_dodge(width = 0.5)) +
  facet_wrap(~ sex, scales = "free_x") +
  scale_x_reordered() +
  theme(axis.text.x = element_text(size = 8)) +
  scale_y_continuous(labels = percent_format())`

```{r temperance-9}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 20)
```

###

Data science often involves this-back-and-forth style of work. First, we need to make a single chunk of code, in this case, a new plot, work well. This requires interactive work between the QMD and the Console. Second, we need to ensure that the entire QMD runs correctly on its own.

### Exercise 10

Finalize the new graphics code chunk in your QMD.

`Command/Ctrl + Shift + K` to ensure that it all works as intended. Don't forget to add `library(marginaleffects)` to your `setup` code chunk.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", start = -8)
```

CP/CR.

```{r temperance-10}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 10)
```

### 

Always [remember](https://en.wikipedia.org/wiki/Map%E2%80%93territory_relation): *The map is not the territory.* A beautiful graphic tells a story, but that story is always an imperfect representation of reality. Our models depend on assumptions, assumptions which are never completely true.

### Exercise 11

Write the last sentence of your summary paragraph. It describes at least one quantity of interest (QoI) and provides a measure of uncertainty about that QoI. (It is OK if this QoI is not the one that you began with. The focus of a data science project often changes over time.)

```{r temperance-11}
question_text(NULL,
	message = "Using data from a study of New Orleans drivers, we seek to understand the relationship between driver race and the probabilty of getting arrested during a traffic stop. However, our data from both our Preceptor Table and our dataset may not fully represent the population as both may not be from the same time frame and some of our data may come from biased officers, who may target certain groups of individuals. However, these concerns don't appear to be valid in a substantial manner in either dataset, allowing us to continue in our process. We modeled `arrested` as a linear function of both `sex` and the product of `race` and `zone`. From this, we examined that Males are less likely of getting arrested than Females. Focusing on our question, there is no uncertainty associated with our estimate because it, itself, is an expression of uncertainty. We estimate that the probaibility of a Black driver in New Orleans getting arrested during a traffic stop is roughly 25%, compared to roughly 20% for White drivers.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Add a final sentence to your summary paragraph in your QMD as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`.

### Exercise 12

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval, if you think either might be warranted.

```{r temperance-12}
question_text(NULL,
	message = "Based on all of the errors in our data that we collected during Justice, our original data source to base our model on was already flawed. Additionally, our model can only predict estimates on paper, based on an ideal world. It doesn't account for many factors of the real world that we, ourselves, can't even describe. However, our estimate was formed to the best of our abilities given the data on hand, and all I would do to modify it would be to modify the confidence intervals: I would keep the upper confidence interval the same, but would singifcantly decrease the lower confidence interval to roughly 15%-17% to account for the future, where the values would most likely decrease based on the pattern of racism in the US decreasing over time.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Always go back to your Preceptor Table, the information which, if you had it, would make answering your question easy. In almost all real world cases, the Preceptor Table and the data are fairly different, not least because validity never holds perfectly. So, even a perfectly estimated statistical model is rarely as useful as we might like.

### Exercise 13

Rearrange the material in your QMD so that the order is graphic, followed by the paragraph. Doing so, of course, requires sensible judgment. For example, the code chunk which creates the fitted model must occur before the chunk which creates the graphic. You can keep or discard the math and any other material at your own discretion.

`Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd")
```

CP/CR.

```{r temperance-13}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 30)
```

### 

This is the version of your QMD file which your teacher is most likely to take a close look at.

### Exercise 14

Publish your rendered QMD to GitHub Pages. Copy/paste the resulting url below.

```{r temperance-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Commit/push everything.

### Exercise 15

Copy/paste the url to your Github repo.

```{r temperance-15}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

We can never know all the entries in the Preceptor Table. That knowledge is reserved for God. If all our assumptions are correct, then our DGM is true, it accurately describes the way in which the world works. There is no better way to predict the future, or to model the past, than to use it. Sadly, this will only be the case with toy examples involving things like coins and dice. We hope that our DGM is close to the true DGM but, since our assumptions are never perfectly correct, our DGM will always be different. The estimated magnitude and importance of that difference is a matter of judgment.

The world confronts us. Make decisions we must.

## Summary
### 

This tutorial covered topics related to [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 


```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
