---
title: Ordered Factors
author: David Kane, Tanay Janmanchi, and Gia Khang
tutorial:
  id: ordered-factors
output:
  learnr::tutorial:
    progressive: yes
    allow_skip: yes
runtime: shiny_prerendered
description: 'Tutorial: #121 for Preceptor''s Primer'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(gt)

library(tidyverse)
library(primer.data)
library(tidymodels)
library(broom)
library(marginaleffects)


knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

x <- colleges |>
  select(tuition, grad_rate, selectivity) |>
   filter(tuition > 2)

fit_colleges <- linear_reg() |>
    set_engine("lm") |>
    fit(grad_rate ~ tuition + selectivity, 
        data = x)

```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

## Introduction
### 

This tutorial supports [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

The world confronts us. Make decisions we must.

Imagine that you are a data scientist working for a non-profit organization that helps students find the best college for them. You have been tasked with creating a model that predicts the graduation rate of colleges based on their tuition fee. 

## The Question
### 

*The important thing is not to stop questioning.* - Albert Einstein


### Exercise 1

Load [**tidyverse**](https://www.tidyverse.org/) package.

```{r the-question-1, exercise = TRUE}

```

```{r the-question-1-hint-1, eval = FALSE}
library(tidyverse)
```

```{r the-question-1-test, include = FALSE}
library(tidyverse)
```

### 

The data that we will use was downloaded from Opportunity Insights. Based at Harvard University, Opportunity Insights focuses on using big data to understand and improve economic mobility. They have many downloadable data sets, check it out for yourself [here!](https://opportunityinsights.org/data/)

### Exercise 2

Load the [**primer.data**](https://ppbds.github.io/primer.data/) package.

```{r the-question-2, exercise = TRUE}

```

```{r the-question-2-hint-1, eval = FALSE}
library(primer.data)
```

```{r the-question-2-test, include = FALSE}
library(primer.data)
```

### 

A version of the data from Opportunity Insights is available in the `colleges` tibble.

### Exercise 3

After loading **primer.data** in your Console, type `?colleges` in the Console, and paste in the Description below.

```{r the-question-3}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

`colleges` contains data from over 900 colleges and universities in the United States. These draw primarily on data from the Department of Education’s (DOE) [IPEDS](https://nces.ed.gov/ipeds/) database in 2013 and the College Scorecard. 


### Exercise 4

Colleges are the broad topic of this tutorial. Given that topic, which variable in `colleges` should we use as our outcome variable? 

```{r the-question-4}
question_text(NULL,
	message = "We will use `grad_rate`.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

`grad_rate` is the rate of graduation at that college/university from the year 2013.

There are many acceptable answers that we could measure, but, for this tutorial we will stick with `grad_rate`.

### Exercise 5

Let's imagine a brand new variable which **does not exist** in the data. This variable should be binary, meaning that it only takes on one of two values. It should also, at least in theory, be manipulable. In other words, if the value of the variable is "X," or whatever, then it generates one potential outcome and if it is "Y," or whatever, it generates another potential outcome.

How might we manipulate this variable?


```{r the-question-5}
question_text(NULL,
	message = "We could create a new variable called `impv_food` where we could send funds to certain schools for the purpose of improving their food, for which `1` means funds were sent and `0` means funds were not send. We could compare the graduation rates after 5 years and see if improving food had any effect on it.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Any data set can be used to construct a causal model as long as there is at least one covariate that we can, at least in theory, manipulate. It does not matter whether or not anyone did, in fact, manipulate it. 


### Exercise 6

Given our choice of treatment variable `impv_food`, how many potential outcomes are there for each college? Explain why.


```{r the-question-6}
question_text(NULL,
	message = "There are 2 potential outcomes because the treatment variable `impv_food` takes on 2 posible values: a college improved their food or a college didn't improve their food.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Any data set can be used to construct a predictive model. 

The same data set can be used to create, separately, lots and lots of different models, both causal and predictive. We can just use different outcome variables and/or specify different treatment variables. All of this stuff is a *conceptual* framework we apply to the data. It is never inherent in the data itself.

### Exercise 7

In a few sentences, specify the two different values for the imaginary treatment variable `impv_food`, for a single unit, guess at the potential outcomes which would result, and then determine the causal effect for that unit given those guesses.

```{r the-question-7}
question_text(NULL,
	message = "For a given college, assume that the value of the treatment variable might be 1 or 0. If the college gets 1 (meaning they improved their food), then the graduation rate (`grad_rate`) would be 0.85. If the college gets o (meaning they did not improve their food), then the graduation rate would be 0.60. The causal effect on the outcome of a treatment of 1 versus 0 is 0.85 - 0.6 --- i.e., the difference between two potential outcomes --- which equals 0.25, which is the causal effect.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The the definition of a causal effect is the difference between two potential outcomes. Of course, you can't just say that the causal effect is 10. The exact value depends on which potential outcome comes first in the subtraction and which second. There is, perhaps, a default sense in which the causal effect is defined as treatment minus control. 

Any causal connection means exploring the *within row* difference between two potential outcomes. We don't need to look at any other rows to have that conversation. 

### Exercise 8

Let's consider a *predictive* model. Which variable in `colleges` do you think might have an important connection to `grad_rate`? 

```{r the-question-8}
question_text(NULL,
	message = "One variable which might have an important connection could be `tuition`. People who pay more for a college may be more willing to spend time there.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

With a predictive model, there is only one outcome for each individual unit. There are not two potential outcomes because we are not considering any of the covariates to be treatment variables. We assuming that all covariates are "fixed." 

### Exercise 9

Specify two different groups of colleges which have specific value for `tuition` and which might have different average values for the `grad_rate`. 

```{r the-question-9}
question_text(NULL,
	message = "Some colleges might charge a tuition of $90,000 per year. Others might have a tuition of $30,000. Those two groups will, on average, have graduation rate.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In predictive models, do not use words like "cause," "influence," "impact," or anything else which suggests causation. The best phrasing is in terms of "differences" between groups of units with different values for the covariate of interest.

### Exercise 10

Write a predicative question which connects the outcome variable `grad_rate` to a covariate of interest. 

```{r the-question-10}
question_text(NULL,
	message = "How does graduation rate differ between colleges at the 75th and 25th percentile of tuition?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We call the answer to this question is your "Quantity of Interest." 

Our Quantity of Interest might appear too specific, too narrow to capture the full complexity of the topic. There are many, many numbers which we are interested in, many numbers that we want to know. But we don't need to list them all here! We just need to choose one of them since our goal is just to have a specific number which helps to guide us in the creation of the Preceptor Table and, then, the model.

## Wisdom
### 

*All we can know is that we know nothing. And that’s the height of human wisdom.* - Leo Tolstoy

Our question:

> *What effect does the tuition of a college have on its graduation rate?*

### Exercise 1

In your own words, describe the key components of Wisdom when working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The central problem for Wisdom is: Can we use survey data from US colleges to understand the relationship between tuition and graduation rate for all US colleges?

### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, we can easily calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table does not include all the covariates which you will eventually including in your model. It only includes covariates which you need to answer your question.

### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem. Use words like "units," "outcomes," and "covariates."

```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Our question is predicative. Not all predicative questions need covariates. If our question asked "What is the probability that a student will graduate Harvard University?" There would be no covariates in this Preceptor Table. Just one column stating whether or not the student graduated.

### Exercise 4

Create a Github repo called `ordered`. Make sure to click the "Add a README file" check box.

Connect the `orderede` Github repo to an R project on your computer. Name the R project `ordered` also.

Select `File -> New File -> Quarto Document ...`. Provide a title (`"Ordered"`) and an author (you). Render the document and save it as `analysis.qmd`.

Save and push.

In the Console, run:

```         
show_file("analysis.qmd")
```

CP/CR.

```{r wisdom-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Remove everything below the YAML header from `analysis.qmd` and render the file. `Cmd/Ctrl + Shift + K` renders the file, this automatically saves the file as well.

### Exercise 5

What are the units for this problem?

```{r wisdom-5}
question_text(NULL,
	message = "Each individual college in the United States.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Specifying the Preceptor Table forces us to think clearly about the units and outcomes implied by the question. The resulting discussion sometimes leads us to modify the question with which we started. No data science project follows a single direction. We always backtrack. There is always dialogue.

### Exercise 6

What is the outcome variable for this problem?

```{r wisdom-6}
question_text(NULL,
	message = "Graduation rate for each individual college.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Regardless, the central lesson is always the same: *You can never look at your data too much.*

### Exercise 7

What are some covariates which you think might be useful for this problem, regardless of whether or not they might be included in the data?

```{r wisdom-7}
question_text(NULL,
	message = "We will need `tuition` for sure, some others that might be useful are: `selectivity`, size of campus, location of campus (could be `region`, `state` or `zip`) and the prestige (or `tier`) of the school",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The term "covariates" is used in at least three ways in data science. First, it is all the variables which might be useful, regardless of whether or not we have the data. Second, it is all the variables which we have data for. Third, it is the set of covariates which we end up using in the model.

### Exercise 8

What are the treatments, if any, for this problem?

```{r wisdom-8}
question_text(NULL,
	message = "Since this is a predicative model, there are no treatments.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Remember that a treatment is just another covariate which, for the purposes of this specific problem, we are assuming can be manipulated, thereby, creating two or more different potential outcomes for each unit.

### Exercise 9

What moment in time does the Preceptor Table refer to?

```{r wisdom-9}
question_text(NULL,
	message = "Now",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

```{r}
colleges |>
  select(tuition, grad_rate, selectivity) |>
  filter(tuition > 2) |>
  ggplot(aes(x = tuition, y  = grad_rate)) + 
  geom_point() + 
  geom_smooth() + 
  labs(title = "Graduation Rate vs Tuition", 
       subtitle = "For colleges with tuition greater than $20,000",
       x = "Tuition (in tens of thousands)", 
       y = "Graduation Rate")
```

### Exercise 10

Define causal effect.

```{r wisdom-10}
question_text(NULL,
	message = "A causal effect is the difference between two potential outcomes.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

According to the Rubin Causal Model, there must be two (or more) potential outcomes for any discussion of causation to make sense. This is simplest to discuss when the treatment only has two different values, thereby generating only two potential outcomes. 

### Exercise 11

What is the fundamental problem of causal inference?

```{r wisdom-11}
question_text(NULL,
	message = "The fundamental problem of causal inference is that we can only observe one potential outcome.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If the treatment variable is continuous (like graduation rate in this case), then there are lots and lots of potential outcomes, one for each possible value of the treatment variable. 

### Exercise 12

How does the motto "No causal inference without manipulation." apply in this problem?

```{r wisdom-12}
question_text(NULL,
	message = "The motto does not apply because this is a predictive, not causal, model",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 13

Describe in words the Preceptor Table for this problem.

```{r wisdom-13}
question_text(NULL,
	message = "The Preceptor Table contains a row for each college. There are three columns: one is tuition, which is our main covariate; next we have ID and finally the last one is graduation rate, which is our outcome variable.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table for this problem looks something like this:

```{r}
library(gt)
library(tidyverse)


data <- tibble(
  ID = c("1", "2", "...", "10", "11", "...", "950"),
  graduation_rate = c(0.92, 0.55, "...", 0.42, 0.78, "...", 0.87),
  tuition = c(4.5, 1.3, "...", 2.9, 2.2, "...", 3.7)
)
data |>
  gt() |>
  tab_header(title = "Preceptor Table") |>
  cols_label(
    ID = md("ID"),
    graduation_rate = md("Graduation Rate"),
    tuition = md("Tuition (tens of thousands)")
  ) |>
  tab_style(
    cell_borders(sides = "right"),
    location = cells_body(columns = c(ID))
  ) |>
  tab_style(
    style = cell_text(align = "left", v_align = "middle", size = "large"), 
    locations = cells_column_labels(columns = c(ID))
  ) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Outcome", columns = c(graduation_rate)) |>
  tab_spanner(label = "Covariate", columns = c(tuition))

```

### 

Like all aspects of a data science problem, the Preceptor Table evolves as we work on the problem. For example, at the start, we aren't sure what right-hand side variables will be included in the model, so we are not yet sure which columns must be in the Preceptor Table.

### Exercise 14

In your QMD, load the **tidyverse** and the **primer.data** packages in a new code chunk. Label it as the setup code chunk by adding `#| label: setup`. Render the file.

Notice that the file does not look good because the code is visible and there are annoying messages. To take care of this, add `#| message: false` to remove all the messages in the setup chunk. Also add the following to the YAML header to remove all code echos from the whole file:

```         
execute: 
  echo: false
```

In the Console, run:

```         
show_file("analysis.qmd", start = -5)
```

CP/CR.

```{r wisdom-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

### 

Render again. Everything looks nice because we have added code to make the file look better and more professional.

### Exercise 15

Print out `colleges` below.

```{r wisdom-15, exercise = TRUE}

```

```{r wisdom-15-hint-1, eval = FALSE}
colleges
```

```{r wisdom-15-test, include = FALSE}
colleges
```

### 

What you may not know is that the `tuition` column is in terms of $10,000 per year. This will make it easier to interpret our regression coefficients when we make our model.

### Exercise 16

Use `select()` to select the `tuition`, `grad_rate` and `selectivity` columns.

```{r wisdom-16, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r wisdom-16-hint-1, eval = FALSE}
... |>
  select(..., ..., ...)
```

```{r wisdom-16-test, include = FALSE}
colleges |>
  select(tuition, grad_rate, selectivity)
```

### 

Take a look at this plot

```{r}
#| echo: FALSE
colleges |>
  select(tuition, grad_rate) |>
  ggplot(aes(x = tuition, y = grad_rate)) +
  geom_point() +
  geom_smooth() + 
  labs(title = "Graduation Rate vs Tuition", 
       subtitle = "The graduation rate varies for colleges with tuition less than $20,00",
       x = "Tuition (in tens of thousands)", 
       y = "Graduation Rate")
```

We see a very interesting relationship. For colleges with less than around 20k per year in tuition, there doesn't seem to be much of relationship between `tuition` and `grad_rate`. However, after that it seems to increase linearly.

### Exercise 17

Continue the pipe to `ggplot()`, map `tuition` to the x-axis. Add the `geom_histogram()` layer. Label the plot with a title, subtitle, x-axis label, and y-axis label.

```{r wisdom-17, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r wisdom-17-hint-1, eval = FALSE}
... |>
  ggplot(aes(...)) +
  ...()
```

```{r wisdom-17-test, include = FALSE}
colleges |>
  select(tuition, grad_rate, selectivity) |> 
  ggplot(aes(x = tuition)) + 
  geom_histogram() + 
  labs(title = "Tuition Distribution", 
       subtitle = "There were many colleges with tuition less than $20,000",
       x = "Tuition (in tens of thousands)", 
       y = "Number of Colleges")
```

### 

Recall the scatter plot earlier we showed earlier where there didn't seem like much of a relationship between graduation rate and tuition for schools that charge less than 20k per year. Looking at the histogram, we might find a reason as to why. There are **so** many schools that charge less than 20k per year.

### Exercise 18

Select the `tuition`, `grad_rate` and `selectivity` columns from `colleges`. Filter `tuition` to be greater than 2. Set this equal to a new object, `x`.

```{r wisdom-18, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r wisdom-18-hint-1, eval = FALSE}
x <- colleges |> 
                select(...) |>
                filter(...)
```

```{r wisdom-18-test, include = FALSE}
x <- colleges |>
  select(tuition, grad_rate, selectivity) |>
  filter(tuition > 2)
```

### 

Take University of Michigan, UCLA and UC Berkeley for example. These are the three highest ranked public universities in all of America. Since they are publics, they charge a relatively low tuition rate compared to that of private institutes. But, they all have high graduation rates since they are considered "nice" schools.

### Exercise 19

Pipe `x` to `ggplot()` map `tuition` to the x-axis and `grad_rate` to the y-axis.

```{r wisdom-19, exercise = TRUE}

```

```{r wisdom-19-hint-1, eval = FALSE}
x |> 
  ggplot(aes(...))
```

```{r wisdom-19-test, include = FALSE}
x |> 
  ggplot(aes(x = tuition, y  = grad_rate))
```

Recall University of Michigan, UCLA and UC Berkeley all have have very high graduation rates. They also have something else in common (and no it's not that they are publics), they are all very selective schools. Could there be a relationship there?

### Exercise 20

Add the `facet_wrap()` layer with `~ selectivity` as the argument. Then, add `geom_point()`

```{r wisdom-20, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r wisdom-20-hint-1, eval = FALSE}
... + 
  facet_wrap(~ ...) + 
  ...()
```

```{r wisdom-20-test, include = FALSE}
x |> 
  ggplot(aes(x = tuition, y  = grad_rate)) + 
  facet_wrap(~ selectivity) + 
  geom_point()
```

### 

This seems kind of cool. If we start with "Elite" schools and make our way down to "Non-selective" schools, we see a big difference in `grad_rate`. There are also differences in `tuition`. `selectivity` seems like a covariate worth measuring.

### Exercise 21

In `analysis.qmd`, add a new code chunk. Copy the code from two exercises ago which prepares the data and paste it in the code chunk. Set the code to an object called `x`. 

Render the file. In the Console, run:

```         
show_file("analysis.qmd", start = -5)
```

CP/CR.

```{r wisdom-21}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 22

In your own words, define "validity" as we use the term.

```{r wisdom-22}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Validity is always about the *columns* in the Preceptor Table and the data. Just because columns from these two different tables have the same *name* does not mean that they are the same *thing*.

### Exercise 23

Provide one reason why the assumption of validity might not hold for the outcome variable: `grad_rate`. Use the words "column" or "columns" in yor answer.

```{r wisdom-23}
question_text(NULL,
	message = "An instance where validity would not hold would be if the column `grad_rate` from the data refered to the graduation rate in 2013, but now it could be the case that colleges have increased their minimum GPA for graduation or added more requirement that caused changes in the graduatiation rate column in the Preceptor Table though they may have the same name.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In order to consider the Preceptor Table and the data to be drawn from the same population, the columns from one must have a *valid correspondence* with the columns in the other. Validity, if true (or at least reasonable), allows us to construct the Population Table, which is the first step in Justice.

Because we control the Preceptor Table and, to a lesser extent, the original question, we can adjust those variables to be “closer” to the data that we actually have. This is another example of the iterative nature of data science. If the data is not close enough to the question, then we check with our boss/colleague/customer to see if we can modify the question in order to make the match between the data and the Preceptor Table close enough for validity to hold.


### Exercise 24

Over the course of this tutorial, we will be creating a summary paragraph. The purpose of this exercise is to write the first two sentences of that paragraph.

The first sentence is a general statement about the overall topic, mentioning both general class of the outcome variable and of at least one of the covariates. It is **not** connected to the initial "Imagine that you are XX" which set the stage for this project. That sentence can be rhetorical. It can be trite, or even a platitude. The purpose of the sentence to let the reader know, gently, about our topic.

The second sentence does two things. First, it introduces the data source. Second, it introduces the specific question. The sentence can't be that long. Important aspects of the data include when/where it was gather, how many observations it includes and the organization (if famous) which collected it.

Type your two sentences below.

```{r wisdom-24}
question_text(NULL,
	message = "Tuition fee and educational quality are one of the main concerns for many students and their families when going to college. Using data from a IPEDS, a system of interrelated surveys on postsecondary eduation in 2013, we seek to understand the relationship between graduation rates tuition for colleges/universities in the United States.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Read our answer. It will not be the same as yours. You can, if you want, change your answer to incorporate some of our ideas. Do not copy/paste our answer exactly. Add your two sentences, edited or otherwise, to your QMD, `Cmd/Ctrl + Shift + K`, and then commit/push.

## Justice
### 

*The arc of the moral universe is long, but it bends toward justice.* - Theodore Parker

### Exercise 1

In your own words, name the four key components of Justice for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Justice is about concerns that you (or your critics) might have, reasons why the model you create might not work as well as you hope. 

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Population Table is almost always much bigger than the combination of the Preceptor Table and the data because, if we can really assume that both the Preceptor Table and the data are part of the same population, than that population must cover a broad universe of time and units since the Preceptor Table and the data are, themselves, often far apart from each other.

### Exercise 3

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-3}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability is all about *time*. Is the relationship among the columns in the Population Table stable over time? In particular, is the relationship --- which is another way of saying "mathematical formula" --- at the time the data was gathered the same as the relationship at the (generally later) time references by the Preceptor Table.


### Exercise 4

Provide one reason why the assumption of stability might not be true in this case.

```{r justice-4}
question_text(NULL,
	message = "The average graduation rate could have changed from 2013.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A change in time or the distribution of the data does not, in and of itself, demonstrate a violation of stability. Stability is about the parameters: $\beta_1$, $\beta_1$ and so on. Stability means these parameters are the same in the data as they are in the population as they are in the Preceptor Table.

### Exercise 5

We use our data to make inferences about the overall population. We use information about the population to make inferences about the Preceptor Table: `Data -> Population -> Preceptor Table`. In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-5}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationships among the rows in the Population Table. The first is between the data and the other rows. The second is between the other rows and the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case.

### Exercise 6

We do not use the data, directly, to estimate missing values in the Preceptor Table. Instead, we use the data to learn about the overall population. Provide one reason, involving the relationship between the data and the population, for why the assumption of representativeness might not be true in this case.

```{r justice-6}
question_text(NULL,
	message = "Smaller schools may have been excluded from our dataset.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The reason that representativeness is important is because, when it is violated, the estimates for the model parameters might be biased. 


### Exercise 7

We use information about the population to make inferences about the Preceptor Table. Provide one reason, involving the relationship between the population and the Preceptor Table, for why the assumption of representativeness might not be true in this case.

```{r justice-7}
question_text(NULL,
	message = "Because the Preceptor Table includes the entire population, there is no problem with representativeness in using the population to draw inferences about the Precetor Table. They are one and the same.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability looks across time periods. Representativeness looks within time periods, for the most part. 

Of course, it is sometimes the case that the Preceptor Table includes every row from the Population Table for that moment in time. In that case, the assumption representativeness is met, by definition, if we only consider that moment. So, in that case, the only possible violation of representativeness must involve a claim that this moment in time is not representative of the rest of the Population Table.

### Exercise 8

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-8}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This assumption is only relevant for causal models. We describe a model as "confounded" if this is not true. The easiest way to ensure unconfoundedness is to assign treatment randomly.

### Exercise 9

Write one sentence which highlights a potential weakness in your model. This will almost always be derived from possible problems with the assumptions discussed above. We will add this sentence to our summary paragraph. So far, our version of the summary paragraph looks like this:

> Tuition fee and educational quality are one of the main concerns for many students and their families when going to college. Using data from a IPEDS, a system of interrelated surveys on postsecondary eduation in 2013, we seek to understand the relationship between graduation rates tuition for colleges/universities in the United States.

Of course, your version will be somewhat different.


```{r justice-9}
question_text(NULL,
	message = "Tuition fee and educational quality are one of the main concerns for many students and their families when going to college. Using data from a IPEDS, a system of interrelated surveys on postsecondary eduation in 2013, we seek to understand the relationship between graduation rates tuition for colleges/universities in the United States. Graduation rates could've changed tremendously since 2013 thus potentially weaken our model.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Add a weakness sentence to the summary paragraph in your QMD. You can modify your paragraph as you see fit, but do not copy/paste our answer exactly. `Cmd/Ctrl + Shift + K`, and then commit/push.

## Courage
### 

*Courage is being scared to death, but saddling up anyway.* - John Wayne

### Exercise 1

In your own words, describe the components of the virtue of Courage for analyzing data.

```{r courage-1}
question_text(NULL,
	message = "Courage starts with math, explores models, and then creates the data generating mechanism.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A statistical model consists of two parts: the *probability family* and the *link function*. The probability family is the probability distribution which generates the randomness in our data. The link function is the mathematical formula which links our data to the unknown parameters in the probability distribution. 

### Exercise 2

Load the [**tidymodels**](https://www.tidymodels.org/) package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(tidymodels)
```

### 

The probability family is determined by the outcome variable `grad_rate`. 

Because `grad_rate` is a continuous variable, the probability family is Normal, also known as Gaussian.

$$ grad\_rate_i \sim Normal(\mu, \sigma^2)$$

### Exercise 3

Load the [**broom**](https://broom.tidymodels.org/) package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(broom)
```

### 

The link function, the basic mathematical structure of the model, is (mostly) determined by the type of outcome variable. 

For a continuous outcome variable, we use a linear model for the link function:

$$\mu = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots$$


### Exercise 4

Load the [**marginaleffects**](https://marginaleffects.com/) package.

```{r courage-4, exercise = TRUE}

```

```{r courage-4-hint-1, eval = FALSE}
library(...)
```

```{r courage-4-test, include = FALSE}
library(marginaleffects)
```

### 

We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.

### Exercise 5

Add `library(tidymodels)`, `library(broom)`, and `library(marginaleffects)` to the `setup` code chunk in your QMD. `Cmd/Ctrl + Shift + K`.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", pattern = "library")
```

CP/CR.

```{r courage-5}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

When we use an ordered factor in a regression model, R will automatically use orthogonal polynomial contrasts to represent the different levels of the factor. 

### Exercise 6

Because our outcome variable is continuous, start to create the model by using `linear_reg()`.

```{r courage-6, exercise = TRUE}

```

```{r courage-6-hint-1, eval = FALSE}
linear_reg()
```

```{r courage-6-test, include = FALSE}
linear_reg()
```

### 

If an ordered factor has $N$ levels, then the orthogonal polynomial contrasts will have $N-1$ terms. This is why you're seeing with terms like `selectivity.L`, `selectivity.Q`, `selectivity.C`, and `selectivity^4`. The higher-degree terms (`like selectivity^4`) capture increasingly complex, non-linear patterns in the data. If these terms are statistically significant, they suggest that the relationship between `selectivity` and `grad_rate` isn't purely linear or quadratic but might have a more complex form.

### Exercise 7

Continue the pipe with `set_engine("lm")`.

```{r courage-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-7-hint-1, eval = FALSE}
... |> 
  set_engine("...")
```

```{r courage-7-test, include = FALSE}
linear_reg() |>
  set_engine("lm")
```

### 

`"lm"` is not the only engine. Since we have a linear regression model, we could use `"glmnet"`, but, that would require us to load up another package, whereas `"lm"` uses standard base R.


### Exercise 8

Continue the pipe to `fit(grad_rate ~ tuition + selectivity, data = x)`.

```{r courage-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-8-hint-1, eval = FALSE}
... |> 
  fit(..., 
      data = ...)
```

```{r courage-8-test, include = FALSE}
linear_reg() |>
    set_engine("lm") |>
    fit(grad_rate ~ tuition + selectivity, 
        data = x)
```

### 

We can translate the fitted model into mathematics, including the best estimates of all the unknown parameters:


There are three main differences between this representation of the model and our previous one. First, we replace the parameters with our best estimate of their values. Second, the error term is gone. Third, the dependent variable now has a "hat," indicating that it is our "fitted" value, our best guess as to the value of the outcome, given the values of the independent variables for any given unit.

### Exercise 9

Behind the scenes of this tutorial, an object called `fit_colleges` has been created which is the result of the code above. Type `fit_colleges` and hit "Run Code." This generates the same results as using `print(fit_colleges)`.


```{r courage-9, exercise = TRUE}

```

```{r courage-9-hint-1, eval = FALSE}
fit_colleges
```

```{r courage-9-test, include = FALSE}
fit_colleges
```

### 

In data science, we deal with words, math, and code, but the most important of these is code. We created the mathematical structure of the model and then wrote a model formula in order to estimate the unknown parameters. 

### Exercise 10

Create a new code chunk in your QMD. Add two code chunk options: `label: model` and `cache: true`. Copy/paste the code from above for estimating the model into the code chunk, assigning the result to `fit_colleges`. 

`Cmd/Ctrl + Shift + K`. It may take some time to render your QMD, depending on how complex your model is. But, by including `cache: true` you cause Quarto to cache the results of the chunk. The next time you render your QMD, as long as you have not changed the code, Quarto will just load up the saved fitted object.

To confirm, `Cmd/Ctrl + Shift + K` again. It should be quick.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", start = -8)
```

CP/CR.

```{r courage-10}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Add `*_cache` to `.gitignore` file. Commit and push. Cached objects are often large. They don't belong on Github.

### Exercise 11

Create another code chunk in your QMD. Add the chunk option: `label: math`. In that code chunk, add something like the below. You may find it useful to add the `coef_digits` argument to show fewer significant digits after the decimal.


`Cmd/Ctrl + Shift + K`. 

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", pattern = "extract")
```

CP/CR.

```{r courage-11}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- DK: This question is messed up! -->

This is our data generating mechanism (DGM). 

The `selectvity.L` entry is a test for linear trend. The null is no linear trend (i.e., a flat line). 

The `selectivity.Q` entry is a test for quadratic trend. The null is no quadratic trend (i.e., a straight line). 

The `selectivity.C` entry is a test for cubic trend. The null is no cubic trend (i.e., a straight or quadratic line). 

The `selectivity^4` entry is a test for quartic trend. The null is no quartic trend (i.e., a straight, quadratic, or cubic line).

These coefficients are too difficult to interpret, so we will not spend time trying to decipher them. But, we can see by the mostly positive values that higher selectivity does seem to positively impact graduation rates.


### Exercise 12

Run `tidy()` on `fit_colleges` with the argument `conf.int` set equal to `TRUE`. The returns 95% intervals for all the parameters in our model.

```{r courage-12, exercise = TRUE}

```

```{r courage-12-hint-1, eval = FALSE}
tidy(..., conf.int = ...)
```

```{r courage-12-test, include = FALSE}
tidy(fit_colleges, conf.int = TRUE)
```

### 

`tidy()` is part of the [**broom**](https://broom.tidymodels.org/) package, used to summarize information from a wide variety of models.

### Exercise 13

```{r}
tidy(fit_colleges, conf.int = TRUE) |> filter(term == "(Intercept)")
```

Write a sentence interpreting the estimate for the Intercept.

```{r courage-13}
question_text(NULL,
	message = "The Intercept shows that our (best) estimate for the overall graduation rate for the colleges in our model is around 36%",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Note how, whenever we consider non-treatment variables, we must never use terms like "cause," "impact" and so on. We can't make any statement which implies the existence of more than one potential outcome based on changes in non-treatment variables. We can't make any claims about within row effects. Instead, we can only compare across rows. Always use the phrase "when comparing X and Y" or something very similar. 

### Exercise 14

```{r}
tidy(fit_colleges, conf.int = TRUE) |> filter(term == "tuition")
```

Write a sentence about the `estimate` for the `tuition` coefficient.

```{r courage-14}
question_text(NULL,
	message = "For every $10,000 extra a college charges in tuition, the graduation rate increases by approximately 9%.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

`tuition` is continuous, each time it goes up by a value of 1 (which remember, corresponds to 10k in tuition), our graduation rate increases by an amount indicated by the `estimate`.

### Exercise 15

```{r}
tidy(fit_colleges, conf.int = TRUE) |> filter(term == "tuition")
```

Write a sentence about the confidence interval for `tuition.`

```{r courage-15}
question_text(NULL,
	message = "We do not know the true value for the coefficient for `tuition`, but we can be 95% confident that it lies somewhere between [0.07, 0.11].",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Because we are Bayesians, we believe that there is a true value and that the confidence or credible or uncertainty interval includes it at the stated level. These questions provide an occasion in the knowledge drop to compare/contrast the Frequenist interpretation. See: [the Primer](https://ppbds.github.io/primer/cardinal-virtues.html#confidencecredibleuncertainty-intervals) to learn more.

### Exercise 16

For interactive use, `tidy()` is very handy. But, for presenting our results, we should use a presentation package like **gtsummary**, which includes handy functions like `tbl_regression()`.

Run `tbl_regression(fit_colleges)`.


```{r courage-16, exercise = TRUE}

```

```{r courage-16-hint-1, eval = FALSE}
tbl_regression(..)
```

```{r courage-16-test, include = FALSE}
# tbl_regression(fit_colleges)
```

### 

See this [tutorial](https://www.danieldsjoberg.com/gtsummary/articles/tbl_regression.html) for a variety of options for customizing your table.

### Exercise 17

Create a new code chunk in `analysis.qmd`. Add a code chunk option: `label: table`. Add this code to the code chunk.

```
tidy(fit_colleges, conf.int = TRUE)
```

`Cmd/Ctrl + Shift + K`. 

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", pattern = "tidy")
```

CP/CR.


```{r courage-17}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### Exercise 18

Add a sentence to your project summary.

Explain the structure of the model. Something like: "I/we model Y [the concept of the outcome, not the variable name] as a [linear/logistic/multinomial/ordinal] function of X [and maybe other covariates]."

Recall the beginning of our version of the summary:

> Tuition fee and educational quality are one of the main concerns for many students and their families when going to college. Using data from a IPEDS, a system of interrelated surveys on postsecondary eduation in 2013, we seek to understand the relationship between graduation rates tuition for colleges/universities in the United States. Graduation rates could've changed tremendously since 2013 thus potentially weaken our model.

```{r courage-18}
question_text(NULL,
	message = "Tuition fee and educational quality are one of the main concerns for many students and their families when going to college. Using data from a IPEDS, a system of interrelated surveys on postsecondary eduation in 2013, we seek to understand the relationship between graduation rates tuition for colleges/universities in the United States. Graduation rates could've changed tremendously since 2013 thus potentially weaken our model. We modeled graduation rate, a continuous variable, as a linear function of both tuition and selectivity. Graduation rates seem to rise as tuition increases.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Read our answer. It will not be the same as yours. You can, if you want, change your answer to incorporate some of our ideas. Do not copy/paste our answer exactly. Add your two sentences, edited or otherwise, to summary paragraph portion of your QMD. `Cmd/Ctrl + Shift + K`, and then commit/push.

## Temperance
### 

*Temperance is a tree which as for its root very little contentment, and for its fruit calm and peace.* - Buddha

### Exercise 1

In your own words, describe the use of Temperance in data science.

```{r temperance-1}
question_text(NULL,
	message = "Temperance uses the data generating mechanism to answer the questions with which we began. Humility reminds us that this answer is always a lie. We can also use the DGM to calculate many similar quantities of interest, displaying the results graphically.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Courage gave us the data generating mechanism. Temperance guides us in the use of the DGM — or the “model” — we have created to answer the questions with which we began. We create posteriors for the quantities of interest. We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.

### Exercise 2

What is the general topic we are investigating? What is the specific question we are trying to answer? 

<!-- GK: Maybe we can change 75th and 25th percentile to something more general. Such as "high" and "low" tuition. -->

```{r temperance-2}
question_text(NULL,
	message = "We are investigating the relationship between tuition and graduation rates. In particular, how does graduation rate differ between colleges at the 75th and 25th percentile of tuition?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Data science projects almost always begin with a broad topic of interest. Yet, in order to make progress, we need to drill down to a specific question. This leads to the creation of a data generating mechanism, which can now be used to answer lots of questions, thus allowing us to explore the original topic broadly.

### Exercise 3

At the Console, run this code: 

```         
plot_predictions(fit_colleges, 
                condition = "selectivity")
```

CP/CR, although note that there will be no response.

```{r temperance-3}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

The graphic is a line plot, with the x-axis showing the values of `tuition` and the y-axis showing the estimated graduation rate. The lines show the estimated graduation rate for each level of `selectivity`.

### Exercise 4

Let's make the plot look more professional. Copy the previous code, add necessary title, subtitle, caption and label for the plot.

Remember this is what your graph should look like:

```{r}
plot_predictions(fit_colleges, 
                condition = "selectivity") +
  labs(
    title = "Graduation Rates Based on Selectivity",
    subtitle = "Graduation rates seem to rise as selectivity increases",
    caption = "Data from IPEDS, 2013",
    x = "Tuition",
    y = "Graduation Rate",
    color = "Tuition Percentile") +
    scale_color_manual(values = c("3.73" = "cyan3", "2.63" = "red"),
                       labels = c("3.73" = "75th Percentile", "2.63" = "25th Percentile")) + 
      guides(color = guide_legend(reverse = TRUE)) +
      theme_minimal()
```

```{r temperance-4, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-4-hint-1, eval = FALSE}
plot_predictions(fit_colleges, 
                condition = "selectivity") +
  labs(
    title = ...,
    subtitle = ...,
    caption = ...,
    x = ...,
    y = ...,
    color = "Tuition Percentile") +
    scale_color_manual(values = c("3.73" = "cyan3", "2.63" = "red"),
                       labels = c("3.73" = "75th Percentile", "2.63" = "25th Percentile")) + 
      guides(color = guide_legend(reverse = TRUE)) +
      theme_minimal()
```

```{r temperance-4-test, include = FALSE}
plot_predictions(fit_colleges, 
                condition = "selectivity") +
  labs(
    title = "Graduation Rates Based on Selectivity",
    subtitle = "Graduation rates seem to rise as selectivity increases",
    caption = "Data from IPEDS, 2013",
    x = "Tuition",
    y = "Graduation Rate",
    color = "Tuition Percentile") +
    scale_color_manual(values = c("3.73" = "cyan3", "2.63" = "red"),
                       labels = c("3.73" = "75th Percentile", "2.63" = "25th Percentile")) + 
      guides(color = guide_legend(reverse = TRUE)) +
      theme_minimal()
```

### 

If you observe closely, you can see that "Non-selective" schools have a higher average graduation rate than "Lowly-Selective" schools. Why could this be?


### Exercise 5

Create a new code chunk in your QMD. Label it with `label: plot`. Copy/paste the code which creates your graphic. 

`Cmd/Ctrl + Shift + K` to ensure that it all works as intended.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", start = -8)
```

CP/CR.

```{r temperance-5}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Recall this plot from earlier:

```{r}
x |> 
  ggplot(aes(x = tuition, y  = grad_rate)) + 
  facet_wrap(~ selectivity) + 
  geom_point()
```

There are only a handful of non-selective schools. We get a less accurate of an estimate when we have fewer schools. This is why the error bars are a lot larger for "Non-selective". In fact, they cross over one another, which could even mean that schools with lower tuition have a **higher** graduation rate as opposed to schools with a lower graduation rate. Point is, we don't have enough data to make a reasonable conclusion about non-selective schools.

### Exercise 6

Write the last sentence of your summary paragraph. It describes at least one quantity of interest (QoI) and provides a measure of uncertainty about that QoI. (It is OK if this QoI is not the one that you began with. The focus of a data science project often changes over time.)

```{r temperance-6}
question_text(NULL,
	message = "Tuition fee and educational quality are one of the main concerns for many students and their families when going to college. Using data from a IPEDS, a system of interrelated surveys on postsecondary eduation in 2013, we seek to understand the relationship between graduation rates tuition for colleges/universities in the United States. Graduation rates could've changed tremendously since 2013 thus potentially weaken our model. We modeled graduation rate, a continuous variable, as a linear function of both tuition and selectivity. Graduation rates seem to rise as tuition increases. Colleges in the 75th percentile are have on average an 11% higher graduation rate as opposed to colleges in the 25th percentile, although that number may be anywhere from 9-13%.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Add a final sentence to your summary paragraph in your QMD as you see fit, but do not copy/paste our answer exactly. `Cmd/Ctrl + Shift + K`.

### Exercise 7

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval, if you think either might be warranted.

```{r temperance-7}
question_text(NULL,
	message = "Perhaps our data did not match the `tuition` coefficient as we hoped. This is because a lot of the assumptions we make during the process of building a model, the processes in Wisdom, are subject to error. Perhaps our data did not match the future as well as we had hoped. In such cases, increase the confidence interval since the assumptions of your model are always false.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 8

Rearrange the material in `analysis.qmd` so that the order is graphic, paragraph, math and table. Doing so, of course, requires sensible judgment. For example, the code chunk which creates the fitted model must occur before the chunk which creates the graphic. `Cmd/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd")
```

CP/CR.

```{r temperance-8}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

This is the version of your QMD file which your teacher is most likely to take a close look at.

### Exercise 9

Publish your rendered QMD to Rpubs. Choose a sensible slug. Copy/paste the url below.

```{r temperance-9}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Add `rsconnect` to the `.gitignore` file. You don't want your personal Rpubs details stored in the clear on Github. Commit/push everything.

## Summary
### 

This tutorial supports [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

We started the Tutorial with a question:

> *What is the relationship between tuition and graduation rates for colleges and universities in the United States?*

Using data from a IPEDS, a system of interrelated surveys on postsecondary eduation in 2013, we seek to understand the relationship between graduation rates tuition for colleges/universities in the United States. Graduation rates could've changed tremendously since 2013 thus potentially weaken our model. We modeled graduation rate, a continuous variable, as a linear function of both tuition and selectivity. Graduation rates seem to rise as tuition increases. Colleges in the 75th percentile are have on average an 11% higher graduation rate as opposed to colleges in the 25th percentile, although that number may be anywhere from 9-13%.

```{r}
plot_predictions(fit_colleges, 
                condition = "selectivity") +
  labs(
    title = "Graduation Rates Based on Selectivity",
    subtitle = "Graduation rates seem to rise as selectivity increases",
    caption = "Data from IPEDS, 2013",
    x = "Tuition",
    y = "Graduation Rate",
    color = "Tuition Percentile") +
    scale_color_manual(values = c("3.73" = "cyan3", "2.63" = "red"),
                       labels = c("3.73" = "75th Percentile", "2.63" = "25th Percentile")) + 
      guides(color = guide_legend(reverse = TRUE)) +
      theme_minimal()
```

```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
