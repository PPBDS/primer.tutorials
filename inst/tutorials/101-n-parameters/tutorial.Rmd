---
title: N Parameters
author: David Kane
tutorial:
  id: n-parameters
output:
  learnr::tutorial:
    progressive: yes
    allow_skip: yes
runtime: shiny_prerendered
description: 'Chapter 10 Tutorial: N Parameters'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(gt)

library(primer.data)
library(tidyverse)
library(tidymodels)
library(broom)        # Or broom.mixed. Not sure if we ever need broom.helpers?
library(marginaleffects)

library(easystats)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 


x <- shaming |> 
  mutate(civ_engage = primary_00 + primary_02 + primary_04 + 
               general_00 + general_02 + general_04) |> 
  select(primary_06, treatment, sex, age, civ_engage) |> 
  mutate(voter_class = factor(
    case_when(
      civ_engage %in% c(5, 6) ~ "Always Vote",
      civ_engage %in% c(3, 4) ~ "Sometimes Vote",
      civ_engage %in% c(1, 2) ~ "Rarely Vote"),
         levels = c("Rarely Vote", 
                    "Sometimes Vote", 
                    "Always Vote"))) |>
  mutate(voted = as.factor(primary_06))			

# fit_vote_1 <- logistic_reg(engine = "glm") |> 
# 	fit(voted ~ sex + age + treatment + voter_class, data = x) 

# fit_vote_2 <- logistic_reg(engine = "glm") |> 
#   fit(voted ~ age + sex + treatment*voter_class, 
#       data = x)

# fit_vote <- fit_vote_2

# coefs_vote_1 <- tidy(fit_vote_1, conf.int = TRUE) |>
# 	select(term, estimate, conf.low, conf.high)	  

# coefs_vote_2 <- tidy(fit_vote_2, conf.int = TRUE) |>
# 	select(term, estimate, conf.low, conf.high)	 

# save(fit_vote_1, fit_vote_2, fit_vote, coefs_vote_1, coefs_vote_2,
# 	 file = "data/objects.RData")

load("data/objects.RData")
```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

<!-- OPEN ISSUES: -->

<!-- Deal with decimals when showing tidy() table of coefficients. -->

<!-- The question just gets you started. It leads to the creation of the model.  -->

<!-- Need some discussion in Question about when/how we start to move from the data to the Preceptor Table. That is, our current examples of coming up with a causal question and with a predictive question center around the actual data. That is fine, but our question will be about the Preceptor Table. Need to make that transition clearer. OR SHOULD THE ENTIRE THE QUESTION TOPIC have nothing to do with the actual data . . . -->

<!-- Give better guidance as to the question. I am thinking, more and more, that the specific question is one that can apply to both the data and the Preceptor Table. That is, there are no details about time or location which prevent it from applying in both cases. -->

<!-- Both a causal effect and a prediction are much fuzzier notions than you might think because their are so many, depending on AGGREGATION. That is, you might ask for the average causal effect, or the average causal effect for men and for women, or for the difference in average causal effect between men and women, or . . . The key point is that all these questions are trivial to answer if you have the Preceptor Table *and* they might require very different approaches given that we don't. This is where the power/flexibility of marginaleffects can come in handy. -->

<!-- Think about the connections among all the material in the initial chunk of each section. How does the "Imagine that you are . . . " of the Introduction connect to the material discussion in the Question into, and then Wisdom and so on. There is nothing wrong with the silly quotes. (Or is there? Are we wasting student time?) But we should do more with that space. Maybe the current version of the summary paragraph goes there? -->

<!-- I worry that we dive too quickly into problems with stability and representativeness, at least when coming up with counter-examples. But how else to handle this? -->

## Introduction
### 

This tutorial supports [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

The world confronts us. Make decisions we must.

Imagine that you are running for Governor of Texas in the next election. You have a campaign budget. Your goal is to win the election. Winning the election involves convincing people to vote for you *and* getting your supporters to vote. Should you send postcards to registered voters? What should those postcards say? Does the effect of the postcards vary for different types of voters? 

## The Question
### 

*The important thing is not to stop questioning.* - Albert Einstein

Running for any political office, much less governor of a large state, is difficult. You have resources --- money, volunteers, surrogates, your own time. You have goals --- increase your name recognition, raise money, attack your opponent, persuade undecided voters, get your supporters to vote. There are thousands of decisions to make. One option is to send postcards to potential voters. What happens if you do?

### Exercise 1

Load [**tidyverse**](https://www.tidyverse.org/) package.

```{r the-question-1, exercise = TRUE}

```

```{r the-question-1-hint-1, eval = FALSE}
library(tidyverse)
```

```{r the-question-1-test, include = FALSE}
library(tidyverse)
```

### 

The data come from “[Social Pressure and Voter Turnout: Evidence from a Large-Scale Field Experiment](https://doi.org/10.1017/S000305540808009X)” by Gerber, Green, and Larimer (2008).

Abstract: Voter turnout theories based on rational self-interested behavior generally fail to predict significant turnout unless they account for the utility that citizens receive from performing their civic duty. We distinguish between two aspects of this type of utility, intrinsic satisfaction from behaving in accordance with a norm and extrinsic incentives to comply, and test the effects of priming intrinsic motives and applying varying degrees of extrinsic pressure. A large-scale field experiment involving several hundred thousand registered voters used a series of mailings to gauge these effects. Substantially higher turnout was observed among those who received mailings promising to publicize their turnout to their household or their neighbors. These findings demonstrate the profound importance of social pressure as an inducement to political participation.

### Exercise 2

Load the [**primer.data**](https://ppbds.github.io/primer.data/) package.

```{r the-question-2, exercise = TRUE}

```

```{r the-question-2-hint-1, eval = FALSE}
library(primer.data)
```

```{r the-question-2-test, include = FALSE}
library(primer.data)
```

### 

A version of the data is available in the `shaming` tibble.

### Exercise 3

After loading **primer.data** in your Console, type `?shaming` in the Console, and paste in the Description below.

```{r the-question-3}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

In their published article, the authors note that “Only registered voters who voted in November 2004 were selected for our sample.” After this, the authors found their voting history and then sent out the mailings. Thus, anyone who did not vote in the 2004 general election is excluded, by definition. 

### Exercise 4

Voting is the broad topic of this tutorial. Given that topic, which variable in `shaming` should we use as our outcome variable? 

```{r the-question-4}
question_text(NULL,
	message = "The outcome is `primary_06`, which indicates whether the resident voted in the 2006 primary election.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

<!-- DK: Discuss treatments. Explain this plot. -->

```{r}
x |> 
  sample_frac(0.05) |> 
  ggplot(aes(x = treatment, y = primary_06)) +
    geom_jitter(alpha = 0.03, height = 0.1) +
    scale_y_continuous(breaks = c(0, 1), labels = c("No", "Yes")) +
    labs(title = "Postcard and Voting Behavior in Michigan",
         subtitle = "Postcards increase likelihood of voting.",
         x = "Type of Postcard",
         y = "Voted in 2006 Primary Election",
         caption = "Random sample of 5% of the data from Gerber, Green, and Larimer (2008)")
```


### Exercise 5

Let's imagine a brand new variable which **does not exists** in the data. This variable should be binary, meaning that it only takes on one of two values. It should also, at least in theory, by manipulable. In other words, if the value of the variable is "3," or whatever, then it generates one potential outcome and if it is "9," or whatever, it generates another potential outcome.

Describe this imaginary variable and how might we manipulate its value.

For now, ignore the actual treatment variable `treatment` which we will be using later in the analysis. The point of this exercise is to reinforce our understanding of the [Rubin Causal Model](https://ppbds.github.io/primer/rubin-causal-model.html).


```{r the-question-5}
question_text(NULL,
	message = "Imagine a variable called `phone_call` which has a value of `1` if the person received a phone call urging them to vote and `0` if they did not receive such a phone call. We, meaning the organization in charge of making such phone calls, can manipulate this variable by deciding, either randomly or otherwise, whether or not we will call a specific individual.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Any data set can be used to construct a causal model as long as there is at least one covariate that we can, at least in theory, manipulate. It does not matter whether or not anyone did, in fact, manipulate it. 

### Exercise 6

Given our (imaginary) treatment variable `phone_call`, how many potential outcomes are there for each person? Explain why.

```{r the-question-6}
question_text(NULL,
	message = "There are 2 potential outcomes because the treatment variable `phone_call` takes on 2 possible values: received a get-out-the-vote phone call or did not.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The same data set can be used to create, separately, lots and lots of different models, both causal and predictive. We can just use different outcome variables and/or specify different treatment variables. This is a *conceptual* framework we apply to the data. It is never inherent in the data itself.

### Exercise 7

In a few sentences, specify the two different values for the imaginary treatment variable `phone_call`, for a single unit, guess at the potential outcomes which would result, and then determine the causal effect for that unit given those guesses.

```{r the-question-7}
question_text(NULL,
	message = "For a given person, assume that the value of the treatment variable might be received a phone call or did not receive phone call. If the person gets the phone call, then her voting behavior would be that she did vote. If the person gets no phone call, then her voting behavior might be not to vote. The causal effect on the outcome of a treatment of receiving-call versus no-call is voting minus not voting --- i.e., the difference between two potential outcomes --- which does not have a numeric value. That difference is still the causal effect, even if we can't assign a number to it. In many cases, we will just assign arbitrary numbers to the outcomes --- say 1 for voting and 0 for not-voting. Doing so allows us to report a numeric causal effect. But keep in mind that any such numbers are arbitrary.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The definition of a causal effect is the difference between two potential outcomes. Of course, you can't just say that the causal effect is 10. The exact value depends on which potential outcome comes first in the subtraction and which second. There is, perhaps, a default sense in which the causal effect is defined as treatment minus control. 

Any causal connection means exploring the *within row* difference between two potential outcomes. We don't need to look at any other rows to have that conversation.

### Exercise 8

Let's consider a *predictive* model. Which variable in `shaming` do you think might have an important connection to `primary_06`? 

```{r the-question-8}
question_text(NULL,
	message = "The person's `age` is probably connected to `primary_06`, but so are other variables like `treatment` and past voting behavior.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

With a predictive model, there is only one outcome for each individual unit. There are not two potential outcomes because we are not considering any of the covariates to be a treatment variable. We assuming that the values of all covariates are "fixed." 

There are no "treatments" in predictive models. There are only covariates.

### Exercise 9

Specify two different groups of people which have different values for `age` and which might have different average values for the `primary_06`.  

```{r the-question-9}
question_text(NULL,
	message = "Some people might have a value for `age` younger than 40. Others might have a value older than 40. Those two groups will, on average, have different values for the `primary_06`.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In predictive models, do not use words like "cause," "influence," "impact," or anything else which suggests causation. The best phrasing is in terms of "differences" between groups of units with different values for a covariate of interest.

### Exercise 10

Write a causal question which connects the outcome variable `primary_06` to `treatment`, the covariate of interest. 

```{r the-question-10}
question_text(NULL,
	message = "What is the causal effect on voting of receiving a postcard which encourages one to vote?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The answer to this question is your "Quantity of Interest." 

Our Quantity of Interest might appear too specific, too narrow to capture the full complexity of the topic. There are many, many numbers in which we are interested, many numbers that we want to know. But we don't need to list them all here! We just need to choose one of them since our goal is just to have a specific number which helps to guide us in the creation of the Preceptor Table and, then, the model.

## Wisdom
### 

*Wonder is the beginning of wisdom.* - Socrates

Our question:

> *What is the causal effect on voting of receiving a postcard which encourages one to vote?*

### Exercise 1

In your own words, describe the key components of Wisdom when working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The central problem for Wisdom is: Can we use data from a primary election in 2006 in Michigan to estimate the relationships in Texas today?

### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, we can easily calculate the quantity of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table does not include all the covariates which you will eventually include in your model. It only includes covariates which you need to answer your question.

### Exercise 3

Run `glimpse()` on `shaming`.

CP/CR.

```{r wisdom-3, exercise = TRUE}

```

```{r wisdom-3-test, include = FALSE}

```

###

Our outcome variable, `primary_06`, is just 0/1, indicating whether or not someone voted in the 2006 Michigan primary election. But that is not what we, as a gubernatorial candidate, really care about! We want to know who someone voted for, or at least which party, not whether or not they voted. Annoying! 

### Exercise 4

Pipe `shaming` to `count(treatment)`.

CP/CR.

```{r wisdom-4, exercise = TRUE}

```

```{r wisdom-4-test, include = FALSE}
shaming |> 
    count(treatment)
```

###

Most people did not receive a postcard at all. They are the control case. Everyone else had a 25% chance of receiving a postcard, each with a different message. Those are the four possible treatments.

### Exercise 5

Run this code:

```{r wisdom-5, exercise = TRUE}
shaming |> 
  mutate(civ_engage = primary_00 + primary_02 + primary_04 + 
                      general_00 + general_02 + general_04) |> 
   count(civ_engage)            
```

```{r wisdom-5-test, include = FALSE}
shaming |> 
  mutate(civ_engage = primary_00 + primary_02 + primary_04 + 
               general_00 + general_02 + general_04) |> 
   count(civ_engage)  
```

###

We are interested in the causal effect of postcards. But we suspect that the causal effect varies. It is different for different sorts of people, for example people who differ in their level of civic engagement. For simplicity, we create such a measure based on how often someone voted in the previous six elections. 

### Exercise 6

Replace `count(civ_engage)` with a `select()` statement which only keeps these variables: `primary_06`, `treatment`, `sex`, `age`, `civ_engage`. 

```{r wisdom-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r wisdom-6-hint-1, eval = FALSE}
... |> 
	select(primary_06, treatment, sex, age, civ_engage)
```

```{r wisdom-6-test, include = FALSE}
shaming |> 
  mutate(civ_engage = primary_00 + primary_02 + primary_04 + 
               general_00 + general_02 + general_04) |> 
  select(primary_06, treatment, sex, age, civ_engage)
```

###

The sooner we restrict our tibble to just the variables we care about, the better. Of course, nothing prevents us from circling back and looking at other variables which might be important. But, at some point, you make your best guess and then move on.


### Exercise 7

Use AI to continue the pipe to add a new variable, `voter_class`, a factor which takes on the values "Always Vote" when `civ_engage %in% c(5, 6)`, "Sometimes Vote" when `civ_engage %in% c(3, 4)`, and "Rarely Vote" when `civ_engage %in% c(1, 2)`. Also, the levels for `voter_class` are ordered with "Rarely Vote" the lowest and "Always Vote" the highest.


```{r wisdom-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r wisdom-7-hint-1, eval = FALSE}

```

```{r wisdom-7-test, include = FALSE}
shaming |> 
  mutate(civ_engage = primary_00 + primary_02 + primary_04 + 
               general_00 + general_02 + general_04) |> 
  select(primary_06, treatment, sex, age, civ_engage) |> 
  mutate(voter_class = factor(
    case_when(
      civ_engage %in% c(5, 6) ~ "Always Vote",
      civ_engage %in% c(3, 4) ~ "Sometimes Vote",
      civ_engage %in% c(1, 2) ~ "Rarely Vote"),
         levels = c("Rarely Vote", 
                    "Sometimes Vote", 
                    "Always Vote"))) 
```

###

Our code looks like this:

````
shaming |> 
  mutate(civ_engage = primary_00 + primary_02 + primary_04 + 
               general_00 + general_02 + general_04) |> 
  select(primary_06, treatment, sex, age, civ_engage) |> 
  mutate(voter_class = factor(
    case_when(
      civ_engage %in% c(5, 6) ~ "Always Vote",
      civ_engage %in% c(3, 4) ~ "Sometimes Vote",
      civ_engage %in% c(1, 2) ~ "Rarely Vote"),
         levels = c("Rarely Vote", 
                    "Sometimes Vote", 
                    "Always Vote")))
````

Your code might look different, but it should have the same effect.

### Exercise 8

Our outcome variable, `primary_06`, is an integer. That is fine for some R models, but not for the models which we will end up using in this tutorial. So, add one last line to the pipe which uses `mutate()` to create a new variable, `voted`, which equals `as.factor(primary_06)`.

```{r wisdom-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r wisdom-8-hint-1, eval = FALSE}

```

```{r wisdom-8-test, include = FALSE}
shaming |> 
  mutate(civ_engage = primary_00 + primary_02 + primary_04 + 
               general_00 + general_02 + general_04) |> 
  select(primary_06, treatment, sex, age, civ_engage) |> 
  mutate(voter_class = factor(
    case_when(
      civ_engage %in% c(5, 6) ~ "Always Vote",
      civ_engage %in% c(3, 4) ~ "Sometimes Vote",
      civ_engage %in% c(1, 2) ~ "Rarely Vote"),
         levels = c("Rarely Vote", 
                    "Sometimes Vote", 
                    "Always Vote"))) |> 
  mutate(voted = as.factor(primary_06))					
```

###

In real work, we often go back-and-forth between data cleaning and modeling work. We don't know, at the start, that we want the dependent variable to be a factor rather than an integer. But, once we do discover this, we change the data cleaning code accordingly.

### Exercise 9

Behind the scenes, we have assigned the result of this pipe to `x`. Type `x` and hit `Enter`.

```{r wisdom-9, exercise = TRUE}

```

```{r wisdom-9-test, include = FALSE}
x
```

###

````
> x
> x
A tibble: 344,084 × 7
   primary_06 treatment   sex      age civ_engage voter_class    voted
        <int> <fct>       <chr>  <int>      <int> <fct>          <fct>
 1          0 Civic Duty  Male      65          4 Sometimes Vote 0    
 2          0 Civic Duty  Female    59          4 Sometimes Vote 0    
 3          1 Hawthorne   Male      55          4 Sometimes Vote 1    
 4          1 Hawthorne   Female    56          4 Sometimes Vote 1    
 5          1 Hawthorne   Female    24          4 Sometimes Vote 1    
 6          0 No Postcard Male      25          1 Rarely Vote    0    
````

Note how the process of cleaning the data starts to make the data, which is just a table with rows and columns, look like the Preceptor Table. This is necessary since we will soon, conceptually, stack the Preceptor Table on top of the data in order to make the Population Table.

### Exercise 10

Describe the key components of Preceptor Tables in general, without worrying about this specific problem. Use words like "units," "outcomes," and "covariates."

```{r wisdom-10}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will considered a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This problem is causal so one of the covariates is a treatment. In our problem, the treatment is `treatment`. There is a potential outcome for each of the 5 possible values of the treatment.

### Exercise 11

Create a Github repo called `postcards`. Make sure to click the "Add a README file" check box.

Connect the Github repo to a project on your computer. Use a folder name which matches your repo name.

Select `File -> New File -> Quarto Document ...`. Provide a title -- `"Voting and Postcards"` -- and an author (you). Render the document and save it as `postcards.qmd`.

Edit the `.gitignore` by adding `*_files` and a blank line. Save and push.

In the Console, run:

```         
show_file(".gitignore")
```

CP/CR.

```{r wisdom-11}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 7)
```

### 

We model units, but we only really care about aggregates.

### Exercise 12

What are the units for this problem?

```{r wisdom-12}
question_text(NULL,
	message = "The units of our Preceptor Table are individual voters in Texas around the time of the next election.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Specifying the Preceptor Table forces us to think clearly about the units and outcomes implied by the question. The resulting discussion sometimes leads us to modify the question with which we started. No data science project follows a single direction. We always backtrack. There is always dialogue.

### Exercise 13

What is the outcome variable for this problem?

```{r wisdom-13}
question_text(NULL,
	message = "Candidate voted for in next Texas gubernatorial election.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The outcome variable that we really care about is often not the outcome variable included in our data. In this case, the Preceptor Table outcome is which candidate a person voted for. The data does not include the voting decision! Instead, it just records whether or not someone voted. Those are not the same things!

This compromise --- working with what we *have* rather than what we really *want* --- is a part of most data science work in the real world.

In this case, we adjust our Preceptor Table to match our data more closely. Instead of looking at the effect of postcards on who someone votes for, we will focus on the effect of postcards on someone's decision to vote at all.

### Exercise 14

What is a covariate which you think might be useful for this problem, regardless of whether or not it might be included in the data?

```{r wisdom-14}
question_text(NULL,
	message = "Donation history. I bet that people who have donated money to a candidate are much more likely to vote than those who have not.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The term "covariates" is used in at least three ways in data science. First, it is all the variables which might be useful, regardless of whether or not we have the data. Second, it is all the variables for which we have data. Third, it is the set of variables in the data which we end up using in the model.

### Exercise 15

What are the treatments, if any, for this problem?

```{r wisdom-15}
question_text(NULL,
	message = "The `treatment` variable indicates the type of postcard that someone received, including no postcard at all. The values of `treatment` are 'No Postcard', 'Civic Duty', 'Hawthorne', 'Self', and 'Neighbors'.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Remember that a treatment is just another covariate which, for the purposes of this specific problem, we are assuming can be manipulated, thereby, creating five potential outcomes for each unit.

### Exercise 16

What moment in time does the Preceptor Table refer to?

```{r wisdom-16}
question_text(NULL,
	message = "We care about the upcoming Texas election.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 3)
```

### 

```{r}
x |> 
    ggplot(aes(x = age, fill = factor(primary_06))) +
        geom_bar(position = "dodge") +
        scale_fill_manual(values = c("0" = "skyblue", "1" = "coral"),
                          labels = c("0" = "Did Not Vote", 
                                     "1" = "Voted"),
                          name = NULL) +
        scale_y_continuous(labels = label_comma()) +
        labs(title = "Voting Behavior in the 2006 Michigan Primary",
             subtitle = "Old people are much more likely to vote",
             x = "Age",
             y = NULL,
             caption = "Gerber, Green, and Larimer (2008)")
```

There were many more people age 18-22 registered to Michigan in 2006 than age 27-31. It is unclear to us why that should be.

> *You can never look at the data too much. -- Mark Engerman*

### Exercise 17

Define a causal effect. 

```{r wisdom-17}
question_text(NULL,
	message = "A causal effect is the difference between two potential outcomes.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

According to the Rubin Causal Model, there must be two (or more) potential outcomes for any discussion of causation to make sense. This is simplest to discuss when the treatment only has two different values, thereby generating only two potential outcomes. 

### Exercise 18

What is the fundamental problem of causal inference?

```{r wisdom-18}
question_text(NULL,
	message = "The fundamental problem of causal inference is that we can only observe one potential outcome.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If the treatment variable is continuous (like income), then there are lots and lots of potential outcomes, one for each possible value of the treatment variable. 

### Exercise 19

How does the motto "No causation without manipulation" apply in this problem?

```{r wisdom-19}
question_text(NULL,
	message = "The motto works because we can manipulate, randomly or otherwise, who receives which postcard. Since the treatment variable can be manipulated, it is reasonable to estimate a causal effect.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We need to keep track of how these issues apply to both our Preceptor Table and our data. 

### Exercise 20

Describe in words the Preceptor Table for this problem. Assume that, in addition to `treatment`, we are interested in a covariate connected to some measure of "civic engagement."

```{r wisdom-20}
question_text(NULL,
	message = "The Preceptor Table has 5 columns. There is a column for the ID, two for the outcomes: Voting After Control and Voting After Treatment. There two covariates: Treatment and Engagement. Each row represents one individual.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table for this problem looks something like this:

```{r}
#| echo: false
tibble(ID = c("1", "2", "...", "10", "11", "...", "N"),
       voting_after_treated = c("1", "1", "...", "1", "0", "...", "1"),
       voting_after_control = c("1", "0", "...", "1", "1", "...", "0"),
       treatment = c("Yes", "No", "...", "Yes", "Yes", "...", "No"),
       engagement = c("1", "3", "...", "6", "2", "...", "2")) |>
  
  gt() |>
  tab_header(title = "Preceptor Table") |> 
  cols_label(ID = md("ID"),
             voting_after_treated = md("Voting After Treatment"),
             voting_after_control = md("Voting After Control"),
             treatment = md("Treatment"),
             engagement = md("Engagement")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(ID))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(ID))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Covariates", columns = c(treatment, engagement)) |>
  tab_spanner(label = "Outcomes", columns = c(voting_after_control, voting_after_treated))
```

Like all aspects of a data science problem, the Preceptor Table evolves as we continue our work. In particular, although the first version of the Preceptor Table (what we really want) included which candidate each person voted for, now --- given the limitations of our data --- we just ask whether or not each person voted at all.

Also, some of our covariates will evolve. We might use the simple integer measure of civic engagement --- How many of the last six elections did the person vote in? --- or the three values for class of voter. There is no right answer.

### Exercise 21

In your QMD, load the **tidyverse** and the **primer.data** packages in a new code chunk. Render the file.

Notice that the file does not look good because the code is visible and there are annoying messages. To take care of this, add `#| message: false` to remove all the messages in the `setup` chunk. Also add the following to the YAML header to remove all code echos from the whole file:

```         
execute: 
  echo: false
```

In the Console, run:

```         
show_file("postcards.qmd", start = -5)
```

CP/CR.

```{r wisdom-21}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

### 

Render again. Everything looks nice because we have added code to make the file look better and more professional.

### Exercise 22

Add a new code chunk which creates the object `x`, using the code above.

In the Console, run:

```         
show_file("postcards.qmd", start = -5)
```

CP/CR.

```{r wisdom-22}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

### 

Render again. 

### Exercise 23

In your own words, define "validity" as we use the term.

```{r wisdom-23}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Validity is always about the *columns* in the Preceptor Table and the data. Just because columns from these two different tables have the same *name* does not mean that they are the same *thing*.

### Exercise 24

Provide one reason why the assumption of validity might not hold for the outcome variable `primary_06` or for one of the covariates. Use the words "column" or "columns" in your answer.

```{r wisdom-24}
question_text(NULL,
	message = "The output column in the data is whether or not someone voted in a primary election. The output column in the Preceptor Table is, now, whether or not someone voted in a general election. But primary elections and general elections are not the same thing! It is a violation of validity to pretend that they are.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In order to consider the Preceptor Table and the data to be drawn from the same population, the columns from one must have a *valid correspondence* with the columns in the other. Validity, if true (or at least reasonable), allows us to construct the Population Table, which is the first step in Justice.

Because we control the Preceptor Table and, to a lesser extent, the original question, we can adjust those variables to be “closer” to the data that we actually have. This is another example of the iterative nature of data science. If the data is not close enough to the question, then we check with our boss/colleague/customer to see if we can modify the question in order to make the match between the data and the Preceptor Table close enough for validity to hold.

Despite these potential problems, we will assume that validity holds since it, mostly (?), does.

### Exercise 25

Over the course of this tutorial, we will be creating a summary paragraph. The purpose of this exercise is to write the first two sentences of that paragraph.

The first sentence is a general statement about the overall topic, mentioning both the general class of the outcome variable and of at least one of the covariates. It is **not** connected to the initial "Imagine that you are XX" which set the stage for this project. That sentence can be rhetorical. It can be trite, or even a platitude. The purpose of the sentence to let the reader know, gently, about our topic.

The second sentence does two things. First, it introduces the data source. Second, it introduces the specific question. The sentence can't be that long. Important aspects of the data include when/where it was gather, how many observations it includes and the organization (if famous) which collected it.

Type your two sentences below.

```{r wisdom-25}
question_text(NULL,
	message = "Sending postcards and other mailings to registered voters is a traditional part of US political campaigns. Using data from a 2006 experiment in Michigan, we seek to explore the likely causal effects of sending postcards to voters in the current gubernatorial campaign in Texas.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Read our answer. It will not be the same as yours. You can, if you want, change your answer to incorporate some of our ideas. Do not copy/paste our answer exactly. Add your two sentences, edited or otherwise, to your QMD, `Command/Ctrl + Shift + K`, and then commit/push.

## Justice
### 

*Justice delayed is justice denied.* - William E. Gladstone

### Exercise 1

In your own words, name the four key components of Justice when working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Justice is about concerns that you (or your critics) might have, reasons why the model you create might not work as well as you hope. 

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Population Table is almost always much bigger than the combination of the Preceptor Table and the data because, if we can really assume that both the Preceptor Table and the data are part of the same population, than that population must cover a broad universe of time and units since the Preceptor Table and the data are, themselves, often far apart from each other.

### Exercise 3

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-3}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The longer the time period covered by the Preceptor Table (and the data), the more suspect the assumption of stability becomes. 

### Exercise 4

Provide one reason why the assumption of stability might not be true in this case.

```{r justice-4}
question_text(NULL,
	message = "It is possible, for instance, that a postcard informing neighbors of voting status has a bigger effect in a world with more social media.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A change in time or the distribution of the data does not, in and of itself, demonstrate a violation of stability. Stability is about the parameters: $\beta_0$, $\beta_1$ and so on. Stability means these parameters are the same in the data as they are in the population as they are in the Preceptor Table.

### Exercise 5

We use our data to make inferences about the overall population. We use information about the population to make inferences about the Preceptor Table: `Data -> Population -> Preceptor Table`. In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-5}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationships among the rows in the Population Table. The first is between the data and the other rows. The second is between the other rows and the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case.

### Exercise 6

We do not use the data, directly, to estimate missing values in the Preceptor Table. Instead, we use the data to learn about the overall population. Provide one reason, involving the relationship between the data and the population, for why the assumption of representativeness might not be true in this case. 

```{r justice-6}
question_text(NULL,
	message = "All the data is from Michigan, which is, by definition, not necessarily representative of all the other states in the country.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The reason that representativeness is important is because, when it is violated, the estimates for the model parameters might be biased. 

### Exercise 7

We use information about the population to make inferences about the Preceptor Table. Provide one reason, involving the relationship between the population and the Preceptor Table, for why the assumption of representativeness might not be true in this case.

```{r justice-7}
question_text(NULL,
	message = "Even if Michigan were representative of the larger population, Texas certainly is not. That is, the rows in the Preceptor Table are not a random draw from the larger population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability looks across time periods. Representativeness looks within time periods, for the most part. 

### Exercise 8

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-8}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This assumption is only relevant for causal models. We describe a model as "confounded" if this is not true. The easiest way to ensure unconfoundedness is to assign treatment randomly.

### Exercise 9

Provide one reason why the assumption of unconfoundedness might not be true (or relevant) in this case.

```{r justice-9}
question_text(NULL,
	message = "The experiment should be randomized, but there is a possibility that the people who ran the experiment did not actually make it fully randomized. It is easy to lie and say that there was randomization, but we can not know for sure if this was truly random assignment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The great advantage of randomized assignment of treatment is that it guarantees unconfoundedness, *if the randomization is done correctly*. There is no way for treatment assignment to be correlated with anything, including potential outcomes, if treatment assignment is random, and *if the experimental set up worked as designed.* Sadly, in the real world, there are sometimes problems.

### Exercise 10

Write one sentence which highlights a potential weakness in your model. This will almost always be derived from possible problems with the assumptions discussed above. We will add this sentence to our summary paragraph. So far, our version of the summary paragraph looks like this:

> Sending postcards and other mailings to registered voters is a traditional part of US political campaigns. Using data from a 2006 experiment in Michigan, we seek to explore the likely causal effects of sending postcards to voters in the current gubernatorial campaign in Texas.

Of course, your version will be somewhat different.

```{r justice-10}
question_text(NULL,
	message = "We are concerned that data from Michigan might not be representative of the United States as a whole.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Add a weakness sentence to the summary paragraph in your QMD. You can modify your paragraph as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`, and then commit/push.


## Courage
### 

*Courage is going from failure to failure without losing enthusiasm.* - Winston Churchill

### Exercise 1

In your own words, describe the components of the virtue of Courage for analyzing data.

```{r courage-1}
question_text(NULL,
	message = "Courage starts with math, explores models, and then creates the data generating mechanism.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A statistical model consists of two parts: the *probability family* and the *link function*. The probability family is the probability distribution which generates the randomness in our data. The link function is the mathematical formula which links our data to the unknown parameters in the probability distribution. 

### Exercise 2

Load the [**tidymodels**](https://www.tidymodels.org/) package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(tidymodels)
```

### 

The probability family is determined by the outcome variable $Y$. 

Since $Y$ is a binary variable (with exactly two possible values), the probability family is Bernoulli.

$$Y \sim \text{Bernoulli}(\rho)$$

where $\rho$ is the probability that one of the two possible values --- conventionally referred to as `1` or `TRUE` --- occurs. By definition, $1 - \rho$ is the probability of the other value.

### Exercise 3

Load the [**broom**](https://broom.tidymodels.org/) package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(broom)
```

### 

The link function, the basic mathematical structure of the model, is (mostly) determined by the type of outcome variable. 

For a binary outcome variable, we use a log-odds model:

$$
\log\left[ \frac { \rho }{ 1 - \rho } \right] = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots 
$$


### Exercise 4

Use AI to come up with a $\LaTeX$ representation of the mathematical structure of the model, with $Y$ as the dependent variable and $X_1$, $X_2$ and so on as the independent variables. This version will not have the values of any parameters since we have not, yet, estimated them. Confirm that the $\LaTeX$ code works by placing it in your QMD and then rendering. Paste that $\LaTeX$ code below.

```{r courage-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###

$$P(Y = 1) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_n X_n)}}$$

with $Y \sim \text{Bernoulli}(\rho)$ where $\rho$ is the probability above.

Which we created with $\LaTeX$ code that looks like this:

````
$$P(Y = 1) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_n X_n)}}$$

with $Y \sim \text{Bernoulli}(\rho)$ where $\rho$ is the probability above.
````

This follows the logistic regression form for binary data, where the $\beta$ coefficients represent the effect of predictors on the log-odds of the outcome.

We use generic variables --- $Y$, $X_1$ and so on --- because our purpose is to describe the general mathematical structure of the model, independent of the specific variables we will eventually choose to use.

### Exercise 5

Add `library(tidymodels)` and `library(broom)` to the `setup` code chunk in your QMD. `Command/Ctrl + Shift + K`.

At the Console, run:

```
tutorial.helpers::show_file("postcards.qmd", pattern = "library")
```

CP/CR.

```{r courage-5}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Having decided on the basic mathematical structure of the model, a choice mostly driven by the distribution of our outcome variable, we now turn toward estimating the model.

### Exercise 6

Because our outcome variable is binary, start to create the model by entering `logistic_reg(engine = "glm")`.

```{r courage-6, exercise = TRUE}

```

```{r courage-6-hint-1, eval = FALSE}
logistic_reg(engine = "glm")
```

```{r courage-6-test, include = FALSE}
logistic_reg(engine = "glm")
```

### 

The *[tidymodels](https://www.tidymodels.org/)* framework is the most popular one in the R world for estimating models. *[Tidy Modeling with R](https://www.tmwr.org/)* by Max Kuhn and Julia Silge is a great introduction.

### Exercise 7

Continue the pipe to `fit(voted ~ sex, data = x)`.

```{r courage-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-7-hint-1, eval = FALSE}
... |> 
  fit(..., data = ...)
```

```{r courage-7-test, include = FALSE}
logistic_reg(engine = "glm") |> 
	fit(voted ~ sex, data = x)
```

### 

<!-- DK: Add this as a question and then discuss the error message. After discussing, start using `voted` variable. Did we create that above? -->

If you had tried, `fit(primary_06 ~ sex, data = x)` instead, you would get an error message: "For a classification model, the outcome should be a <factor>, not an integer vector." This is why we created `voted` as a factor variable above.

Recall that a categorical variable (whether character or factor) like `sex` is turned into a $0/1$ "dummy" variable which is then re-named something like $sex{Male}$. After all, we can't have words --- like "Male" or "Female" --- in a mathematical formula, hence the need for dummy variables.

### Exercise 8

Continue the pipe with `tidy(conf.int = TRUE)`.

```{r courage-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-8-hint-1, eval = FALSE}
...
  tidy(... = TRUE)
```

```{r courage-8-test, include = FALSE}
logistic_reg(engine = "glm") |> 
	fit(voted ~ sex, data = x) |> 
	tidy(conf.int = TRUE)
```

### 

The meaning of the magnitude of the coefficient values are much harder to interpret in logistic models then they are in linear models. But, the fact that the coefficient of $sexMale$ is positive means that men are more likely to vote than women, and the fact that the confidence interval excludes zero means that we can be fairly certain of that claim.

### Exercise 9

Change the call to `fit()` to `fit(voted ~ voter_class, data = x)`.

```{r courage-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-9-hint-1, eval = FALSE}
... |> 
  fit(..., data = ...)
  ...
```

<!-- Testing takes too long. -->

### 

The same dummy variable approach applies to a categorical covariate with $N$ values. Such cases produce $N-1$ dummy $0/1$ variables. The presence of an intercept in most models means that we can't have $N$ categories. The "missing" category is incorporated into the intercept. Since `voter_class` has three values --- "Rarely Vote", "Sometimes Vote", and "Always Vote" --- the model creates two 0/1 dummy variables, giving them names like $voter_classSometimes Vote$ and $voter_classAlways Vote$. The results for the *first* category are included in the intercept, which becomes the reference case, relative to which the other coefficients are applied.

Because the coefficients of the dummy variables for "Sometimes Vote" and "Always Vote" are positive, and their confidence intervals exclude zero, we can be fairly certain that people in these categories are more likely to vote than "Rarely Vote" voters. This is not a tautology since `voter_class` is calculated from campaigns prior to the 2006 primary.

### Exercise 10

Change the call to `fit()` to `fit(voted ~ sex + age + treatment + voter_class, data = x)`.

```{r courage-10, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-10-test, include = FALSE}
fit_vote_1
```

### 

```{r}
coefs_vote_1
```

The `(Intercept)`, as always, describes the situation for members of the groups which are excluded from all the categorical variables. In this case, it is females who receive no postcard and never vote. Relative to that "reference" group, all other types of people are more likely to vote. And, given that all those estimates exclude zero, we can be fairly certain that this result is not due to chance.

### Exercise 11

Change the call to `fit()` to `fit(voted ~ sex + age + treatment*voter_class, data = x)`. This is just like our last model, but it adds interaction terms between `treatment` and `voter_class`.

```{r courage-11, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-11-test, include = FALSE}
fit_vote_2
```

### 

```{r}
coefs_vote_2
```

The more variables we add, the more difficult it is to interpret the meaning of any particular coefficient. But interpretation also becomes less important. We don't really care about coefficients. We care about using our model to estimate quantities of interest.

<!-- DK: Add questions to help choose between the models. -->

### Exercise 12

Behind the scenes of this tutorial, an object called `fit_vote` has been created which is the result of the code above. Type `fit_vote` and hit "Run Code." This generates the same results as using `print(fit_vote)`.

```{r courage-12, exercise = TRUE}

```

```{r courage-12-hint-1, eval = FALSE}
fit_vote
```

```{r courage-12-test, include = FALSE}
fit_vote
```

### 

In data science, **we deal with words, math, and code, but the most important of these is code.** We created the mathematical structure of the model and then wrote a model formula in order to estimate the unknown parameters. 

### Exercise 13

Load the **[easystats](https://easystats.github.io/easystats/)** package.

```{r courage-13, exercise = TRUE}

```

```{r courage-13-hint-1, eval = FALSE}
library(...)
```

```{r courage-13-test, include = FALSE}
library(easystats)
```

###

We don't add **easystats** to the QMD because we are only using it for an interactive check of our fitted model. However, the [easystats ecosystem](https://easystats.github.io/easystats/) has a variety of interesting functions and packages which you might want to explore.

### Exercise 14

In the Console, run `check_predictions(fit_vote)`. (This will produce an error.) CP/CR.

```{r courage-14, exercise = TRUE}

```

```{r courage-14-hint-1, eval = FALSE}
check_predictions(...)
```

```{r courage-14-test, include = FALSE}
# check_predictions(fit_vote)
```

###

<!-- DK: Fix this! -->

It is not clear to us why `check_predictions()` fails for this model. Our apologies!

### Exercise 15

Ask AI to create $\LaTeX$ code for this model, including our variable names and estimates for all the coefficients. Because this is a fitted model, the dependent variable will have a "hat" and the formula will not include an error term. 

Add the code to your QMD. `Cmd/Ctrl + Shift + K`.

Make sure the resulting display looks good. For example, you don't want an absurd number of figures to the right of the decimal. If the model is too long, you will need to spread it across several lines. You may need to go back-and-forth with the AI a few times.

Once the $\LaTeX$ code looks good, paste it below.

```{r courage-15}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

###

Our formula looks like:

$$
\begin{align}
\log\left(\frac{P(\text{voted} = 1)}{1 - P(\text{voted} = 1)}\right) &= -2.43 + 0.01 \cdot \text{age} + 0.04 \cdot \text{sexMale} + 0.09 \cdot \text{treatmentCivic Duty} + 0.07 \cdot \text{treatmentHawthorne} \\
&\quad + 0.20 \cdot \text{treatmentSelf} + 0.36 \cdot \text{treatmentNeighbors} + 0.82 \cdot \text{voter_classSometimes Vote} \\
&\quad + 1.61 \cdot \text{voter_classAlways Vote} + 0.03 \cdot \text{treatmentCivic Duty} \times \text{voter_classSometimes Vote} \\
&\quad + 0.06 \cdot \text{treatmentHawthorne} \times \text{voter_classSometimes Vote} + 0.05 \cdot \text{treatmentSelf} \times \text{voter_classSometimes Vote} \\
&\quad + 0.04 \cdot \text{treatmentNeighbors} \times \text{voter_classSometimes Vote} - 0.05 \cdot \text{treatmentCivic Duty} \times \text{voter_classAlways Vote} \\
&\quad + 0.06 \cdot \text{treatmentHawthorne} \times \text{voter_classAlways Vote} - 0.01 \cdot \text{treatmentSelf} \times \text{voter_classAlways Vote} \\
&\quad + 0.01 \cdot \text{treatmentNeighbors} \times \text{voter_classAlways Vote}
\end{align}
$$

It was created with:

````
$$
\begin{align}
\log\left(\frac{P(\text{voted} = 1)}{1 - P(\text{voted} = 1)}\right) &= -2.43 + 0.01 \cdot \text{age} + 0.04 \cdot \text{sexMale} + 0.09 \cdot \text{treatmentCivic Duty} + 0.07 \cdot \text{treatmentHawthorne} \\
&\quad + 0.20 \cdot \text{treatmentSelf} + 0.36 \cdot \text{treatmentNeighbors} + 0.82 \cdot \text{voter_classSometimes Vote} \\
&\quad + 1.61 \cdot \text{voter_classAlways Vote} + 0.03 \cdot \text{treatmentCivic Duty} \times \text{voter_classSometimes Vote} \\
&\quad + 0.06 \cdot \text{treatmentHawthorne} \times \text{voter_classSometimes Vote} + 0.05 \cdot \text{treatmentSelf} \times \text{voter_classSometimes Vote} \\
&\quad + 0.04 \cdot \text{treatmentNeighbors} \times \text{voter_classSometimes Vote} - 0.05 \cdot \text{treatmentCivic Duty} \times \text{voter_classAlways Vote} \\
&\quad + 0.06 \cdot \text{treatmentHawthorne} \times \text{voter_classAlways Vote} - 0.01 \cdot \text{treatmentSelf} \times \text{voter_classAlways Vote} \\
&\quad + 0.01 \cdot \text{treatmentNeighbors} \times \text{voter_classAlways Vote}
\end{align}
$$
````

Note the differences. First, we have replaced the parameters with our best estimates. Second, we have dropped the error term because this is a formula for predicting the value for our outcome variable. Third, the left-hand side variable is $\widehat{\text{XX}}$ instead of $\text{XX}$ because this formula generates our estimated `XX`. A hat indicates an estimated value.

**This is our data generating mechanism.**

A data generating mechanism is just a formula, something which we can write down and implement with computer code.

### Exercise 16

Create a new code chunk in your QMD. Add a code chunk option: `#| cache: true`. Copy/paste the code from above for estimating the model into the code chunk, assigning the result to `fit_vote`. 

`Command/Ctrl + Shift + K`. It may take some time to render your QMD, depending on how complex your model is. But, by including `#| cache: true` you cause Quarto to cache the results of the chunk. The next time you render your QMD, as long as you have not changed the code, Quarto will just load up the saved fitted object.

At the Console, run:

```
tutorial.helpers::show_file("postcards.qmd", start = -8)
```

CP/CR.

```{r courage-16}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 8)
```

### 

To confirm, `Command/Ctrl + Shift + K` again. It should be quick.

### Exercise 17

Add `*_cache` to `.gitignore` file. Cached objects are often large. They don't belong on Github.

At the Console, run:

```
tutorial.helpers::show_file(".gitignore")
```

CP/CR.

```{r courage-17}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

###

Because of the change in your `.gitignore` (assuming that you saved it), the cache directory should not appear in the Source Control panel because Git is ignoring it, as instructed. Commit and push. 

### Exercise 18

In the Console, run `tidy()` on `fit_vote` with the argument `conf.int` set equal to `TRUE`. The returns 95% intervals for all the parameters in our model.

```{r courage-18, exercise = TRUE}

```

```{r courage-18-hint-1, eval = FALSE}
tidy(..., conf.int = ...)
```

<!-- Testing takes too long. -->

### 

`tidy()` is part of the [**broom**](https://broom.tidymodels.org/) package, used to summarize information from a wide variety of models.

### Exercise 19

Create a new code chunk in your QMD. Ask AI to help you make a nice looking table from the tibble which is returned by `tidy()`. You don't have to include all the variables which `tidy()` produces. We often just show the estimate and the confidence intervals.

Insert that code into the QMD. 

`Command/Ctrl + Shift + K`. 

Make sure it works. You might need to add some new libraries, e.g., **[tinytable](https://vincentarelbundock.github.io/tinytable/)**, **[knitr](https://yihui.org/knitr/)**, **[gt](https://gt.rstudio.com/)**, **[kableExtra](https://haozhu233.github.io/kableExtra/)**, **[flextable](https://davidgohel.github.io/flextable/)**, **[modelsummary](https://modelsummary.com/)**, et cetera, to the `setup` code chunk, if you use any functions from these packages, all of which have strengths and weaknesses for making tables.

At the Console, run:

```
tutorial.helpers::show_file("postcards.qmd", end = -10)
```

CP/CR.

```{r courage-19}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 12)
```

###

<!-- DK: Our example and the code which created it? -->

At the very least, your table should include a title and a caption with the data source. The more you use AI, the better you will get at doing so.

### Exercise 20

Add a sentence to your project summary. 

Explain the structure of the model. Something like: "I/we model XX [the concept of the outcome, not the variable name], [insert description of values of XX], as a [linear/logistic/multinomial/ordinal] function of XX [and maybe other covariates]." 

Recall the beginning of our version of the summary:

> Sending postcards and other mailings to registered voters is a traditional part of US political campaigns. Using data from a 2006 experiment in Michigan, we seek to explore the likely causal effects of sending postcards to voters in the current gubernatorial campaign in Texas. We are concerned that data from Michigan might not be representative of the United States as a whole.

```{r courage-20}
question_text(NULL,
	message = "We model whether or not a person voted as a logistic function of postcard received interacted with a measure of voter engagement, along with sex and age.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Read our answer. It will not be the same as yours. You can, if you want, change your answer to incorporate some of our ideas. Do not copy/paste our answer exactly. Add your two sentences, edited or otherwise, to summary paragraph portion of your QMD. `Command/Ctrl + Shift + K`, and then commit/push.

## Temperance
### 

*Temperance is a bridle of gold; he, who uses it rightly, is more like a god than a man.* - Robert Burton

### Exercise 1

In your own words, describe the use of Temperance in data science.

```{r temperance-1}
question_text(NULL,
	message = "Temperance uses the data generating mechanism to answer the question with which we began. Humility reminds us that this answer is always a lie. We can also use the DGM to calculate many similar quantities of interest, displaying the results graphically.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Courage gave us the data generating mechanism. Temperance guides us in the use of the DGM — or the “model” — we have created to answer the question(s) with which we began. We create posteriors for the quantities of interest. 

### Exercise 2

Before using the DGM, we should make sure that we can interpret it.

Recall the values for the parameters in our data generating mechanism:

```{r}
coefs_vote_2
```

Interpret the estimate and confidence interval for `age`.

```{r temperance-2}
question_text(NULL,
	message = "Because this is a logistic model, the raw value of the estimate for the coefficient of age, 0.01, does not have a direct interpretation in terms of voting behavior. However, the fact that it is positive means that older people, adjusting for our other covariates, were more likely to vote in the 2006 primary than younger people. And the fact that the confidence interval excludes zero means that we can be fairly confident about that claim.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

Whenever we consider non-treatment variables, we must never use terms like "cause," "impact" and so on. We can't make any statement which implies the existence of more than one potential outcome based on changes in non-treatment variables. We can't make any claims about **within row** effects. Instead, we can only compare **across rows**. Always use the phrase "when comparing X and Y" or something very similar.

### Exercise 3

```{r}
coefs_vote_2[1:7,]
```

Interpret the estimates for the four treatment variables.

```{r temperance-3}
question_text(NULL,
	message = "The coefficients of all the treatment dummy variables are relative to the intercept, which is used to estimate the probability of voting for those who do not receive a postcard. Since all four coefficients are positive, that suggests that the causal effects of each postcard is to increase someone's likehood of voting. That 0.36 is the largest of the treatment coefficients suggests that a postcard with information about your neighbors voting behavior does the most to increase your odds of voting.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

The fact that there are interaction effects means that the above isn't exactly true, but it is probably true, and certainly true for people who Never Vote, since that is the `voter_class` variable which is left out of the list of interaction terms.

The interpretation of a treatment variable is very different than the interpretation of a standard covariate. The key point is that there is no such thing as a causal (versus preditive) data set nor a causal (versus predictive) R code formula. You can use the same data set (and the same R code!) for both causal and predictive models. The difference lies in the assumptions you make.

### Exercise 4

```{r}
coefs_vote_2[10:13,]
```

Interpret the estimated coefficients for the interaction between the treatments and the category of people who sometimes vote.

```{r temperance-4}
question_text(NULL,
	message = "The category which is left out of the regression is 'Rarely Vote.' This means that the coefficients of the interation terms must be interpreted relative to that category. So, the positive coefficients mean that, relative to them, 'Sometimes Vote' people are always more likely to vote, regardless of the postcard which they receive. But the fact that the confidence intervals all include zero means that this result might just be due to chance.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

In other words, there is evidence that the treatment postcards increase the likelihood that someone votes, but there is not much evidence that this treatment effect differs between Rarely Vote and Sometimes Vote people.

Most of the time parameters in a model have no direct relationship with any population value in which we might be interested. This is especially true in complex and/or non-linear models. That is, in those cases, a coefficient of `treatmentCivic Duty:voter_classSometimes Vote` does not "mean" anything. But, in simple, small, linear models, it sometimes happens that a parameter does correspond to something real.

### Exercise 5

In the end, we don't really care about parameters, much less how to interpret them. Parameters are *imaginary*, like unicorns. We care about answers to our questions. Parameters are tools for answering questions. They aren't interesting in-and-of themselves. *In the modern world, all parameters are nuisance parameters.* 

Load the [**marginaleffects**](https://marginaleffects.com/) package.

```{r temperance-5, exercise = TRUE}

```

```{r temperance-5-hint-1, eval = FALSE}
library(...)
```

```{r temperance-5-test, include = FALSE}
library(marginaleffects)
```

### 

We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are generally better than decisions made without them.

### Exercise 6

What is the specific question we are trying to answer? 

```{r temperance-6}
question_text(NULL,
	message = "What is the causal effect on voting of receiving a postcard which encourages one to vote?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Data science projects almost always begin with a broad topic of interest. Yet, in order to make progress, we need to drill down to a specific question. This leads to the creation of a data generating mechanism, which can now be used to answer lots of questions, thus allowing us to explore the original topic more broadly.

### Exercise 7

Run this code:

```
plot_predictions(fit_vote,
				type = "prob",	
                 by = c("sex", "group")) 
```       

```{r temperance-7-test, include = FALSE}
plot_predictions(fit_vote,
				type = "prob",	
                 by = c("sex", "group")) 
```

### 

There are two main differences in using `plot_predictions()`, and other **marginaleffects** functions, with logistic models. First, you need to set `type = "prob"`. This places the predicted value on a probability scale. Second, we need the `group` variable to split out the probabilities, which differ between Male and Female.

In this case, men are slightly more likely to vote than women.

### Exercise 8

Run this code:

```
plot_predictions(fit_vote,
				type = "prob",	
                 by = c("age", "group")) 
```       

```{r temperance-8, exercise = TRUE}

```

```{r temperance-8-test, include = FALSE}
plot_predictions(fit_vote,
				type = "prob",	
                 by = c("age", "group")) 
```

### 

As in the previous plot, the vertical data points need to add to 100% because, for each `age` (as for each `sex` above), the probability of voting must equal one minus the probability of not voting. Younger people are much less likely to vote than older people. The plot gets "jittery" at very old ages because of lack of data but, big picture, the oldest people have about a 50/50 chance of voting in this model.

These are claims about the model --- the data generating mechanism --- which is supposed to capture important aspects of reality. They are not claims about reality itself. We are not just *measuring* the probability of old people voting. We are *modeling* that probability, adjusting for a bunch of other covariates.

### Exercise 9

Run this code:

```
plot_predictions(fit_vote,
				 type = "prob",	
                 by = c("treatment", "group", "voter_class")) 
```       

```{r temperance-9, exercise = TRUE}

```

```{r temperance-9-test, include = FALSE}
plot_predictions(fit_vote,
				 type = "prob",	
                 by = c("treatment", "group", "voter_class")) 
```

### 




<!-- DK: Really ought to add a couple of questions which have students run this:

plot_predictions(fit_vote,
+  type = "prob",
+                  by = c("treatment", "group", "voter_class"), draw = FALSE) 

And then use that 30 row dataframe to build a cool plot by, first dropping the rows that are group 0. Second, subtracting the No Postcard group estimates from the others, so that we have the 12 treatment effects we care about: 4 treatments times three voter classes. Only hack is that the confidence intervals --- we would just use the std.error that we are given --- wouldn;t be quite right, but close enough. -->


### Exercise 10

Work interactively with your QMD to make a beautiful version of this plot. Your title should highlight the key variables. Your subtitle should describe the key takeaway, the sentence/conclusion which readers will, you hope, remember. Your caption should mention the data source. Your axis labels should look nice.

This plot is not directly connected to your question. It answers lots of questions! It might be used by lots of different people. 

Copy the code for your plot here:

```{r temperance-10}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 20)
```

###

Data science often involves this-back-and-forth style of work. First, we need to make a single chunk of code, in this case, a new plot, work well. This requires interactive work between the QMD and the Console. Second, we need to ensure that the entire QMD runs correctly on its own.

### Exercise 11

Finalize the new graphics code chunk in your QMD.

`Command/Ctrl + Shift + K` to ensure that it all works as intended. Don't forget to add `library(marginaleffects)` to your `setup` code chunk.

At the Console, run:

```
tutorial.helpers::show_file("postcards.qmd", start = -8)
```

CP/CR.

```{r temperance-11}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 10)
```


### 


<!-- XX: Discuss some limitations of this model. Remind us of some of the reasons to demonstrate humility. -->

### Exercise 12

Write the last sentence of your summary paragraph. It describes at least one quantity of interest (QoI) and provides a measure of uncertainty about that QoI. (It is OK if this QoI is not the one that you began with. The focus of a data science project often changes over time.)

```{r temperance-12}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Add a final sentence to your summary paragraph in your QMD as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`.

### Exercise 13

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval, if you think either might be warranted.

```{r temperance-13}
question_text(NULL,
	message = "XX: This is another example in which the quality of your answer is important. You might or might not suggest an alternate estimate. I always adjust the estimate toward my own subjective sense of a long-run average and/or typical value and/or zero. But that is not necessary. However, you should always increase the confidence interval since the assumptions of your model are always false.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Always go back to your Preceptor Table, the information which, if you had it, would make answering your question easy. In almost all real world cases, the Preceptor Table and the data are fairly different, not least because validity never holds perfectly. So, even a perfectly estimated statistical model is rarely as useful as we might like.

### Exercise 14

Rearrange the material in your QMD so that the order is graphic, followed by paragraph.  Doing so, of course, requires sensible judgment. For example, the code chunk which creates the fitted model must occur before the chunk which creates the graphic. You can keep or discard the math and any other material at your own discretion.

`Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("postcards.qmd")
```

CP/CR.

```{r temperance-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 30)
```

### 

This is the version of your QMD file which your teacher is most likely to take a close look at.

### Exercise 15

Publish your rendered QMD to GitHub Pages. Copy/paste the resulting url below.

```{r temperance-15}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Commit/push everything.

### Exercise 16

Copy/paste the url to your Github repo.

```{r temperance-16}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

We can never know all the entries in the Preceptor Table. That knowledge is reserved for God. If all our assumptions are correct, then our DGM is true, it accurately describes the way in which the world works. There is no better way to predict the future, or to model the past, than to use it. Sadly, this will only be the case with toy examples involving things like coins and dice. We hope that our DGM is close to the true DGM but, since our assumption are never perfectly correct, our DGM will always be different. The estimated magnitude and importance of that difference is a matter of judgment.

The world confronts us. Make decisions we must.

## Summary
### 

This tutorial supports [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

<!-- XX: Give the final plot and our summary paragraph. And a note indicating how this information might be helpful to the Imagine person we created at the start.  -->


```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
