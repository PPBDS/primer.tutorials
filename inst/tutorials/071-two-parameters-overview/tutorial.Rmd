---
title: 'Two Parameters: Overview'
tutorial:
  id: two-parameters-overview
output:
  learnr::tutorial:
    progressive: yes
    allow_skip: yes
runtime: shiny_prerendered
description: Tutorial questions which follow along with Chapter 7 in the Primer.
---

```{r setup, include = FALSE}
library(learnr)
library(primer.tutorials)
library(tidyverse)
library(primer.data)
library(rstanarm)
library(skimr)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 60, 
        tutorial.storage = "local") 

ch7_female <- nhanes %>%
  filter(survey == 2009, gender == "Female", age >= 18) %>%
  select(weight) %>%
  drop_na()

fit_obj <- stan_glm(data = ch7_female,
                    weight ~ 1, 
                    family = gaussian(), 
                    refresh = 0)

newobs <- tibble(constant = 1)

pp <- posterior_predict(fit_obj,
                  newdata = newobs) %>% 
       as_tibble() %>% 
       mutate_all(as.numeric)

ts <- tibble(student_id = 1:4, 
             test1 = 10:13, 
             test2 = 20:23,
             test3 = 30:33) 

```

```{r copy-code-chunk, child = "../../child_documents/copy_button.Rmd"}
```

```{r info-section, child = "../../child_documents/info_section.Rmd"}
```

## Preliminaries 

### 

In this chapter, there were several functions thrown out there that might need a refresher or a proper introduction. Let's quickly familiarize ourselves with them so we are ready to take on the exercises that follow!

### 

### Exercise 1

Consider this tibble, containing the test scores for three students on four tests.

```{r preliminaries-1, echo = TRUE}
print(ts)
```

Start a new pipe with `ts`. Use `mutate()` to create a new column called `avg` which is the average score for each student across all three tests. (Remember to use `rowwise()` as well as helpter functions like `c_across()` to tell R to compute using the rows of a tibble.)

```{r preliminaries-ex-1, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r preliminaries-1-hint-1, eval = FALSE}
ts %>% 
  rowwise() %>% 
  mutate(avg = ...)
```

```{r preliminaries-1-hint-2, eval = FALSE}
ts %>% 
  rowwise() %>% 
  mutate(avg = mean(c_across(...)))
```

```{r preliminaries-1-hint-3, eval = FALSE}
ts %>% 
  rowwise() %>% 
  mutate(avg = mean(c_across(test1:test3)))
```

### 

### Exercise 2

Start a new pipe with `ts`. Use `mutate()` (as well as `rowwise()` and `c_across()`) to calculate the sum and standard deviation of the test scores for each student.

```{r preliminaries-2, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r preliminaries-2-hint-1, eval = FALSE}
ts %>%
  rowwise() %>%
  mutate(sum = ...,
         sd = ...)
```

```{r preliminaries-2-hint-2, eval = FALSE}
ts %>%
  rowwise() %>%
  mutate(sum = sum(c_across(...)),
         sd = sd(c_across(...)))
```

### 

### Exercise 3

For the remaining questions we will work with the `nhanes` data set. Use `select` to pick the variables `gender`, `age` and `pulse`. Assign the result to an object named `our_data`.

```{r preliminaries-3, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r preliminaries-3-hint-1, eval = FALSE}
... <- nhanes %>% 
        select(...)
```

```{r preliminaries-3-hint-2, eval = FALSE}
our_data <- nhanes %>% 
              select(gender, age, pulse)
```

`our_data` is now available for use in later questions.

### 

### Exercise 4

Before doing any calculations, we should get a rough overview of the data set. Run `skim()` on the tibble `our_data`. 

```{r preliminaries-4}

# This is for the tibble `our_data`. I didn't put it in the
# setup chunk at the beginning since that would make it show
# up in the last exercise when people type it. That may be
# confusing.

our_data <- nhanes %>% 
              select(gender, age, pulse)
```

```{r drop_na, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r preliminaries-4-hint-1, eval = FALSE}
skim(our_data)
```

### 

### Exercise 5

Let's get rid of all rows with any missing values. Remove the observations with NAs by creating a pipe and using `drop_na()`. Save the clean tibble again as `our_data` as you did before.

```{r preliminaries-5}

# Setup from before.

our_data <- nhanes %>% 
              select(gender, age, pulse)
```

```{r drop_na2, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r preliminaries-5-hint-1, eval = FALSE}
... <- our_data %>% 
        drop_na()
```

```{r preliminaries-5-hint-2, eval = FALSE}
our_data <- our_data %>% 
              drop_na()
```

### 

### Exercise 6

The function `ungroup()` removes grouping done by the `group_by()` function. Run the code below to see the tibble `our_data`, which has been grouped by `gender`. 

**Remember**: `group_by()` only affects how the data is grouped for subsequent operations, it does not itself change the appearance of the data!

```{r preliminaries-6}

# Setup from before.

our_data <- nhanes %>% 
              select(gender, age, pulse) %>% 
              drop_na()
```

```{r rowwise3, exercise = TRUE}
our_data  %>%
  group_by(gender)
```

### 

### Exercise 7

Great! Now we are going to show why using `ungroup()` is important. Let's say we wanted to calculate the average age and pulse of males and females.

Notice that `ungroup()` has been placed at the end of both calculations. Run the following code. 

```{r preliminaries-7}

# Setup from before.

our_data <- nhanes %>% 
              select(gender, age, pulse) %>% 
              drop_na()
```

```{r ungroup1, exercise = TRUE}
our_data %>%
  group_by(gender) %>%
  mutate(m_age = mean(age)) %>% 
  mutate(m_pulse = mean(pulse)) %>%
  ungroup()
```

The output shows that the mean age (`m`) is approximately 40.3 years for males and 41.7 years for females. It also shows us that the mean pulse (`x`) is 71.67 bpm for males and 75.42 bpm for females. For both calculations, the data is grouped by `Sex` and separate from one another. 

### 

### Exercise 8

Instead of placing `ungroup()` at the end, we are going to place it in between the two `mutate()` functions. Run the following code.

```{r preliminaries-8}

# This is for the clean tibble `our_data`

our_data <- nhanes %>% 
              select(gender, age, pulse) %>% 
              drop_na()
```

```{r ungroup2, exercise = TRUE}
our_data %>%
  group_by(gender) %>%
  mutate(m_age = mean(age)) %>% 
  ungroup()%>% 
  mutate(x_pulse = mean(pulse)) 
```

Here our mean age (`m`), is still 40.3 years for males and 41.7 years for females. However, our mean pulse (`x`) is 73.55 bpm for every row. Because `group_by(gender)` is removed by `ungroup()` after the first `mutate()` function, the mean score is calculated for _all participants together_, which is what we do not want! Therefore, our first placement of `ungroup()` is correct. 

### 

### Exercise 9

We can `select()` multiple variables using different methods. Suppose we wanted to select the first three variables from `nhanes`, namely `survey`, `gender` and `age`. One way, which we have already seen before, is to type out all names. Run the code below to see this approach in action.

```{r preliminaries-9, exercise = TRUE}
nhanes %>%
  select(survey, gender, age)
```

### 

### Exercise 10

However, being the tech wizards that we are, we want to make things as simple as possible. Recall the `:` operator, which creates a shortcut! Run the following code. 

```{r preliminaries-10, exercise = TRUE}
nhanes %>%
  select(survey:age)
```

As you can see, `:` defines a closed interval. `select` returns all columns from (and including) 'survey' to 'age' in the order they appear in the tibble.

### 

### Exercise 11

Awesome! We can also use `[ ]` to extract columns. This is especially useful when we want to extract variables not by their name, but by their position. Extract the third variable from `nhanes` using this method.  

**Note:** When you use `[ ]` , place a comma before the column number you want to extract. 

```{r preliminaries-11, exercise = TRUE }

```

```{r brackets1-hint, eval = FALSE }
nhanes[...]
```

### 

### Exercise 12

As before, we can combine `[ ]` with the `:` operator to extract multiple variables. Use this method to extract the first two variables from `nhanes`.

```{r preliminaries-12, exercise = TRUE }

```

```{r brackets2-hint-1, eval = FALSE }
nhanes[...:...]
```

```{r brackets2-hint-2, eval = FALSE }
nhanes[,1:2]
```

### 

### Exercise 13

We can use the function `rename()` to change the names of the variables in a tibble. For this, simply set the new name equal to the old name within `rename()`.

Copy your code from the last exercise. Add a pipe and `rename()` "survey" to "year" and "gender" to "sex".

```{r preliminaries-13, exercise = TRUE }

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r set_names-hint-1, eval = FALSE }
nhanes[,1:2] %>% 
  rename(year = ...,
         sex = ...)

```

### 

### Exercise 14

The function `after_stat()` allows us to work with variables that have been calculated by ggplot, like `density` or — in the case of the following code chunk — `count`. In ye olden days of R, you would need to surround your after-stat variables by `..` in order to refer to them (e.g. `..count..`, `..density..`) but using `after_stat()` is the modern way of doing things.

Run the following code chunk.

```{r preliminaries-14, exercise = TRUE}
ggplot(nhanes, aes(age)) +
  geom_histogram(bins = 40, aes(y = after_stat(count/sum(count))))
```

As you can see, the y-axis in the plot shows the relative proportion of each age group. Without our transformation, `geom_histogram()` would display only the absolute number of each group.

### 

## Wisdom

### 

Consider the graph below.

```{r}
ch7 <- nhanes %>% 
  select(age, gender, weight, survey) %>%
  filter(age >= 18, gender == "Female") %>% 
  drop_na()

ch7 %>%
  ggplot(aes(x = weight, color = gender)) + 
  geom_density() + 
  labs(x = "Weight, in kg",
       y = "Density",
       title = "Adult Female Weight in NHANES") +
  theme(legend.position = "none")
```

### 

### Exercise 1

As you can tell, the graph above displays "Adult Female Weight by Gender in NHANES". Let's say our motive behind generating this graph was to answer the question: _What is the probability that the next adult female we meet in Cambridge today will weigh more than 100kg?_ 

Using the concept of **Wisdom**, write a paragraph about whether or not this data is relevant for the problem we face. See *The Primer* for guidance. Make sure to use the terms "Population" and "Preceptor Table".

```{r wisdom-1}
question_text(NULL,
	message = "Our question is about adult females in Cambridge today. The data we have (NHANES) is from a survey distributed to people of all ages in the United States. To determine whether or not our data is relevant for the problem we face, we must first determine the population that we are working with. The population (by definition) must encompass both the data we have (NHANES) and the data from the preceptor table (the data we want to have).\nFirst, the population must include people from all over the world (if we are to assume that we can use United States data to answer questions about people in Cambridge — whether or not this assumption can be made, is a question reserved for Justice).\nSecondly, the population must include data about people in all years at least from 2009 (the earliest year we have data for). If we are to answer questions about people now using data from 2009, we are assuming that the average weight has not significantly changed in the last decade and a bit.\nAs for the rest of our variables (age, gender), they are a subset of our NHANES variables, and so we do not need to make significant additions to our population.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

## Justice 

### Exercise 1

$$y_i = \mu + \epsilon_i$$ \n

$$where \ \ \epsilon_i \sim N(0, \sigma^2)$$
&nbsp;

Recall the mathematical relationship above. Write a paragraph describing, in your own words, what each component of this equation describes in the context of our question. You do not need to figure out how to display the symbols in your answer, just write their names, like "phi," mu," "sigma," "epsilon," "delta," and so on.  

```{r Justice1}
question_text(NULL,
	message = "i, in this case, is an index number used to refer to a specific unit. y_i is the weight of woman number i. mu is the average weight of all women sampled. epsilon_i is the \"error term\", meaning the different between the weight of woman number i, and the average weight. epsilon_i is normally distributed with a mean of 0 and a standard deviation of sigma (variance of sigma squared). The mean being 0 relates to our concept of accuracy; we are assuming that our data is representative enough to be accurate, and so we can expect our average error to be 0. The standard deviation, on the other hand, relates to our concept of precision; the smaller sigma is, the more precise our data is, and the larger sigma is, the less precise our data is.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

### Exercise 2

Great! Next, specify which are the two parameters we want to determine. Also mention which one we care most about and why, writing no more than 2 sentences.

```{r justice-2}
question_text(NULL,
	message = "We are looking for a probability distribution for weights of adult women, so our two parameters will be the average weight (mu) and the standard deviation (sigma). Of the two, mu is far more important because we cannot conclude anything from sigma alone, but we can from mu alone.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

### Exercise 3

Using your own words, explain in 2 sentences why this is a predictive model. 

```{r justice-3}
question_text(NULL,
	message = "This model is predictive because we are not at all concerned about causation. It is predictive because there is only one Y(u) output for each unit u.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

## Courage 

### 

Let's create a Bayesian model of female weight.

### 

### Exercise 1

Start a new pipe with `nhanes`. Use `filter()` to choose rows for **adult women** surveyed in **2009**, use `select()` to select only their weights, use `drop_na()` to drop any NA values, and then assign this all to a new object called `ch7_female`.

```{r courage-1, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-1-hint-1, eval = FALSE}
nhanes %>% 
  filter(...) %>% 
  select(...) %>% 
  drop_na() -> ch7_female
```

We will use the `ch7_female` tibble in the questions which follow.

### 

### Exercise 2

Next we'll use `stan_glm()` to create a simple Bayesian model. When using `stan_glm()`, there are always four arguments that should be specified:

* The `data` argument tells `stan_glm()` what data frame to work with. In this case, we'll set it to `ch7_female`.
* The `family` argument tells `stan_glm()` what error distribution and link function to use in the model. In this case, we'll set it to `gaussian()` (which is, for our intents and purposes, synonymous with normal).
* We usually set the `refresh` argument to 0 — otherwise, the function will spit back a lot of messy lines before giving us the meat of the output.
* The `formula` argument tells `stan_glm()` what model is to be fitted. In this case, since we are working with a predictive model and not a casual model, we should set it to `weight ~ 1` (constant).

```{r courage-2, exercise = TRUE}
library(rstanarm)


```

```{r courage-2-hint-1, eval = FALSE}
stan_glm(data = ...,
         formula = ..., 
         family = ..., 
         refresh = ...)
```

### 

### Exercise 3

Next, we should save our model to be able to work with it in later questions.

Copy your code from the previous exercise, and assign it to an object called `fit_obj`.

```{r courage-3, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

While we have saved the model, the model summary is above still somewhat complex. Let's simplify this.

### 

### Exercise 4

Instead of printing out the whole model like before, just use `print` to print out the parameters of the model. Set the `detail` argument to FALSE.

```{r courage-4, exercise = TRUE}

```

```{r courage-4-hint-1, eval = FALSE}
print(fit_obj, detail = ...)
```

### 

### Exercise 5

Recall that the most important single number related to a distribution is some measure of its location. The two common measures for this are _mean_ and _median_. 

In a single sentence, using your own words, describe why we use the median here.

```{r courage-5}
question_text(NULL,
	message = "The median is less affected by outliers, and is therefore a more stable measure of the distribution's center.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

### Exercise 6

Now, in 2 sentences, use your own words to define `MAD_SD`.

```{r courage-6}
question_text(NULL,
	message = "The MAD_SD is the scaled median absolute deviation. It is a measure of the variability of our posterior distributions for a given parameter.",
	answer(NULL,
	correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	options = list(nrows = 6))
```

### 

### Exercise 7

Awesome! Now let's create the following posterior distribution.

```{r courage-7}
weight_p <- fit_obj %>% 
  as_tibble() %>% 
  rename(mu = `(Intercept)`) %>% 
  ggplot(aes(x = mu)) +
    geom_histogram(aes(y = after_stat(count/sum(count))), 
                   bins = 200, 
                   color = "white") +
    labs(title = "Posterior Probability Distribution",
         subtitle = "Average weight among American adult women in 2009",
         x = "Weight in Kilograms",
         y = "Probability") +
    theme_classic()

weight_p
```

First, create a pipe starting with `fit_obj` and then continuing with `as_tibble()`.

```{r not_print, exercise = TRUE}

```

```{r courage-7-hint-1, eval = FALSE}
fit_obj %>% 
  ...
```

### 

### Exercise 8

Cool. Now copy and paste your work from the previous question and continue the pipe. Use `rename()` and rename `(Intercept)` as `mu`. Recall that column names can be anything you want. But, if you use weird things — like a parenthesis — then you need to put backticks around the column names. Since that is a bother, we prefer column names like `mu` to column names like `(Intercept)`.

```{r courage-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-8-hint-1, eval = FALSE}
fit_obj %>% 
  as_tibble() %>%
  rename(mu = `(Intercept)`) 
```

### 

### Exercise 9

  
Continue the pipe and use `ggplot()`. Map x to `mu` in the `aes` argument. Use `geom_histogram()` and map y to the `after_stat()` function. Set its argument to `count` divided by the `sum` of `count`.
    
```{r courage-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-9-hint-1, eval = FALSE}
fit_obj %>% 
  as_tibble() %>% 
  rename(mu = `(Intercept)`) %>% 
  ggplot(aes(x = ...)) +
    geom_histogram(aes(y = ...))
```

### 

### Exercise 10

Also, set `bins` to 200 and `color` to white within `geom_histogram()`.

```{r courage-10, exercise = TRUE}

```

### 

### Exercise 11

Title your histogram "Posterior Probability Distribution" with the subtitle "Average weight among American adult women in 2009". Also name the x-axis "Weight" and the y-axis "Probability". Add a layer and use `theme_classic()`. Reminder: Your plot should look something like this:

```{r courage-11}
weight_p
```

```{r classic, exercise = TRUE}

```

```{r courage-11-hint-1, eval = FALSE}
Use labs() to add labels.
```

### 

## Temperance 

### 

We have a model of female height in 2009. What can we do with it? Let's use it to answer out initial question: _What is the probability that the next adult female we meet in Cambridge today will weigh more than 100 kilos?_

### 

### Exercise 1

Create a tibble with one variable, `constant`, which is set equal to the value 1. Assign this tibble to an object named `newobs`.

```{r temperance-1, exercise = TRUE}

```

```{r temperance-1-hint-1, eval = FALSE}
... <- tibble(...)
```

```{r temperance-1-hint-2, eval = FALSE}
... <- tibble(constant = 1)
```

`newobs` is available for use in later questions.

### 

### Exercise 2

Let's now obtain some estimates for the weight of a single woman. 

Use `posterior_predict` with `fit_obj` as the first argument to get some draws from the posterior distribution of our model. Set the `newdata` argument equal to the tibble `newobs` to indicate that we only want estimates for one person.

```{r temperance-2, exercise = TRUE}

```

```{r temperance-2-hint-1, eval = FALSE}
posterior_predict(fit_obj,
                  newdata = ...)
```

### 

### Exercise 3

Good job! We now have 4000 estimates for a random woman's weight in kg.

Copy your code from above and add two pipes with `as_tibble()` and `mutate_all(as.numeric)`. Assign the result to an object named `pp` to save it.

```{r temperance-3, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-3-hint-1, eval = FALSE}
... <- posterior_predict(fit_obj,
                         newdata = newobs) %>% 
       ... %>% 
       ...
```

`pp` is available for use in later questions.

### 

### Exercise 4

It is always helpful to plot our data before working with it.

Start a new pipe with `pp`. Create a histogram with `geom_histogram()`. Use `after_stat()` to display the y-axis in relative proportions of each weight group. Set `bins` to 200 and `color` to "white".

```{r temperance-4, exercise = TRUE }

```

```{r temperance-4-hint-1, eval = FALSE}
pp %>% 
  ggplot(aes(x = ...)) +
    geom_histogram(aes(y = after_stat(...)),
                   bins = ...,
                   color = ...)
```

### 

### Exercise 5

Your code should now look as shown below.

Add `labs()` to title your histogram "4000 Draws from Posterior Distribution" with the subtitle, "Average weight of a random American adult woman in 2009". Name the x-axis "Weight in Kilograms" and the y-axis "Probability". Finally, add a layer and use `theme_classic()`. 

```{r temperance-5, exercise = TRUE}
pp %>% 
  ggplot(aes(x = `1`)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 200,
                   color = "white")
```

```{r temperance-5-hint-1, eval = FALSE}
pp %>% 
  ggplot(aes(x = `1`)) +
    geom_histogram(aes(y = after_stat(count/sum(count))), 
                   binwidth = 0.02, 
                   color = "white") +
    labs(title = ...,
         subtitle = ...,
         x = ...,
         y = ...) +
    theme_classic()
```

How does the distribution of our 4000 estimates compare to the actual posterior distribution you plotted earlier? As a reminder, it looked like this:

```{r courage_plot2}
fit_obj %>% 
  as_tibble() %>% 
  rename(mu = `(Intercept)`) %>% 
  ggplot(aes(x = mu)) +
    geom_histogram(aes(y = after_stat(count/sum(count))), 
                   bins = 200, 
                   color = "white") +
    labs(title = "Posterior Probability Distribution",
         subtitle = "Average weight among American adult women in 2009",
         x = "Weight in Kilograms",
         y = "Probability") +
    theme_classic()
```

### 

### Exercise 6

Recall our question: _What is the probability that the next adult female we meet in Cambridge today will weigh more than 100 kilos?_ 

The histogram already shows approximately what the answer to our question might be, but let's calculate it exactly.

Using one line of code, determine the proportion of all women in `pp` who weigh more than 100kg. 

```{r temperance-6, exercise = TRUE}

```

```{r temperance-6-hint-1, eval = FALSE}
sum(... > 100) / length(...)
```

```{r temperance-6-hint-2, eval = FALSE}
sum(pp$`1` > 100) / length(pp$`1`)
```

### 

```{r download-answers, child = "../../child_documents/download_answers.Rmd"}
```
