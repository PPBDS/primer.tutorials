---
title: 'Four Parameters: Categorical'
author: David Kane and Ivy Spratt
tutorial:
  id: four-parameters-categorical
output:
  learnr::tutorial:
    progressive: yes
    allow_skip: yes
runtime: shiny_prerendered
description: "Tutorial #8 for Preceptor's Primer"
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(gt)

library(tidyverse)
library(primer.data)
library(tidymodels)
library(broom)
library(marginaleffects)

library(easystats)


knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

nes_92 <- nes |> 
  filter(year == 1992) |> 
  select(sex, pres_vote) |> 
  drop_na() |> 
  mutate(pres_vote = as.factor(case_when(
    pres_vote == "Democrat" ~ "Clinton",
    pres_vote == "Republican" ~ "Bush",
    pres_vote == "Third Party" ~ "Perot",
  ))) 

fit_nes <- multinom_reg(engine = "nnet") |>
  fit(pres_vote ~ sex, data = nes_92)

# Notice that tidy(fit_nes) produces estimates of 4 parameters, which, when
# plugged into standard logistic formulas, would give us the probablities for
# Clinton and Perod for men and women. The probability for Bush is then
# calculated via subtraction.

# I could not get simple plot_predictions() to work. Can you? I think it is
# because marginaleffects does not deal well with situations like this.
# Regardless, we can still have students make a nice looking plot with this
# code.

# DK: Does this belong here? I doubt it.

tmp_p <- plot_predictions(fit_nes, 
                          by = "sex", 
                          type = "prob", 
                          draw = FALSE) |> 
    ggplot(aes(x = group, y = estimate, color = sex)) +
      geom_point(size = 3, position = position_dodge(width = 0.5)) +
      geom_errorbar(aes(ymin = conf.low, 
                        ymax = conf.high), 
                    width = 0.2, 
                    position = position_dodge(width = 0.5)) +
      labs(title = "Voting Preferences by Candidate and Sex",
           x = NULL,
           y = "Estimated Proportion",
           color = "Sex") +
      theme_minimal() 
```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

<!-- Should we be using brglm2::bracl()? See discussion: https://github.com/easystats/easystats/issues/452 -->


## Introduction
### 

This tutorial supports [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

The world confronts us. Make decisions we must.

Imagine you are a historian interested in the 1992 Presidential election. You want to understand how different groups of Americans made their decisions voting, an important lens being gender. In this analysis, we focus on the three leading candidates — Bill Clinton, George H. W. Bush, and Ross Perot — to explore how gender influenced voter support in a historically significant election.

### Exercise 1

What are the four [Cardinal Virtues](https://en.wikipedia.org/wiki/Cardinal_virtues), in order, which we use to guide our data science work?

```{r introduction-1}
question_text(NULL,
	message = "Wisdom, Justice, Courage, and Temperance.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

###

Why do we ask this, and a score more other questions, in each tutorial? Because the best way to (try to) ensure that students remember these concepts more than a few months after the course ends is [spaced repetition](https://en.wikipedia.org/wiki/Spaced_repetition), although we focus more on the repetition than on the spacing.

### Exercise 2

Create a Github repo called `four-parameters-categorical`. Make sure to click the "Add a README file" check box.

Connect the repo to a project on your computer using `File -> New Folder from Git ...`. Make sure to select the "Open in a new window" box. 

You need two Positon windows: this one for running the tutorial and the one you just created for writing your code and interacting with the Console.

Select `File -> New File -> Quarto Document ...`. Provide a title -- `"Four Parameters Categorical"` -- and an author (you). Render the document and save it as `analysis.qmd`.

Create a `.gitignore` file with `*_files` on the first line and then a blank line. Save and push.

In the Console, run:

```         
show_file(".gitignore")
```

If that fails, it is probably because you have not yet loaded `library(tutorial.helpers)` in the Console.

CP/CR.

```{r introduction-2}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Professionals keep their data science work in the cloud because laptops fail.

### Exercise 3

In your QMD, put `library(tidyverse)` and `library(primer.data)` in a new code chunk. Render the file.

Notice that the file does not look good because the code is visible and there are annoying messages. To take care of this, add `#| message: false` to remove all the messages in this `setup` chunk. Also add the following to the YAML header to remove all code echos from the HTML:

```         
execute: 
  echo: false
```

In the Console, run:

```         
show_file("XX.qmd", start = -5)
```

CP/CR.

```{r introduction-3}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

### Exercise 4

Place your cursor in the QMD file on the `library(tidyverse)` line. Use `Cmd/Ctrl + Enter` to execute that line.

Note that this causes `library(tidyverse)` to be copied down to the Console and then executed. 

CP/CR.

```{r introduction-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

###

We will be using the data set about US people's voting result from [American National Election Studies](https://electionstudies.org/) survey. **The primer.data** package includes a version of the main data set with a selection of variables. The full ANES data is much richer than this relatively simple tibble.

### Exercise 5

<!-- XX: This question only works if there is help available for the tibble you hope to use. Delete the question if there is not.  -->

In the Console, type `?nes`, and paste the Description below.

```{r introduction-5}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 8)
```

### 

Note that the survey has been conducted since 1948 before and after each presidential election and some of the questions asked in the survey have changed slightly over time. Further information on this issue can be found at the [ANES codebook](https://electionstudies.org/wp-content/uploads/2018/12/anes_timeseries_cdf_codebook_var.pdf)


## Wisdom
### 

*The only true wisdom is in knowing you know nothing.*  - Socrates

### Exercise 1

In your own words, describe the key components of Wisdom for working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires a question, the creation of a Preceptor Table and an examination of our data.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The central problem for Wisdom: Can we use data from `nes` to predict the voting behavior of men and women in the US this year? When was the data collected? Is the question in the survey across year the same? 

### Exercise 2

Election is the broad topic of this tutorial. Given that topic, which variable in `nes` should we use as our outcome variable? 

```{r wisdom-2}
question_text(NULL,
	message = "`pres_vote` is our outcome variable.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

`pres_vote` is the name of the party to which the voted candidates belong. Such explorations are often restricted to just the two “major party” candidates, the nominees of the Democratic and the Republican parties, Bill Clinton and George HW Bush. But, in 1992, Ross Perot was a very successful “third party” candidate, winning almost 19% of the vote. We transferred each party to its candidate's name. 

```{r}
nes_92 |> 
  ggplot(aes(x = pres_vote)) +
    geom_bar(position = "dodge") +
    labs(title = "Survey of 1992 Presidential Election Votes",
         subtitle = "Clinton was mostly voted in the 1992 Presidential Election",
         x = NULL,
         y = "Count",
         caption = "Source: American National Election Survey")
```

### Exercise 3

Let's imagine a brand new variable which **does not exists** in the data. This variable should be binary, meaning that it only takes on one of two values. It should also, at least in theory, by manipulable. In other words, if the value of the variable is "X," or whatever, then it generates one potential outcome and if it is "Y," or whatever, it generates another potential outcome.

Describe this imaginary variable and how might we manipulate its value.


```{r wisdom-3}
# XX: In your answer, and for the next few questions, always treat this
# imaginary variable as real by putting backticks around the name. For example,
# with nhanes data, we might imagine a variable called `vitamin` for which `1`
# means that the individual ate vitamins growing up and `0` means they did not.
# Using the words "treatment group" and "control group" as part of your answer
# is often helpful since it reinforces the fact that we are using the Rubin
# Causal Model.

question_text(NULL,
	message = "Imagine a variable called `phone_call` which has a value of `1` if the person received a phone call urging them to vote and `0` if they did not receive such a phone call. We, meaning the organization in charge of making such phone calls, can manipulate this variable by deciding, either randomly or otherwise, whether or not we will call a specific individual.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Any data set can be used to construct a causal model as long as there is at least one covariate that we can, at least in theory, manipulate. It does not matter whether or not anyone did, in fact, manipulate it. 

### Exercise 4

Given our (imaginary) treatment variable `phone_call`, how many potential outcomes are there for each individual? Explain why.

```{r wisdom-4}
question_text(NULL,
	message = "There are 2 potential outcomes because the treatment variable `phone_call` takes on 2 posible values: receive phone call versus no phone call.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The same data set can be used to create, separately, lots and lots of different models, both causal and predictive. We can just use different outcome variables and/or specify different treatment variables. All of this stuff is a *conceptual* framework we apply to the data. It is never inherent in the data itself.

### Exercise 5

In a few sentences, specify two different values for the imaginary treatment variable `phone_call`, for a single unit, and then guess at the potential outcomes which would result, and then determine the causal effect for that unit given those guesses.

```{r wisdom-5}
# XX: Replace [XX: unit] with a better word below given the actual data set we
# are using. Replace all the XX terms as appropriate.

# XX: For a given individual, assume that the value of the treatment variables
# might be 'exposure to Spanish-speakers' or 'no exposure'. If the individual
# gets 'exposure to Spanish-speakers', then her attitude toward immigration
# would be 10. If the individual gets 'no exposure', then her attitude would be
# 8. The causal effect on the outcome of a treatment of exposure to
# Spanish-speakers versus no exposure is 10 - 8 --- i.e., the difference between
# two potential outcomes --- which equals 2, which is the causal effect.

# XX: If the outcome is a character variable, like Strongly Approve, then there
# is no simple metric on which we can pinpoint the causal effect. That is, the
# causal effect is still defined --- as, in this example, the difference between
# Strongly Approve and Neutral --- but can not be expressed as a number, at
# least without further work.

question_text(NULL,
	message = "For a given individual, assume that the value of the treatment variable might be `receive phone call` or `no phone call`. If this individual gets `receive phone call`, then they vote for Bush. If the individual gets `no phone call`, they vote for Clinton. The causal effect of `receive phone call` versus `no phone call` is the difference between voting for Bush and voting for Clinton, a difference with no uniquely-defined counterpart.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A causal effect is defined as the *difference* between two potential outcomes. Keep two things in mind.

First, *difference* does not necessarily mean *subtraction*. Many potential outcome are not numbers. For example, it makes no sense to subtract a potential outcome, like who you would vote for if you saw a Facebook ad, from another potential outcome, like who you vote for if you did not see the ad.

Second, even in the case of numeric outcomes, you can’t simply say the effect is 10 without specifying the order of subtraction, although there is, perhaps, a default sense in which the causal effect is defined as potential outcome under treatment minus potential outcome under control.

### Exercise 6

Let's consider a *predictive* model. Which variable in `nes` do you think might have an important connection to `pres_vote`? 


```{r wisdom-6}
question_text(NULL,
	message = "`sex` is a potential variable that may relate to `pres_vote`.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

With a predictive model, there is only one outcome for each individual unit. There are not two potential outcomes because we are not considering any of the covariates to be a treatment variable. We assuming that the values of all covariates are "fixed." 

Predictive models have no "treatments" -—- only covariates.

### Exercise 7

Specify two different groups of individuals which have specific value for `sex` and which might have different average values for the `pres_vote`.  

```{r wisdom-7}
question_text(NULL,
	message = "Consider two groups, the first with a value for `sex` of `Male`. Others might have a value of `Female`. Those two groups will, on average, have different values for the probability of voting for a specific candidate.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In predictive models, do not use words like "cause," "influence," "impact," or anything else which suggests causation. The best phrasing is in terms of "differences" between groups of units with different values for the covariate of interest.

Any causal connection means exploring the *within row* difference between two potential outcomes. There's no need to consider other rows.

### Exercise 8

Write a predictive question which connects the outcome variable `pres_vote` to `sex`, the covariate of interest. 

```{r wisdom-8}
# XX: If it is causal, you should use key causal language in the question, like
# "What is the causal effect of the treatment on the outcome?" Example: "What is
# the causal effect of exposure to Spanish-speakers on attitudes toward
# immigration?" If the model is predictive, the question should clearly compare
# two groups of units. "What is the difference in the outcome variable between
# two groups of units?" Example:  "What is the difference in immigration
# attitudes between Democrats and Republicans?" In both cases, the word
# "average" is implicit in the question.

question_text(NULL,
	message = "What was the difference in voting preference of men and women in the 1992 US Presidential election among supporters of the three leading candidates: Clinton, Bush and Perot?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This is the first version of the question. We will now create a Preceptor Table to answer the question. We may then revise the question given complexities discovered in the data. We then update the question and the Preceptor Table. And so on.

### Exercise 9

Define a Preceptor Table.

```{r wisdom-9}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, we can easily calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table does not include all the covariates which you will eventually include in your model. It only includes covariates which you need to answer your question.

### Exercise 10

Describe the key components of Preceptor Tables in general, without worrying about this specific problem. Use words like "units," "outcomes," and "covariates."

```{r wisdom-10}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This problem is predictive so there are only covariates. In our problem, one of the covariates is each individual's sex. 

### Exercise 11

What are the units for this problem?

```{r wisdom-11}
question_text(NULL,
	message = "Individual US voters.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We are looking at who voted for these three candidates: Bush, Clinton and Perot. The question suggests that we are not interested in people who did not vote, although one might explore if men were more or less likely to vote in the first place. As always, the initial question rarely specifies the Preceptor Table precisely. 

Specifying the Preceptor Table forces us to think clearly about the units and outcomes implied by the question. The resulting discussion sometimes leads us to modify the question with which we started. No data science project follows a single direction. We always backtrack. There is always dialogue.

We model units, but we only really care about aggregates.

### Exercise 12

What is the outcome for this problem?

```{r wisdom-12}
question_text(NULL,
	message = "The outcome for this problem is the presidential voting result of each individual voter. This is not the same thing as the answer to the question we have beeen asked. But, if we can build a model which explains/understands/predicts voting result for an individual, we can use that model to answer our questions.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The outcome variable that we really care about is often not the outcome variable which our data includes. This compromise --- working with what we *have* rather than what we really *want* --- is a part of most data science work in the real world.

### Exercise 13

What is a covariate which you think might be useful for this problem, regardless of whether or not it might be included in the data?

```{r wisdom-13}
question_text(NULL,
	message = "We will certainly need sex, with two values: “Male” and “Female”. Other variables which might be helpful include party, income, race and past voting history.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The term "covariates" is used in at least three ways in data science. First, it is all the variables which might be useful, regardless of whether or not we have the data. Second, it is all the variables for which we have data. Third, it is the set of variables in the data which we end up using in the model.

### Exercise 14

What are the treatments, if any, for this problem?

```{r wisdom-14}
question_text(NULL,
	message = "There are no treatment variables.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Remember that a treatment is just another covariate which, for the purposes of this specific problem, we are assuming can be manipulated, thereby, creating two or more different potential outcomes for each unit.

### Exercise 15

What moment in time does the Preceptor Table refer to?

```{r wisdom-15}
question_text(NULL,
	message = "The Presidential Election result in 1992.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A Preceptor Table can never really refer to an exact instant in time since nothing is instantaneous in this fallen world.

In almost all practical problems, the data was gathered at a time other than that to which the Preceptor Table refers.

```{r}
nes_92 |>
  ggplot(aes(x = pres_vote, fill = sex)) +
    geom_bar(position = "dodge") +
    labs(title = "Survey of 1992 Presidential Election Votes",
         subtitle = "Men were much more likely to support Ross Perot",
         x = NULL,
         y = "Count",
         caption = "Source: American National Election Survey")
```

> *You can never look at the data too much. -- Mark Engerman*

### Exercise 16

Define a causal effect.

```{r wisdom-16}
question_text(NULL,
	message = "A causal effect is the difference between two potential outcomes.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

According to the Rubin Causal Model, there must be two (or more) potential outcomes for any discussion of causation to make sense. This is simplest to discuss when the treatment only has two different values, thereby generating only two potential outcomes. 

### Exercise 17

What is the fundamental problem of causal inference?

```{r wisdom-17}
question_text(NULL,
	message = "The fundamental problem of causal inference is that we can only observe one potential outcome.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If the treatment variable is continuous (like income), then there are lots and lots of potential outcomes, one for each possible value of the treatment variable. 

### Exercise 18

How does the motto "No causal inference without manipulation." apply in this problem?

```{r wisdom-18}
question_text(NULL,
	message = "The motto does not apply because this is a predictive, not causal, model.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We have to choose a variable that we can change to be the treatment. If we do not have such variable that we can manipulate, then we would have to create a predictive model instead. For example, if we were focused on individuals' voting, one conclusion maybe: the probability of voting for Clinton of women is expected to be higher than that of men. Correlation does not mean causation, we cannot assume that sex directly makes people prefer Clinton. In order to find a causation relationship, we would need to manipulate the treatment so that we can measure its effect on the outcome.

### Exercise 19

Describe in words the Preceptor Table for this problem.

```{r wisdom-19}
question_text(NULL,
	message = "The Preceptor Table has one row for each voter, one output column for which party was voted and one covariate, sex.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table for this problem looks something like this:

```{r}
#| echo: false
tibble(ID = c("1", "2", "...", "10", "11", "...", "103,754,865"),
       vote = c("Democrat", "Third Party", "...", "Republican", "Democrat", "...", "Republican"),
       sex = c("M", "F", "...", "F", "F", "...", "M")) |>
  
  gt() |>
  tab_header(title = "Preceptor Table") |> 
  cols_label(ID = md("ID"),
             vote = md("Vote"),
             sex = md("Sex")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(ID))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(ID))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Outcome", columns = c(vote)) |>
  tab_spanner(label = "Covariate", columns = c(sex))
```

Like all aspects of a data science problem, the Preceptor Table evolves as we work on the problem. 

### Exercise 20

What is the narrow, specific question we will try to answer?

```{r wisdom-20}
question_text(NULL,
	message = "What was the difference in voting preference of men and women in the 1992 US Presidential election among supporters of the three leading candidates: Clinton, Bush and Perot?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

The answer to this question is your "Quantity of Interest." It is OK if your question differs from ours. Many similar questions lead to the creation of the same model. For the purpose of this tutorial, let's use our question.

Our Quantity of Interest might appear too specific, too narrow to capture the full complexity of the topic. There are many, many numbers in which we are interested, many numbers that we want to know. But we don't need to list them all here! We just need to choose one of them since our goal is just to have a specific question which helped to guide us in the creation of the Preceptor Table and, soon, the model. 

### Exercise 21

Over the course of this tutorial, we will be creating a summary paragraph. The purpose of this exercise is to write the first two sentences of that paragraph.

The first sentence is a general statement about the overall topic, mentioning both general class of the outcome variable and of at least one of the covariates. It is **not** connected to the initial "Imagine that you are XX" which set the stage for this project. That sentence can be rhetorical. It can be trite, or even a platitude. The purpose of the sentence to let the reader know, gently, about our topic.

The second sentence does two things. First, it introduces the data source. Second, it introduces the specific question. The sentence can't be that long. Important aspects of the data include when/where it was gather, how many observations it includes and the organization (if famous) which collected it.

Type your two sentences below.

```{r wisdom-21}
question_text(NULL,
	message = "Understanding the voter preference of different genders is essential for a candidate to design the campaign strategy. Using data from the National Election Studies survey of US citizens, we seek to understand the relationship between voter preference and sex in the 1992 Presidential election.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

Read our answer. It will not be the same as yours. You can, if you want, change your answer to incorporate some of our ideas. Do not copy/paste our answer exactly. Add your two sentences, edited or otherwise, to `analysis.qmd`, `Cmd/Ctrl + Shift + K`, and then commit/push.

## Justice
### 

*Justice delayed is justice denied.* - William E. Gladstone

### Exercise 1

In your own words, name the four key components of Justice for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns the Population Table and the four key assumptions which underlie it: validity, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Justice is about concerns that you (or your critics) might have, reasons why the model you create might not work as well as you hope. 

### Exercise 2

In your own words, define "validity" as we use the term.

```{r justice-2}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Validity is always about the *columns* in the Preceptor Table and the data. Just because columns from these two different tables have the same *name* does not mean that they are the same *thing*.

### Exercise 3

Provide one reason why the assumption of validity might not hold for the outcome variable: `pres_vote` or for one of the covariates. Use the words "column" or "columns" in your answer.

```{r justice-3}
question_text(NULL,
	message = "People may claim that they voted for one candidate when they really voted for another. This causes the column `pres_vote` in the data we have do not match up with the `pres_vote` column in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In order to consider the Preceptor Table and the data to be drawn from the same population, the columns from one must have a *valid correspondence* with the columns in the other. Validity, if true (or at least reasonable), allows us to construct the Population Table, which is the first step in Justice.

Because we control the Preceptor Table and, to a lesser extent, the original question, we can adjust those variables to be “closer” to the data that we actually have. This is another example of the iterative nature of data science. If the data is not close enough to the question, then we check with our boss/colleague/customer to see if we can modify the question in order to make the match between the data and the Preceptor Table close enough for validity to hold.

Despite these potential problems, we will assume that validity holds since it, mostly (?), does.

### Exercise 4

In your own words, define a Population Table.

```{r justice-4}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Population Table is almost always much bigger than the combination of the Preceptor Table and the data because, if we can really assume that both the Preceptor Table and the data are part of the same population, than that population must cover a broad universe of time and units since the Preceptor Table and the data are, themselves, often far apart from each other.

### Exercise 5

<!-- IS: not sure what to put for this answer -->

Specify the unit/time combinations which define each row in this Population Table.

```{r justice-5}
question_text(NULL,
	message = "The unit is the individual voter, and the time is the time of the election.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The exact time period used --- whether hour, day, month, year, or whatever --- is relatively arbitrary. The important thing to note is that the Population Table, unlike the Preceptor Table, covers a period of time over which things may change.

Here is our Population Table:

```{r}
#| echo: false
tibble(source = c("PT/Data", "PT/Data", "PT", "PT", "PT", "PT", "...", "PT/Data", "PT/Data", "PT",  "PT",  "...", "PT/Data"),
       ID = c("1", "2", "3", "4", "5", "6", "...", "10", "11", "12", "13", "...", "103,754,865"),
       vote = c("Democrat", "Third Party", "Republican", "Democrat", "Democrat", "Democrat",  "...", "Republican", "Democrat", "Democrat", "Republican", "...", "Republican"),
       sex = c("M", "F", "M", "F", "F", "M", "...", "F", "F", "...", "F", "...", "M")) |>
 
  gt() |>
  tab_header(title = "Population Table") |>
  cols_label(source = md("Source"),
             ID = md("ID"),
             vote = md("Vote"),
             sex = md("Sex")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(ID))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"),
            locations = cells_column_labels(columns = c(ID))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Outcome", columns = c(vote)) |>
  tab_spanner(label = "Covariate", columns = c(sex))
```

### Exercise 6

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-6}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability is all about *time*. Is the relationship among the columns in the Population Table stable over time? In particular, is the relationship --- which is another way of saying "mathematical formula" --- at the time the data was gathered the same as the relationship at the (generally later) time referenced by the Preceptor Table.

### Exercise 7

Provide one reason why the assumption of stability might not be true in this case.

```{r justice-7}
question_text(NULL,
	message = "Stability may not hold because the Preceptor Table comes before the data, and the relationship between sex and vote choice could have changed over time due to shifts in public opinion or campaign dynamics. As a result, the patterns seen in the data may not reflect those in the Preceptor Table or the broader population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Some voters cast their ballots weeks before Election Day. Some NES participants were surveyed right after the election. Some were survey later. We sweep all these complications under the mythical moment in time which we assert is the same for both the data and the Preceptor Table.

A change in time or the distribution of the data does not, in and of itself, demonstrate a violation of stability. Stability is about the parameters: $\beta_0$, $\beta_1$ and so on. Stability means these parameters are the same in the data as they are in the population as they are in the Preceptor Table.

### Exercise 8

We use our data to make inferences about the overall population. We use information about the population to make inferences about the Preceptor Table: `Data -> Population -> Preceptor Table`. In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-8}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationships among the rows in the Population Table. The first is between the data and the other rows. The second is between the other rows and the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case.

### Exercise 9

We do not use the data, directly, to estimate missing values in the Preceptor Table. Instead, we use the data to learn about the overall population. Provide one reason, involving the relationship between the data and the population, for why the assumption of representativeness might not be true in this case. 

```{r justice-9}
# XX: In your answer, try not use of the concept time, even though, in theory,
# it is a perfectly reasonable to do so. Instead, focus on why the data might
# not be representative of the population at that moment in time.

question_text(NULL,
	message = "The data used might underrepresent some different minority groups or demographics, as there is a certain type of person who likes to respond to political surveys.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The reason that representativeness is important is because, when it is violated, the estimates for the model parameters might be biased. 

### Exercise 10

We use information about the population to make inferences about the Preceptor Table. Provide one reason, involving the relationship between the population and the Preceptor Table, for why the assumption of representativeness might not be true in this case.

```{r justice-10}
question_text(NULL,
	message = "Since voting is a right, but not compulsory for everyone, the people who voted may not be representative of the entire population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability looks across time periods. Representativeness looks within time periods, for the most part. 

### Exercise 11

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-11}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This assumption is only relevant for causal models. We describe a model as "confounded" if this is not true. The easiest way to ensure unconfoundedness is to assign treatment randomly.

### Exercise 12

A statistical model consists of two parts: the *probability family* and the *link function*. The probability family is the probability distribution which generates the randomness in our data. The link function is the mathematical formula which links our data to the unknown parameters in the probability distribution. 

Add `library(tidymodels)` to the QMD file.

Place your cursor in the QMD file on the `library(tidymodels)` line. Use `Cmd/Ctrl + Enter` to execute that line.

Note that this causes `library(tidymodels)` to be copied down to the Console and then executed. 

CP/CR.

```{r justice-12}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

###

The probability family is determined by the outcome variable `pres_vote`. 

Since $Y$ is a categorical value (with 2+ possible values), the probability family is Multinomial.

$$Y \sim \text{Mutinomial}(\rho_{bush}, \rho_{clinton}, \rho_{perot})$$

where $$ \rho_{bush} + \rho_{clinton} + \rho_{perot} = 1 $$

### Exercise 13

<!-- XX: In later tutorials, you can shrink this verbiage. -->

Add `library(broom)` to the QMD file.

Place your cursor in the QMD file on the `library(broom)` line. Use `Cmd/Ctrl + Enter` to execute that line.

Note that this causes `library(broom)` to be copied down to the Console and then executed. 

CP/CR.

```{r justice-13}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

###

The link function, the basic mathematical structure of the model, is (mostly) determined by the type of outcome variable. 

For a multinomial outcome variable, we use a multinomial logistic regression model. (Note that this formulation is for the case with three outcomes, but the same approach holds for more than three outcomes.)

$$
\begin{aligned}
\rho_{A} &= \frac{e^{\beta_{0, A} + \beta_{1, A} \cdot X}}{1 + e^{\beta_{0, A} + \beta_{1, A} \cdot X} + e^{\beta_{0, B} + \beta_{1, B} \cdot X}} \\
\rho_{B} &= \frac{e^{\beta_{0, B} + \beta_{1, B} \cdot X}}{1 + e^{\beta_{0, A} + \beta_{1, A} \cdot X} + e^{\beta_{0, B} + \beta_{1, B} \cdot X}} \\
\rho_{C} &= 1 - \rho_{A} - \rho_{B}
\end{aligned}
$$

### Exercise 14

Use AI to come up with a $\LaTeX$ representation of the mathematical structure of the model, with $Y$ as the dependent variable and $X_1$, $X_2$ and so on as the independent variables. This version will not have the values of any parameters since we have not, yet, estimated them. Confirm that the $\LaTeX$ code works by placing it in your QMD and then rendering. Paste that $\LaTeX$ code below.

```{r justice-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

###

Our answer:

$$P(Y = k) = \frac{e^{\beta_{k0} + \beta_{k1} X_1 + \beta_{k2} X_2 + \cdots + \beta_{kn} X_n}}{\sum_{j=1}^{K} e^{\beta_{j0} + \beta_{j1} X_1 + \beta_{j2} X_2 + \cdots + \beta_{jn} X_n}}$$

with $Y \sim \text{Multinomial}(\boldsymbol{\rho})$ where $\boldsymbol{\rho} = (\rho_1, \rho_2, \ldots, \rho_K)$ are the probabilities above.

Which we created with $\LaTeX$ code that looks like this:

````
$$P(Y = k) = \frac{e^{\beta_{k0} + \beta_{k1} X_1 + \beta_{k2} X_2 + \cdots + \beta_{kn} X_n}}{\sum_{j=1}^{K} e^{\beta_{j0} + \beta_{j1} X_1 + \beta_{j2} X_2 + \cdots + \beta_{jn} X_n}}$$

with $Y \sim \text{Multinomial}(\boldsymbol{\rho})$ where $\boldsymbol{\rho} = (\rho_1, \rho_2, \ldots, \rho_K)$ are the probabilities above.
````

This follows the multinomial logistic regression form, where each category $k$ has its own set of parameters $\beta_{k0}, \beta_{k1}, \ldots, \beta_{kn}$.

### Exercise 15

Write one sentence which highlights a potential weakness in your model. This will almost always be derived from possible problems with the assumptions discussed above. We will add this sentence to our summary paragraph. So far, our version of the summary paragraph:

> Understanding the voter preference of different genders is essential for a candidate to design a campaign strategy. Using data from the National Election Studies survey of US citizens, we seek to understand the relationship between voter preference and sex in the 1992 Presidential election.

Of course, your version will be somewhat different.

```{r justice-15}
question_text(NULL,
	message = "Understanding the voter preference of different genders is essential for a candidate to design a campaign strategy. Using data from the National Election Studies survey of US citizens, we seek to understand the relationship between voter preference and sex in the 1992 Presidential election. However, since not everyone participates in the survey, the data might not be representative of the entire population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Add a weakness sentence to the summary paragraph in your QMD. You can modify your paragraph as you see fit, but do not copy/paste our answer exactly. `Cmd/Ctrl + Shift + K`, and then commit/push.

## Courage
### 

*Courage is the commitment to begin without any guarantee of success.* - Johann Wolfgang von Goethe


### Exercise 1

In your own words, describe the components of the virtue of Courage for analyzing data.

```{r courage-1}
question_text(NULL,
	message = "Courage creates the data generating mechanism.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Having decided on the basic mathematical structure of the model at the end of *Justice*, a choice mostly driven by the distribution of our outcome variable, we now turn toward estimating the model. 

### Exercise 2

Because our outcome variable is multinomial, start to create the model by using `multinom_reg(engine = "nnet")`.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
multinom_reg(engine = ...)
```

```{r courage-2-test, include = FALSE}
multinom_reg(engine = "nnet")
```

### 

The *[tidymodels](https://www.tidymodels.org/)* framework is the most popular one in the R world for estimating models. *[Tidy Modeling with R](https://www.tmwr.org/)* by Max Kuhn and Julia Silge is a great introduction.

The same approach applies to a categorical covariate with $N$ values. Such cases produce $N-1$ dummy $0/1$ variables. The presence of an intercept in most models means that we can't have $N$ categories. The "missing" category is incorporated into the intercept. If `race` has three values --- "black", "hispanic", and "white" --- then the model creates two 0/1 dummy variables, giving them names like $race_{hispanic}$ and $race_{white}$. The results for the *first* category are included in the intercept, which becomes the reference case, relative to which the other coefficients are applied. However, note that there is no variable like this in our model.

### Exercise 3

Continue the pipe to `fit(pres_vote ~ sex, data = nes_92)`.

```{r courage-3, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-3-hint-1, eval = FALSE}
... |> 
  fit(..., data = ...)
```

```{r courage-3-test, include = FALSE}
multinom_reg(engine = "nnet") |> 
  fit(pres_vote ~ sex, data = nes_92)
```

### 

Recall that a categorical variable (whether character or factor) like `sex` is turned into a $0/1$ "dummy" variable which is then re-named something like $sex{Male}$. After all, we can't have words --- like "Male" or "Female" --- in a mathematical formula, hence the need for dummy variables.

### Exercise 4

Continue the pipe with `tidy(conf.int = TRUE)`.

```{r courage-4, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-4-hint-1, eval = FALSE}
... |> 
  tidy(... = TRUE)
```

```{r courage-4-test, include = FALSE}
multinom_reg(engine = "nnet") |> 
  fit(pres_vote ~ sex, data = nes_92) |> 
  tidy(conf.int = TRUE)
```

### 

In this model, the **intercept** \(\beta_0\) represents the log-odds of voting for a candidate (e.g., Clinton or Perot) for the **reference group**, which in this case is **females** (because `sexMale = 0`).

The **slope coefficient** \(\beta_1\) represents the **difference in the log-odds** of voting for that candidate **between males and females**. If \(\beta_1\) is negative, it means that males are **less likely** (compared to females) to vote for that candidate. If it’s positive, they are **more likely**.

### Exercise 5

Behind the scenes of this tutorial, an object called `fit_nes` has been created which is the result of the code above. Type `fit_nes` and hit "Run Code." This generates the same results as using `print(fit_nes)`.

```{r courage-5, exercise = TRUE}

```

```{r courage-5-hint-1, eval = FALSE}
fit_nes
```

```{r courage-5-test, include = FALSE}
fit_nes
```

### 

In data science, **we deal with words, math, and code, but the most important of these is code.** We created the mathematical structure of the model and then wrote a model formula in order to estimate the unknown parameters.

### Exercise 8

We need `fit_nes` to exit in Console World. Copy/paste this code into the Console and execute it.

````
nes_92 <- nes |> 
  filter(year == 1992) |> 
  select(sex, pres_vote) |> 
  drop_na() |> 
  mutate(pres_vote = as.factor(case_when(
    pres_vote == "Democrat" ~ "Clinton",
    pres_vote == "Republican" ~ "Bush",
    pres_vote == "Third Party" ~ "Perot",
  ))) 

fit_nes <- multinom_reg(engine = "nnet") |>
  fit(pres_vote ~ sex, data = nes_92)
````

CP/CR.

```{r courage-8}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

###

Just because something exists in the tutorial (or in the QMD) does not mean that it is in the Console. You should be aware of what exists in Console World, which is generally called your "workspace."

### Exercise 6

Load the **[easystats](https://easystats.github.io/easystats/)** package.

```{r courage-6, exercise = TRUE}

```

```{r courage-6-hint-1, eval = FALSE}
library(...)
```

```{r courage-6-test, include = FALSE}
library(easystats)
```

###

We don't add **easystats** to the QMD because we are only using it for an interactive check of our fitted model. However, the [easystats ecosystem](https://easystats.github.io/easystats/) has a variety of interesting functions and packages which you might want to explore.

### 

Because `check_predictions()` does no work with multinomial models created with **tidymodels**, we can not use it on the `fit_nes`.

<!-- DK: Revisit in November 2025. -->


### Exercise 7

Ask AI to create $\LaTeX$ code for this model, including our variable names and estimates for all the coefficients. Because this is a fitted model, the dependent variable will have a "hat" and the formula will not include an error term. 

Add the code to your QMD. `Cmd/Ctrl + Shift + K`.

Make sure the resulting display looks good. For example, you don't want an absurd number of figures to the right of the decimal. If the model is too long, you will need to spread it across several lines. You may need to go back-and-forth with the AI a few times.

Once the $\LaTeX$ code looks good, paste it below.

```{r courage-7}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

###

<!-- XX: Replace these examples with your code. -->

Our formula looks like:

$$
\begin{aligned}
\hat{\rho}_{clinton} &= \frac{e^{0.45 - 0.25 \cdot male}}{1 + e^{0.45 - 0.25 \cdot male}} \\
\hat{\rho}_{perot}   &= \frac{e^{-0.85 + 0.42 \cdot male}}{1 + e^{-0.85 + 0.42 \cdot male}} \\
\hat{\rho}_{bush}    &= 1 - \hat{\rho}_{clinton} - \hat{\rho}_{perot}
\end{aligned}
$$


It was created with:

````
$$
\begin{aligned}
\hat{\rho}_{clinton} &= \frac{e^{0.45 - 0.25 \cdot male}}{1 + e^{0.45 - 0.25 \cdot male}} \\
\hat{\rho}_{perot}   &= \frac{e^{-0.85 + 0.42 \cdot male}}{1 + e^{-0.85 + 0.42 \cdot male}} \\
\hat{\rho}_{bush}    &= 1 - \hat{\rho}_{clinton} - \hat{\rho}_{perot}
\end{aligned}
$$
````

Note the differences. First, we have replaced the parameters with our best estimates. Second, we have dropped the error term because this is a formula for predicting the value for our outcome variable. Third, the left-hand side variable is now expressed as estimated probabilities, such as $\hat{\rho}{clinton}$, instead of unknowns like $\rho{clinton}$. A hat indicates an estimated value derived from the model fit.

**This is our data generating mechanism.**

A data generating mechanism is just a formula, something which we can write down and implement with computer code.

### Exercise 8

Create a new code chunk in `analysis.qmd`. Add two code chunk options: `label: model` and `cache: true`. Copy/paste the code from above for estimating the model into the code chunk, assigning the result to `fit_nes`. 

`Cmd/Ctrl + Shift + K`. It may take some time to render `analysis.qmd`, depending on how complex your model is. But, by including `cache: true` you cause Quarto to cache the results of the chunk. The next time you render `analysis.qmd`, as long as you have not changed the code, Quarto will just load up the saved fitted object.

To confirm, `Cmd/Ctrl + Shift + K` again. It should be quick.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", start = -8)
```

CP/CR.

```{r courage-8}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 8)
```

### 

### Exercise 9

Add `*_cache` to `.gitignore` file. Cached objects are often large. They don't belong on Github.

At the Console, run:

```
tutorial.helpers::show_file(".gitignore")
```

CP/CR.

```{r courage-9}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

###

Because of the change in your `.gitignore` (assuming that you saved it), the cache directory should not appear in the Source Control panel because Git is ignoring it, as instructed. Commit and push. 

### Exercise 10

In the Console, run `tidy()` on `fit_nes` with the argument `conf.int` set equal to `TRUE`. The returns 95% intervals for all the parameters in our model.

```{r courage-10, exercise = TRUE}

```

```{r courage-10-hint-1, eval = FALSE}
tidy(..., conf.int = ...)
```

```{r courage-10-test, include = FALSE}
tidy(fit_nes, conf.int = TRUE)
```

### 

`tidy()` is part of the [**broom**](https://broom.tidymodels.org/) package, used to summarize information from a wide variety of models.

### Exercise 11

Create a new code chunk in your QMD. Ask AI to help you make a nice looking table from the tibble which is returned by `tidy()`. You don't have to include all the variables which `tidy()` produces. We often just show the estimate and the confidence intervals.

Insert that code into the QMD. 

`Cmd/Ctrl + Shift + K`. 

Make sure it works. You might need to add some new libraries, e.g., **[tinytable](https://vincentarelbundock.github.io/tinytable/)**, **[knitr](https://yihui.org/knitr/)**, **[gt](https://gt.rstudio.com/)**, **[kableExtra](https://haozhu233.github.io/kableExtra/)**, **[flextable](https://davidgohel.github.io/flextable/)**, **[modelsummary](https://modelsummary.com/)**, et cetera, to the `setup` code chunk, if you use any functions from these packages, all of which have strengths and weaknesses for making tables.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", chunk = "Last")
```

CP/CR.

```{r courage-11}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 12)
```

###

At the very least, your table should include a title and a caption with the data source. The more you use AI, the better you will get at doing so.

### Exercise 12

Add a sentence to your project summary. 

Explain the structure of the model. Something like: "I/we model Y [the concept of the outcome, not the variable name] as a [linear/logistic/multinomial/ordinal] function of X [and maybe other covariates]."

Recall the beginning of our version of the summary:

> Understanding the voter preference of different genders is essential for a candidate to design a campaign strategy. Using data from the National Election Studies survey of US citizens, we seek to understand the relationship between voter preference and sex in the 1992 Presidential election. However, since not everyone participates in the survey, the data might not be representative of the entire population.

```{r courage-12}
question_text(NULL,
	message = "Understanding the voter preference of different genders is essential for a candidate to design a campaign strategy. Using data from the National Election Studies survey of US citizens, we seek to understand the relationship between voter preference and sex in the 1992 Presidential election. However, since not everyone participates in the survey, the data might not be representative of the entire population. We modeled voting result as a multinomial function of sex.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Read our answer. It will not be the same as yours. You can, if you want, change your answer to incorporate some of our ideas. Do not copy/paste our answer exactly. Add your two sentences, edited or otherwise, to summary paragrah portion of your QMD. `Cmd/Ctrl + Shift + K`, and then commit/push.

## Temperance
### 

*Temperance is a tree which as for its root very little contentment, and for its fruit calm and peace.* - Buddha

### Exercise 1

In your own words, describe the use of Temperance in data science.

```{r temperance-1}
question_text(NULL,
	message = "Temperance uses the data generating mechanism to answer the questions with which we began. Humility reminds us that this answer is always a lie. We can also use the DGM to calculate many similar quantities of interest, displaying the results graphically.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Courage gave us the data generating mechanism. Temperance guides us in the use of the DGM — or the “model” — we have created to answer the questions with which we began. We create posteriors for the quantities of interest. 

### Exercise 2

Before using the DGM, we should make sure that we can interpret it.

What does the estimate for the intercept in the clinton row mean in the context of this model?

```{r temperance-2}
question_text(NULL,
	message = "The intercept in the clinton row represents the log-odds of a female voter (the reference category for sex) voting for Clinton, relative to Bush (the base category in the multinomial model), when all other predictors are held constant.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

### Exercise 3

What does the coefficient for sexMale in the perot row tell us?

```{r temperance-3}
question_text(NULL,
	message = "When comparing male to female voters, male voters have higher log-odds of voting for Perot (relative to Bush) by the value of the sexMale coefficient. This does not mean males are more likely to vote for Perot in absolute terms — only that the log-odds relative to Bush are higher.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

### Exercise 4

Does the 95% confidence interval for the sexMale coefficient in the clinton row contain zero? What does that mean?

```{r temperance-4}
question_text(NULL,
	message = "If the confidence interval for the sexMale coefficient in the clinton row does not include zero, it suggests a statistically significant difference in the odds of voting for Clinton (vs. Bush) between males and females. If it does contain zero, then we can't confidently say that males and females differ in that respect.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 5

In the end, we don't really care about parameters, much less how to interpret them. Parameters are *imaginary*, like unicorns. We care about answers to our questions. Parameters are tools for answering questions. They aren't interesting in-and-of themselves. *In the modern world, all parameters are nuisance parameters.* 

Load the [**marginaleffects**](https://marginaleffects.com/) package.

```{r temperance-5, exercise = TRUE}

```

```{r temperance-5-hint-1, eval = FALSE}
library(...)
```

```{r temperance-5-test, include = FALSE}
library(marginaleffects)
```

### 

We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.

### Exercise 6

What is the specific question we are trying to answer? 

```{r temperance-6}
question_text(NULL,
	message = "What was the difference in voting preference of men and women in the 1992 US Presidential election among supporters of the three leading candidates: Clinton, Bush and Perot?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Data science projects almost always begin with a broad topic of interest. Yet, in order to make progress, we need to drill down to a specific question. This leads to the creation of a data generating mechanism, which can now be used to answer lots of questions, thus allowing us to explore the original topic broadly.



<!-- IS: tutorial says to run predictions() and avg_comparisons, but won't work on multinomial. Yes it does! -->

### Exercise 7

Run `plot_predictions` on `fit_nes` with `type` set to `"prob"`, and `condition` set to `c("sex")`.    

```{r temperance-7, exercise = TRUE}
plot_predictions(fit_nes, 
				 type = "prob",
                 condition = c("sex"))
```

```{r temperance-7-hint-1, eval = FALSE}
plot_predictions(fit_nes, 
				 type = ...,
                 condition = ...)
```

```{r temperance-7-test, include = FALSE}
plot_predictions(fit_nes, 
				 type = "prob",
                 condition = c("sex"))
```

### 

The plot displays the predicted probabilities of voting for each presidential candidate in 1992, separated by sex. Men were more likely to vote for Bush and Perot, while women were more likely to vote for Clinton. The differences in height between bars show how sex predicts vote choice in the model. These patterns reflect how gender shaped political preferences in the 1992 election.

### Exercise 8

Run `plot_predictions` on `fit_nes` with `by` set to `"sex`, `type` set to `"prob"`, and `draw` set to `FALSE`.               

```{r temperance-8, exercise = TRUE}

```

```{r temperance-8-hint-1, eval = FALSE}
plot_predictions(fit_nes, 
                 by = ...,
                 type = ...,
                 draw = ...)
```

```{r temperance-8-test, include = FALSE}
plot_predictions(fit_nes,
                 by = "sex", 
                 type = "prob",
                 draw = FALSE)
```

### 

This code returns the estimated probabilities of voting for each candidate, for male and female. 

The intercept coefficient from the fitted model (0.4553900) represents the log-odds, whereas the predicted probabilities from plot_predictions() represent the chances of a voter choosing Clinton based on sex, transformed from those log-odds.

### Exercise 9

Work interactively with your QMD to make a beautiful version of this plot. Your title should highlight the key variables. Your subtitle should describe the key takeaway, the sentence/conclusion which readers will, you hope, remember. Your caption should mention the data source. Your axis labels should look nice.

This plot is not directly connected to your question. It answers lots of questions! It might be used by lots of different people. 

Copy the code for your plot here:

```{r temperance-9}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 20)
```

###

Data science often involves this-back-and-forth style of work. First, we need to make a single chunk of code, in this case, a new plot, work well. This requires interactive work between the QMD and the Console. Second, we need to ensure that the entire QMD runs correctly on its own.

### Exercise 10

Finalize the new graphics code chunk in your QMD.

`Cmd/Ctrl + Shift + K` to ensure that it all works as intended. Don't forget to add `library(marginaleffects)` to your `setup` code chunk.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", start = -8)
```

CP/CR.

```{r temperance-10}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 10)
```


### 

Always [remember](https://en.wikipedia.org/wiki/Map%E2%80%93territory_relation): *The map is not the territory.* A beautiful graphic tells a story, but that story is always an imperfect representation of reality. Our models depend on assumptions, assumptions which are never completely true.

### Exercise 11

Write the last sentence of your summary paragraph. It describes at least one quantity of interest (QoI) and provides a measure of uncertainty about that QoI. (It is OK if this QoI is not the one that you began with. The focus of a data science project often changes over time.)

```{r temperance-11}
question_text(NULL,
	message = "Understanding the voter preference of different genders is essential for a candidate to design a campaign strategy. Using data from the National Election Studies survey of US citizens, we seek to understand the relationship between voter preference and sex in the 1992 Presidential election. However, since not everyone participates in the survey, the data might not be representative of the entire population. We modeled voting result as a multinomial function of sex. Women are most likely to support Clinton. About 53% of women claim to support Clinton, although that number could be as high as 58% or as low as 48%.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Add a final sentence to your summary paragraph in your QMD as you see fit, but do not copy/paste our answer exactly. `Cmd/Ctrl + Shift + K`.


### Exercise 12

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval, if you think either might be warranted.


```{r temperance-12}
question_text(NULL,
	message = "As we would tell our boss, it would not be shocking to find out that the voting preference was less or more than our estimate. This is because a lot of the assumptions we make during the process of building a model, the processes in Wisdom, are subject to error. Perhaps our data did not match the future as well as we had hoped. In such cases, increase the confidence interval since the assumptions of your model are always false.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 13

Rearrange the material in your QMD so that the order is graphic, paragraph, math and table. Doing so, of course, requires sensible judgment. For example, the code chunk which creates the fitted model must occur before the chunk which creates the graphic. `Cmd/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd")
```

CP/CR.

```{r temperance-13}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

This is the version of your QMD file which your teacher is most likely to take a close look at.

### Exercise 14

Publish your rendered QMD to Rpubs. Choose a sensible slug. Copy/paste the resulting url below.

```{r temperance-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Add `rsconnect` to the `.gitignore` file. You don't want your personal Rpubs details stored in the clear on Github. Commit/push everything.

### Exercise 15

Copy/paste the url to your Github repo.

```{r temperance-15}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

## Summary
### 

This tutorial supports [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

The plot above shows the predicted probabilities of voting for Clinton, Bush, or Perot based on the respondent’s gender. We see that women were more likely than men to support Clinton, while men were more likely than women to support Perot. Support for Bush was similar across genders, with a slight male preference. These differences suggest that gender played a meaningful role in voter preferences during the 1992 election.

This information helps our historian better understand the political dynamics of the time. Gendered voting patterns offer insight into campaign messaging, voter priorities, and broader societal attitudes at a pivotal moment in American political history.

```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
