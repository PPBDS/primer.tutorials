---
title: 'Data: Files'
author: Shyamsai Bethina
tutorial:
  id: data-files
output:
  learnr::tutorial:
    progressive: yes
    allow_skip: yes
runtime: shiny_prerendered
description: Reading data from files.
---

```{r setup, include = FALSE}
library(learnr)
library(primer.tutorials)
library(tidyverse)
library(janitor)
library(readxl)
library(jsonlite)
library(knitr)
library(googlesheets4)
library(googledrive)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

# We need this call to allow us to interact with public Google Sheets. 

gs4_deauth()

tbl_1 <- tibble(a = 1 , b = 2, c = 3)

iris_p <- iris %>% 
  ggplot(aes(x = Sepal.Length, y = Sepal.Width)) +
  geom_jitter() +
  labs(title = "Sepal Dimensions of Various Species of Iris",
       x = "Sepal Length",
       y = "Sepal Width")

example_1 <- tibble(name = c("Miguel", "Sofia", "Aya", "Cheng"), 
                    student_id = 1:4, exam_1 = c(85, 94, 87, 90), 
                    exam_2 = c(86, 93, 88, 91))

json<- '[
  [1, 2, 3, 4],
  [5, 6, 7, 8],
  [9, 10, 11, 12]
]'
```

```{r copy-code-chunk, child = "../../child_documents/copy_button.Rmd"}
```

```{r info-section, child = "../../child_documents/info_section.Rmd"}
```

<!-- Figure out authentication so we can create some Google Sheets. -->

<!-- realising that #dplyr::select() can also simultaneously rename columns! -->

## CSV Files

### 

"CSV" stands for **c**omma-**s**eparated **v**alues, meaning that the variable names and data values are separated by commas in the file. All the files we will use in this tutorial live in the `data/` directory.

### Exercise 1

Consider the contents of the `test_1.csv` file.

```{r comment = ''}
cat(readLines("data/test_1.csv"), sep = "\n")
```

### 

Write code to read this file into R using read_csv(), and set the `file` argument to "data/test_1.csv".

```{r csv-files-1, exercise = TRUE}

```

```{r csv-files-1-hint-1, eval = FALSE}
Use read_csv() to read in a csv file. 
Set the `file` argument to "data/test_1.csv".
```

```{r csv-files-1-hint-2, eval = FALSE}
read_csv(file = "data/test_1.csv")
```

### 

The result when your code is run should look like this:

```{r}
read_csv("data/test_1.csv")
```

### 

The column specification message is a suggestion to specify the data types for each column of data. R "guesses" a data type until we use the `col_types` argument. 


### Exercise 2

Make the warning message disappear by setting the `show_col_types` argument to `False`.

```{r csv-files-2, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r csv-files-2-hint-1, eval = FALSE}
read_csv(files = "data/test_1.csv",
         show_col_types = ...)
```

### 

Your code should look like this after running it:

```{r}
read_csv("data/test_2.csv",
         show_col_types = FALSE)
```

### 

It is often better to use the `col_types` argument explicitly in order to ensure that the variable types are what you want them to be.


### Exercise 3

```{r csv-files-3-setup}
cat(readLines("data/test_1.csv"), sep = "\n")
```

Consider the contents of the `test_2.csv` file. 

```{r comment = ''}
cat(readLines("data/test_2.csv"), sep = "\n")
```

### 

Write code for skipping the text at the top of `"data/test_2.csv"` by setting the second argument `skip` to the appropriate number.

```{r csv-files-3, exercise = TRUE}

```

```{r csv-files-3-hint-1, eval = FALSE}
In addition to the `file` argument, you will 
need to use the`skip` argument here. Set `skip` 
to 2.
```

```{r csv-files-3-hint-2, eval = FALSE}
read_csv(file = "data/test_2.csv",
          skip = ...)
```

### 

The result when your code is run should look like this:

```{r}
read_csv("data/test_2.csv",
         skip = 2)
```

### 

The argument `skip` is used to skip rows, but to skip columns, you can set `col_types` to `col_only` to only read the specified columns you want. 

### Exercise 4

```{r csv-files-4-setup}
cat(readLines("data/test_3.csv"), sep = "\n")
```

Consider the contents of the `test_3.csv` file. 

```{r comment = ''}
cat(readLines("data/test_3.csv"), sep = "\n")
```

### 

Write code that will create default names for `"data/test_3.csv"` by setting the `col_names` argument to `FALSE`.

```{r csv-files-4, exercise = TRUE}

```

```{r csv-files-4-hint-1, eval = FALSE}
Use the `col_names argument and set it to FALSE
```

```{r csv-files-4-hint-2, eval = FALSE}
read_csv(file = "data/test_3.csv",
          col_names = ...)
```

### 

The result when your code is run should look like this:

```{r}
read_csv("data/test_3.csv",
         col_names = FALSE)
        
```

### 

The argument `col_names` can also be used to create custom column names. 

### Exercise 5

```{r csv-files-5-setup}
cat(readLines("data/test_3.csv"), sep = "\n")
```

Consider, again, the contents of the `test_3.csv` file. 

```{r comment = ''}
cat(readLines("data/test_3.csv"), sep = "\n")
```

### 

<!-- Using `col_names`, write code that will name the columns `a`, `b` and `c`.  -->

Set the argument `col_names` to a vector containing the column names `"a"`, `"b"`, and `"c"`.

```{r csv-files-5, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r csv-files-5-hint-1, eval = FALSE}
Use the `col_names` argument and set it to c("a", "b", "c"). 
```

### 

The result when your code is run should look like this:

```{r}
read_csv("data/test_3.csv",
         col_names = (c("a", "b", "c")))
```

### 

`col_names` is not only specific to `read_csv()`, it can be used in other functions such as `read_excel` and `read_delim()`


### Exercise 6

```{r csv-files-6-setup}
cat(readLines("data/test_3.csv"), sep = "\n")
```

Get rid of the column specification message by setting the `col_types` argument to `cols(a = col_double(), b = col_double(), c = col_double())`.


```{r csv-files-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r csv-files-6-hint-1, eval = FALSE}
read_csv("data/test_3.csv",
         col_names = (c("a", "b", "c")),
         col_types = cols(a = col_double(), 
                        b = col_double(), 
                        c = col_double()))
```

### 

The result when your code is run should look like this:

```{r}
read_csv("data/test_3.csv",
         col_names = (c("a", "b", "c")),
         col_types = cols(a = col_double(), 
                        b = col_double(), 
                        c = col_double()))
```

### 

There are many other arguments to `cols`. You can type `?cols` into your console to see all the different arguments!


### Exercise 7

```{r csv-files-7-setup}
cat(readLines("data/test_5.csv"), sep = "\n")
```

Consider the contents of the `test_5.csv` file. Note the "." for the first value for `b`. In this file, a period indicates a missing value. **This is not always true.** Missing values can be indicated in many different ways. And, sometimes, a period is just a period.

```{r comment = ''}
cat(readLines("data/test_5.csv"), sep = "\n")
```

### 

Write code to recognize the `.` value for `b` in `"data/test_5.csv"` as an NA value by setting the `na` argument to "." in `read_csv`.

```{r csv-files-7, exercise = TRUE}

```

```{r csv-files-7-hint-1, eval = FALSE}
Use the `na` argument and set it to "."
```

```{r csv-files-7-hint-2, eval = FALSE}
read_csv(file = "data/test_5.csv",
         na = ".")
```

### 

The result when your code is run should look like this:

```{r}
read_csv("data/test_5.csv",
         na = ".")
```

### 

Before removing `"."`, the `col_type` of Column b was character, but after it became a `double`. One element can change the entire column which can mess up other parts of your code.


### Exercise 8

```{r csv-files-8-setup}
cat(readLines("data/test_6.csv"), sep = "\n")
```

Consider the contents of the `test_6.csv` file.

```{r comment = ''}
cat(readLines("data/test_6.csv"), sep = "\n")
```

### 

Write code for skipping the text lines within `"data/test_6.csv"` by setting the `comment` to "#".

```{r csv-files-8, exercise = TRUE}

```

```{r csv-files-8-hint-1, eval = FALSE}
Use the `comment` argument and set it to "#".
```

```{r csv-files-8-hint-2, eval = FALSE}
read_csv(file = "data/test_6.csv",
         comment = "...")
```

### 

The result when your code is run should look like this:

```{r}
read_csv("data/test_6.csv",
         comment = "#")
```

### 

It doesn't always have to be "#", it can be any character that designates a line as a comment!

### Exercise 9

```{r csv-files-9-setup}
cat(readLines("data/test_7.csv"), sep = "\n")
```

Consider the contents of the `test_7.csv` file.

```{r comment = ''}
cat(readLines("data/test_7.csv"), sep = "\n")
```

### 

Write code to make sure the column `grade` within `"data/test_7.csv"` appears as an integer variable (`col_integer()`), and `student` as a character variable (`col_character()`).

```{r csv-files-9, exercise = TRUE}

```

```{r csv-files-9-hint-1, eval = FALSE}
Use the col_types argument and set it 
to cols(grade = col_integer(), 
        student = col_character())
```

### 

The result when your code is run should look like this:

```{r}
read_csv("data/test_7.csv",
         col_types = cols(grade = col_integer(),
                          student = col_character()))
```

### 

There are many more data types such as `col_logical`, `col_double`, `col_date`, etc.

### Exercise 10

Consider the following tibble `tbl_1`.

```{r}
tbl_1 <- tibble(John = 1 , Aliya = 2, Maxilla = 3)
tbl_1
```

### 

<!-- AG: It seems like tutorial exercises don't store their files in the same place (at least on Windows), so I'm combining the list.files() and write_csv() so that you can see the result. -->

Use `write_csv()` to save this tibble to a file named "tbl_1.csv". Then add `list.files()` after that in order to see the file that you've created.

```{r csv-files-10, exercise = TRUE}

```

```{r csv-files-10-hint-1, eval = FALSE}
The first argument should be the object you want 
to save. The second argument should be the name you 
want the file saved as.
```

```{r csv-files-10-hint-2, eval = FALSE}
write_csv(...)
list.files()
```

### 

Your result should look like include two files: `exercise.Rmd`, which is a file used by the **learnr** package and `tbl_1.csv`, which is the file you created.

There are many arguments to `write_csv()` such as `delim`, `na`, `col_names` and many more to make the written file cleaner.

### Exercise 11

Consider the contents of the `test_bad_names.csv` file.

```{r comment = ''}
cat(readLines("data/test_bad_names.csv"), sep = "\n")
```

### 

Many files will have column names that are not formatted correctly, but **tidyverse** has the `name_repair` argument to fix that. Using the contents of `"data/test_bad_names.csv"`, use the `name_repair` argument and set it to `"universal"` in `read_csv()`

```{r csv-files-11, exercise = TRUE}

```

```{r csv-files-11-hint-1, eval = FALSE}
read_csv(file="data/test_bad_names.csv", name_repair="universal")
```

### 

The result when your code is run should look like this:

```{r}
read_csv(file = "data/test_bad_names.csv", name_repair = "universal")
```

### 

The `"universal"` makes sure the columns names are all unique and uses the syntax already built into the `name_repair` command to organize the names. There are other options such as `minimal` and`unique`, try them out!


### Exercise 12

The  [**janitor**](https://garthtarr.github.io/meatR/janitor.html) package is also commonly used for cleaning names. Load in the package below. *Note*: Nothing will be displayed if the code runs correctly.

```{r csv-files-12, exercise = TRUE}

```

```{r csv-files-12-hint-1, eval = FALSE}
library(janitor)
```

### Exercise 13

Now read the file `"data/test_bad_names.csv"` using `read_csv()`. Then pipe it into `clean_names()`, a function from the **janitor** package.

```{r csv-files-13, exercise = TRUE}

```

```{r csv-files-13-hint-1, eval = FALSE}
read_csv(file = "data/test_bad_names.csv") %>% 
  clean_names()
```

### 

The result when your code is run should look like this:

```{r}
read_csv(file = "data/test_bad_names.csv") %>% 
  clean_names()
```

### 

The function `clean_names()` used the syntax within the **janitor** package to clean the names and also makes them unique. This lets you easily access the different columns without running into errors.

### Exercise 14

To make the code cleaner and to reduce the number of pipes, you can set the `name_repair` argument to `janitor::make_clean_names` in `read_csv()`.

```{r csv-files-14, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r csv-files-14-hint-1, eval = FALSE}
read_csv(file = "data/test_bad_names.csv", 
         name_repair = janitor::make_clean_names)
```

### 

The result when your code is run should look like this:

```{r}
read_csv(file = "data/test_bad_names.csv",
         name_repair = janitor::make_clean_names)
```

### 

The **janitor** package has a function called `remove_empty()` to remove empty spaces, `remove_constant()` to remove columns of constant values, and many more. Try them out!

## Parsing multiple files

### 

Data Scientists deal with a huge number of files loaded with data, so it is important to learn how to clean multiple files at once.

### Exercise 1

Run `list.files("data")` to check what files there are in the `data` folder.

```{r parsing-multiple-fil-1, exercise = TRUE}

```

```{r parsing-multiple-fil-1-hint-1, eval = FALSE}
list.files("data")
```

### 

The function `list.files()` accepts directories, not just names of folders.

### Exercise 2

Set the argument `pattern` to `"similar"` to only look at the files with the names "similar" in them.

```{r parsing-multiple-fil-2, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r parsing-multiple-fil-2-hint-1, eval = FALSE}
list.files("data", pattern = "similar")
```

### 

The result when your code is run should look like this:

```{r}
list.files("data", pattern = "similar")
```

### 

You can also set `pattern` to ".csv" or ".delim" for those types of files in a folder.

### Exercise 3

To show the exact directory of where the files came from, set the argument `full.names` to `TRUE` in `list.files()`.

```{r parsing-multiple-fil-3, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r parsing-multiple-fil-3-hint-1, eval = FALSE}
list.files("data", pattern = "similar", full.names = TRUE)
```

### 

The result when your code is run should look like this:

```{r}
list.files("data", pattern = "similar", full.names = TRUE)
```

### Exercise 4

These are the contents of `similar_1.csv`, `similar_2.csv`, `similar_3.csv`, respectively.

```{r}
cat(readLines("data/similar_1.csv"), sep = "\n")
cat(readLines("data/similar_2.csv"), sep = "\n")
cat(readLines("data/similar_3.csv"), sep = "\n")
```

### 

Now let's combine the files by piping the previous code with `read_csv()`!

```{r parsing-multiple-fil-4, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r parsing-multiple-fil-4-hint-1, eval = FALSE}
list.files("data", pattern = "similar", full.names = TRUE) %>% 
  read_csv()
```

### 

Column `b`'s type is `chr` because the "." in `similar_1.csv` makes R think the rest of the column are characters. We will fix that using the `na` argument in `read_csv()`.

### Exercise 5

In `read_csv()`, set the argument `na` to `"."` to get rid of the character in column `b`.

```{r parsing-multiple-fil-5, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r parsing-multiple-fil-5-hint-1, eval = FALSE}
... %>% 
  read_csv(na = ".")
```

### 

The result when your code is run should look like this:

```{r}
list.files("data", pattern = "similar", full.names = TRUE) %>% 
  read_csv(na = ".")
```

### 

Because the "." is gone, column `b`'s type is `dbl` now. 

### Exercise 6

Now let's get rid of the annoying "specify column types" message by using the `show_col_types` argument.

```{r parsing-multiple-fil-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r parsing-multiple-fil-6-hint-1, eval = FALSE}
... %>% read_csv(na = ".", show_col_types = FALSE)
```

### 

You can use the other arguments of `read_csv()` to further clean your files, such as `col_names`, `col_types`, and `skip`. 

### 

These functions can be used as a stepping stone to filter huge amounts of data, but **Tidyverse** has many interesting functions, explore them!

<!-- Deleted exercise 7 which used the janitor function as it made no change in the column names so it was trivial to even show them -->

## Text files

### 

CSV files are just one type of **text** file. A text file is any file which includes plain text. The contents of such files are easy to look at in any text editor, or in RStudio.

### Exercise 1

```{r text-files-1-setup}
cat(readLines("data/delim_1.txt"), sep = "\n")
```

Consider the contents of the text file `delim_1.txt`:

```{r}
cat(readLines("data/delim_1.txt"), sep = "\n")
```

### 

Write code for reading this file in to R. The values in the file are separated by pipes rather than commas. So, instead of `read_csv()`, you should use `read_delim()`. 

```{r text-files-1, exercise = TRUE}

```

```{r text-files-1-hint-1, eval = FALSE}
Set the file argument to "data/delim_1.txt". 
Also use the `delim` argument and set it to "|".
```

### 

The result when your code is run should look like this:

```{r}
read_delim("data/delim_1.txt", delim = "|")
```

### 

Note how the spaces and commas are included in the values for `town`. You can't use `read_csv()` here because not all the columns are denoted by commas.

### Exercise 2

```{r text-files-2-setup}
cat(readLines("data/delim_2.txt"), sep = "\n")
```

Consider the contents of the text file `delim_2.txt`:

```{r}
cat(readLines("data/delim_2.txt"), sep = "\n")
```

### 

Write code for reading this file in to R. Also, use the `col_types` argument to both prevent the col_types message from printing out and to set `population` as an integer.

```{r text-files-2, exercise = TRUE}

```

```{r text-files-2-hint-1, eval = FALSE}
Set the `col_types` argument to 
cols(date = col_date(format = ""),
     population = col_integer(),
     town = col_character())
```

### 

The result when your code is run should look like this:

```{r}
read_delim("data/delim_2.txt", 
           delim = "|",
           col_types = cols(date = col_date(format = ""),
                            population = col_integer(),
                            town = col_character()))
```

## Excel files

### 

Excel is a spreadsheet program that use tables to analyze, store, or manipulate data. The tables are composed of cells which include text, numbers, or formulas.

### Exercise 1

```{r excel-files-1-setup}
cat(readLines("data/excel_1.xlsx"), sep = "\n")
```

Consider the contents of the excel file `excel_1.xlsx`:

```{r}
include_graphics("images/excel_1.png")
```

### 

Write code for reading this file in to R by using the `read_excel()` function from the [**readxl**](https://readxl.tidyverse.org) package.

```{r excel-files-1, exercise = TRUE}

```

```{r excel-files-1-hint-1, eval = FALSE}
Use `read_excel()` and set the `path` argument to `data/excel_1.xlsx`.
```

### 

The result when your code is run should look like this:

```{r}
read_excel("data/excel_1.xlsx")

```

### 

You can use the **janitor** package to remove empty rows or columns which are common in excel files.


### Exercise 2

```{r excel-files-2-setup}
cat(readLines("data/excel_1.xlsx"), sep = "\n")
```

Let's once again consider the contents of `excel_1.xlsx`. However, we want to look at the second sheet of the file. **Note**: Sheet 1 is the default when looking at an Excel file, so the last exercise only showed us the contents of Sheet 1.


```{r}
include_graphics("images/excel_2.png")
```

### 

Write code for reading the second sheet of the file into R by setting the `sheet` argument to "Sheet2" in `read_excel()`.

```{r excel-files-2, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r excel-files-2-hint-1, eval = FALSE}
Use the `sheet` argument to look at other sheets.
Set `sheet` to "Sheet2".
```

### 

The result when your code is run should look like this:

```{r}
read_excel("data/excel_1.xlsx", sheet = "Sheet2")
```

### 

To write Excel files out, you need to use the [**xlsx**](http://www.sthda.com/english/wiki/r-xlsx-package-a-quick-start-guide-to-manipulate-excel-files-in-r) package and the function `write.xlsx`. 


## Google Sheets

### 

[Google Sheets](https://www.google.com/sheets/about/) are like Excel spreadsheets which live in the Google cloud. They are also used to store data, so it's important to learn how to work with them.


### Exercise 1

First we have to load in the [**googlesheets4**](https://googlesheets4.tidyverse.org/) package, do that below.

```{r google-sheets-1, exercise = TRUE}

```

```{r google-sheets-1-hint-1, eval = FALSE}
library(googlesheets4)
```

### 

The package is used for reading Google Sheets. We will use public sheets available on the internet during this section, accessing your own sheets requires the [**googledrive**](https://googledrive.tidyverse.org) package.


### Exercise 2

We will use a Google Sheet provided from the **googlesheets4**. The url is "https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077". Place the link,*in quotations*, directly into the function `read_sheet()`.

```{r google-sheets-2, exercise = TRUE}

```

```{r google-sheets-2-hint-1, eval = FALSE}
read_sheet("https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077")
```

### 

The result when your code is run should look like this:

```{r}
read_sheet("https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077")
```

### Exercise 3

Sheets also have a unique ID they can be identified with, which are much shorter than urls. The id for the Sheet above is "1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY". Place the id,*in quotations*, directly into the function `read_sheet()`. 

```{r google-sheets-3, exercise = TRUE}

```

```{r google-sheets-3-hint-1, eval = FALSE}
read_sheet("1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY")
```

### 

The id of a sheet is between the "/d/" and the "gid=" in the URL of the Google Sheet.

### Exercise 4

We can use the function `gs4_examples()` to list example sheets within the **googlesheets4** package. Run the function below.

```{r google-sheets-4, exercise = TRUE}

```

```{r google-sheets-4-hint-1, eval = FALSE}
gs4_examples()
```

### Exercise 5

Now use `gs4_example()` to specifically list out the metadata of the Sheet "deaths".

```{r google-sheets-5, exercise = TRUE}

```

```{r google-sheets-5-hint-1, eval = FALSE}
gs4_example("deaths")
```

### 

The metadata of a Sheet is important because it gives crucial information at a glance such as column names, ranges of each column, and the number of sheets. You can use the function `gs4_get()` to get metadata of Sheets outside of only the example Sheets.

### Exercise 6

Read the Sheet "deaths" by piping the previous code with `read_sheet()`.

```{r google-sheets-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r google-sheets-6-hint-1, eval = FALSE}
gs4_example("deaths") %>% 
  read_sheet()
```

### 

In the result, notice how there is a section called `Named Range`. This shows the column names of the sheets, which can be used to filter out certain columns you don't want. 

<!-- Had to delete exercise 7 because it required google authentication to access other Sheets outside of the example Sheets -->

### Exercise 7

The previous sheet file had two worksheets, `arts` and `other`. Using the previous code, set the `sheet` argument in `read_sheet()` to `2`.

```{r google-sheets-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r google-sheets-7-hint-1, eval = FALSE}
gs4_example("deaths") %>% 
  read_sheet(sheet = 2)
```

### 

The result when your code is run should look like this:

```{r}
gs4_example("deaths") %>% 
  read_sheet(sheet = 2)
```

### 

In `read_sheet()`, you can choose to use the **janitor** package, or the built-in `trim_ws` argument to trim out leading and trailing whitespace.


### Exercise 8

You can also set the range of rows and columns you want to look at. Using previous code, set the `range` argument to `"A5:F15"` in `read_sheet()`.

```{r google-sheets-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r google-sheets-8-hint-1, eval = FALSE}
read_sheet(gs4_example("deaths"), sheet = 2, range = "A5:F15")
```

### 

The result when your code is run should look like this:

```{r}
read_sheet(gs4_example("deaths"), sheet = 2, range = "A5:F15")
```

### 

If you want a limit on the number of rows that are read, you can use `n_max`. It is helpful if you just want a glimpse of the sheet in tibble form.

### 

It is also possible to write to Google Sheets, but we were not able to get authentication to work within the context of this tutorial.

## RDS files

### 

RDS files store R objects in a file which can be saved on your computer. Then, if you come back to a project, even after restarting R, you can quickly load back the object, without redoing all the code which created it.

### Exercise 1

Consider the following plot.

```{r}
iris %>% 
  ggplot(aes(x = Sepal.Length, y = Sepal.Width)) +
  geom_jitter() +
  labs(title = "Sepal Dimensions of Various Species of Iris",
       x = "Sepal Length",
       y = "Sepal Width")
```

### 

We have saved the plot for you to an object named `iris_p`. On the line 8, use `write_rds()` to save this plot to a file named "test_1.rds". *Note*: Nothing will be displayed for you to see.


```{r rds-files-1, exercise = TRUE}
iris_p <- iris %>% 
  ggplot(aes(x = Sepal.Length, y = Sepal.Width)) +
  geom_jitter() +
  labs(title = "Sepal Dimensions of Various Species of Iris",
       x = "Sepal Length",
       y = "Sepal Width")

```

```{r rds-files-1-hint-1, eval = FALSE}
The first argument should be the object you want to save. 
The second argument should be the name you want the 
file saved as.
```

```{r rds-files-1-hint-2, eval = FALSE}
write_rds(iris_p, 
          "test_1.rds")
```

### 

The big advantage of creating an rds file is that we can reload the object it contains later, without re-running the code which created it.  

### Exercise 2

```{r rds-files-2-setup}
cat(readLines("data/test_1.rds"), sep = "\n")
```

<!-- Somehow this works unlike what happened in the CSV section, so I'm not touching it. -->

Run `list.files()`. You should see your newly created file listed.

```{r rds-files-2, exercise = TRUE}

```

```{r rds-files-2-hint-1, eval = FALSE}
list.files()
```

### 

Your result should look like include two files: `exercise.Rmd`, which is a file used by the **learnr** package and `test_1.rds`, which is the file you created.

### 

To find the file in your pc, you can set the argument `include.dirs` to `TRUE` so that `list.files()` can speel out the directories for you.

### Exercise 3

```{r rds-files-3-setup}
cat(readLines("data/test_1.rds"), sep = "\n")
```

Let's now use `read_rds()` to read in the newly created file! Set the `file` argument to "data/test_1.rds".

```{r rds-files-3, exercise = TRUE}

```

```{r rds-files-3-hint-1, eval = FALSE}
read_rds(file = "data/test_1.rds")
```

### 

Plots are just one example of what we can store in and .rds file. We can also store datasets.

### Exercise 4

Consider the following dataset.

```{r}
glimpse(mtcars)
```

### 

Use `write_rds()` to save `mtcars` to a file named `test_2.rds`.

```{r rds-files-4, exercise = TRUE}

```

```{r rds-files-4-hint-1, eval = FALSE}
The first argument should be the object you want to save. 
The second argument should be the name you want the 
file saved as.
```

```{r rds-files-4-hint-2, eval = FALSE}
write_csv(mtcars, "test_2.rds")
```

### 

You are not limited to just one object in an .rds file. You can save multiple!

### Exercise 5

```{r rds-files-5-setup}
cat(readLines("data/test_2.rds"), sep = "\n")
```

<!-- I think RDS files are just different, since this works as well. -->

Run `list.files()`. You should see your newly created file listed.

```{r rds-files-5, exercise = TRUE}

```

```{r rds-files-5-hint-1, eval = FALSE}
list.files()
```

### 

Your result should look like include two files: `exercise.Rmd`, which is a file used by the **learnr** package and `test_2.rds`, which is the file you created.

### 

You can also use `append` in `write_delim()` to add on data to an existing file.


### Exercise 6

```{r rds-files-6-setup}
cat(readLines("data/test_2.rds"), sep = "\n")
```

Great. Let's now use `read_rds()` to read in the newly created file! Set the `file` argument to "data/test_2.rds".

```{r rds-files-6, exercise = TRUE}

```

```{r rds-files-6-hint-1, eval = FALSE}
read_rds(file = "data/test_2.rds")
```

### 

If you want to also add column names when using `write_csv`, you can set the
`col_names` argument to `TRUE`.

## JSON files 

### 

An increasingly common format for sharing data is JavaScript Object Notation or JSON. 

JSON is a standard text-based format for representing structured data based on JavaScript object syntax.

### Exercise 1

```{r json-files-1-setup}
cat(readLines("data/test_1.json"), sep = "\n")
```

Consider the contents of the file `test_1.json`.

```{r}
cat(readLines("data/test_1.json"), sep = "\n")
```

### 

Write code for reading this JSON file into R as a tibble. Use the `fromJSON()` function from the [**jsonlite**](https://cran.r-project.org/web/packages/jsonlite/vignettes/json-aaquickstart.html) package.

```{r json-files-1, exercise = TRUE}

```

```{r json-files-1-hint-1, eval = FALSE}
fromJSON("data/test_1.json")
```

### 

If there are "null" values in the file, you can specify how to encode those values with the `null` argument in `fromJSON`.


### Exercise 2

Consider the following tibble, which is saved in the environment as an object called `example_1`.

```{r}
tibble(name= c("Miguel", "Sofia", "Aya", "Cheng"), 
                student_id = 1:4, exam_1 = c(85, 94, 87, 90), 
                exam_2 = c(86, 93, 88, 91))
```

### 

Write code to convert the following tibble into JSON format. Use the `toJSON()` function from the **jsonlite** package.

```{r json-files-2, exercise = TRUE}

```

```{r json-files-2-hint-1, eval = FALSE}
toJSON(example_1)
```

### 

`toJSON` actually has the same arguments as `fromJSON`, meaning that you can use `null`, `na`, `pretty` and many more arguments to make the result how you want it to be.

### Exercise 3

After converting from a tibble to the JSON format, it is hard to read the JSON format. To fix this, use the previous code and set the second argument `pretty` equal to `TRUE`.

```{r json-files-3, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r json-files-3-hint-1, eval = FALSE}
toJSON(example_1, pretty = ...)
```

### 

The `pretty` argument comes from the [**prettify**](https://www.rdocumentation.org/packages/papeR/versions/1.0-5/topics/prettify) package, run `??prettify` to learn more about it.


### Exercise 4

Try reading from the `json` object which has already been loaded with JSON array data. Use `fromJSON()` to display the data in a tibble.

```{r json-files-4, exercise = TRUE}

```

```{r json-files-4-hint-1, eval = FALSE}
fromJSON(json)
```

### 

As you can see, `fromJSON()` can display arrays as well, which can be useful for datasets that include matrices. You can do math operations with them as well! 

### Exercise 5

You can also write information like arrays or matrices to a JSON format using `toJSON()`. 

Display a 3x3 array in JSON format by creating 3 arrays structured like `[1, 2, 3]`, containing them in a larger array, and then passing them into `toJSON()`.

```{r json-files-5, exercise = TRUE}

```

```{r json-files-5-hint-1, eval = FALSE}
json2 <- '[[..., ..., ...], [..., ..., ...], [..., ..., ...]]'

```

```{r json-files-5-hint-2, eval = FALSE}
json2 <- '[[..., ..., ...], [..., ..., ...], [..., ..., ...]]'
toJSON(json2)
```

### 

Because JSON files can so easily store complex matrix data, they're often used in APIs and websites. This makes `fromJSON()` invaluable when you're pulling data off the Internet, as the data will often come in a JSON file. 

Vice versa, `toJSON()` is useful for when you want to send data across the Internet due to its light weight (there's very little extra formatting included in the file and it's mostly data).

## Parsing a vector

### 

There are many `parse_*()` functions that break down the most important parts of an individual vector.

### Exercise 1

People write numbers differently in different parts of the world. For example, some countries use `.` in between the integer and fractional parts of a real number, while others use `,`.

### 

To begin, use the function  `parse_double()` with the argument "1.23".

```{r parsing-a-vector-1, exercise = TRUE}

```

```{r parsing-a-vector-1-hint-1, eval = FALSE}
parse_double("1.23")
```

### 

There other `parse` functions such as `parse_logical`, `parse_integer`, and `parse_character`.

### Exercise 2

What if the file you worked with used a comma to denote a decimal mark? The [**readr**](https://readr.tidyverse.org) package has whats called a “locale”, an object that specifies parsing options that differ from place to place.You can override the default value of "." by creating a new locale and setting the `decimal_mark` argument.

### 

Use `parse_double()` with the argument "1,23". The second argument should set `locale` to `locale(decimal_mark = ",")`.

```{r parsing-a-vector-2, exercise = TRUE}

```

```{r parsing-a-vector-2-hint-1, eval = FALSE}
parse_double("1,23", locale = ...)
```

Note that **readr’s** default locale is US-centric because R is generally US-centric.

### Exercise 3

The function `parse_number()` ignores non-numeric characters before and after the number. 

### 

Use `parse_number()` with the argument "$100". Then on the line below, use `parse_number()` again with the argument "20%".


```{r parsing-a-vector-3, exercise = TRUE}

```

```{r parsing-a-vector-3-hint-1, eval = FALSE}
parse_number("$100")
parse_number("20%")
```

### 

Unlike `parse_integer` and `parse_double`, `parse_number` can parse both integers and doubles.

### Exercise 4

Great. Now use `parse_number()` with the argument "The cost of the package is $40.75" 

```{r parsing-a-vector-4, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r parsing-a-vector-4-hint-1, eval = FALSE}
parse_number("The cost of ...." )
```

### Exercise 5

The function `parse_date()` allows you to parse a date. The function requires the following criteria: a four digit year,  a `-` or `/`, the month, a `-` or `/`, then the day. An example would be "2010-10-01".

### 

Use `parse_date()` to parse the following date: "2009-12-06"

```{r parsing-a-vector-5, exercise = TRUE}

```

```{r parsing-a-vector-5-hint-1, eval = FALSE}
parse_date("...")
```

### 

This function is very strict about it's format, there are other functions such as `format_iso_8601` and `parse_datetime` which can parse date and time.

### Exercise 6

Let's have some practice with `parse_datetime`. It requires a format where the components of a date are organized from biggest to smallest: year, month, day, hour, minute, second.

### 

Use `parse_datetime()` with the argument "2010-10-01T2010".

```{r parsing-a-vector-6, exercise = TRUE}

```

```{r parsing-a-vector-6-hint-1, eval = FALSE}
parse_datetime("2010-10-01T2010")
```

### 

The user can also specify which number is the month, day and year by using the `%` symbol which allows more flexibility. Type "?parse_datetime" in the console to see examples.

## Parsing a file 

### 

<!-- DK: The below is wrong! readr 2.0.0 does much better on this. Delete this example? Rework it? DONE -->

<!-- This entire section doesn't work anymore. There are hundreds of parsing failures and the exercises don't do anything to fix them. Please rework it to work with readr 2.0.0 DONE -->

A lot of the things that **readr** does is done automatically, without us inputting any extra information. All we need to do is type in `read_csv()` and it'll do most of the work for us.

However, **readr** can still mess up, which means that we have to fix the problems manually.

<!-- AG: I'm commenting the section about parsing failures out because readr is better now so you really can't rework it. This entire section is kind of unnecessary due to the fact that we did most of this in the Read CSV section, but I'd like some feedback before removing it entirely. -->

<!-- ### Exercise 1 -->

<!-- Sometimes the defaults **reader** generates don’t always work for larger files. Run `read_csv("data/ex_1.csv")` and examine the parsing failures. -->

<!-- AG: Somebody screwed up the file! ex_1.csv has 1000 rows of NA values, which makes it look like there was a parsing issue when there really wasn't. I'm not sure exactly why this is and this section is deleted anyways. -->

<!-- ```{r parsing-a-file-1-setup} -->
<!-- cat(readLines("data/ex_1.csv"), sep = "\n") -->
<!-- ``` -->

<!-- ```{r parsing-a-file-1, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r parsing-a-file-1-hint-1, eval = FALSE} -->
<!-- read_csv("data/ex_1.csv") -->
<!-- ``` -->

<!-- Note the two printed outputs: the column specification generated by looking at the first 1000 rows, and the first five parsing failures.  -->

<!-- ###  -->

<!-- You can use the `problems` function to examine the problems more in depth by piping the `read_csv`. -->

<!-- ### Exercise 2 -->

<!-- If we look at the last few rows, you’ll see that they’re dates stored in a character vector. Pipe the results with `tail()`. -->

<!-- ```{r parsing-a-file-2-setup} -->
<!-- cat(readLines("data/ex_1.csv"), sep = "\n") -->
<!-- ``` -->

<!-- ```{r parsing-a-file-2, exercise = TRUE} -->

<!-- ``` -->

<!-- <button onclick = "transfer_code(this)">Copy previous code</button> -->

<!-- ```{r parsing-a-file-2-hint-1, eval = FALSE} -->
<!-- ... %>%  -->
<!--  tail() -->
<!-- ``` -->

<!-- ###  -->

<!-- The opposite of `tail` is the `head` function, which returns first few elements.  -->

<!-- ### Exercise 3 -->

<!-- ```{r parsing-a-file-3-setup} -->
<!-- cat(readLines("data/ex_1.csv"), sep = "\n") -->
<!-- ``` -->

<!-- To fix the call, use the `col_types` argument and copy/paste the column specification into your original call.  -->

<!-- ```{r parsing-a-file-3, exercise = TRUE} -->

<!-- ``` -->

<!-- <button onclick = "transfer_code(this)">Copy previous code</button> -->

<!-- ```{r parsing-a-file-3-hint-1, eval = FALSE} -->
<!-- read_csv("data/ex_1.csv",  -->
<!--   col_types = cols( -->
<!--     x = col_double(), -->
<!--     y = col_logical() -->
<!--   ) -->
<!-- ) -->
<!-- ``` -->

<!-- ### Exercise 4 -->

<!-- ```{r parsing-a-file-4-setup} -->
<!-- cat(readLines("data/ex_1.csv"), sep = "\n") -->
<!-- ``` -->

<!-- Let's now fix the type of the `y` column by specifying that `y` is a date column. -->

<!-- ```{r parsing-a-file-4, exercise = TRUE} -->

<!-- ``` -->

<!-- <button onclick = "transfer_code(this)">Copy previous code</button> -->

<!-- ```{r parsing-a-file-4-hint-1, eval = FALSE} -->
<!-- read_csv("data/ex_1.csv",  -->
<!--   col_types = cols( -->
<!--     x = col_double(), -->
<!--     y = col_date() -->
<!--   ) -->
<!-- ) -->
<!-- ``` -->

<!-- ###  -->

<!-- With this last file, we used the `col_types` argument to `read_csv()` to resolve the failures. However, we will now explore a different approach using different parsing functions we learned in the "Parsing a vector" section. -->

### Exercise 1

```{r parsing-a-file-1-setup}
cat(readLines("data/ex_2.csv"), sep = "\n")
```

For example, there could be problems with how the column types are detected. 

Let's explore the `ex_2.csv` file and fix the parsing failures it causes.  

### 

Read the `data/ex_2.csv` file into R to check if there are any parsing mistakes.

```{r parsing-a-file-1, exercise = TRUE}

```

```{r parsing-a-file-1-hint-1, eval = FALSE}
read_csv("data/ex_2.csv")
```

### 

Notice that R parses column `a` and `b` both as a doubles. However, column `a` should be parsed as an integer and column `b` should be parsed as a date.

### Exercise 2

```{r parsing-a-file-2-setup}
cat(readLines("data/ex_2.csv"), sep = "\n")
```

Begin by using `read_csv()` to read in the file `ex_2.csv`. Then, set the `col_types` argument to `cols()`. Within `cols()`, set `.default` to `col_character()`.

```{r parsing-a-file-2, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r parsing-a-file-2-hint-1, eval = FALSE}
read_csv(..., 
         col_types = cols(.default = ...)
)
```

### Exercise 3

```{r parsing-a-file-3-setup}
cat(readLines("data/ex_2.csv"), sep = "\n")
```

Pipe the results of `read_csv()` to the function `mutate()`. Within `mutate()` set `a` to `parse_integer(a)`. 

```{r parsing-a-file-3, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r parsing-a-file-3-hint-1, eval = FALSE}
... %>% 
    mutate(a = ...)
```

### 

You can also use `parse_number` to parse integers, not just `parse_integer`.

### Exercise 4

```{r parsing-a-file-4-setup}
cat(readLines("data/ex_2.csv"), sep = "\n")
```

Continue your pipe with `mutate()`. Use `parse_date()` to transform `b` to dates. The first argument to `parse_date()` should be `b`. The second argument should be `format`. Set `format` to `"%Y%M%D"`.

```{r parsing-a-file-4, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r parsing-a-file-4-hint-1, eval = FALSE}
... %>% 
  mutate(b = parse_date(b, format="..."))
```

### 

`"%Y%M%D"` tells R to read the number as a date (Y for year, M for month, D for date). 

### Exercise 5

```{r parsing-a-file-5-setup}
cat(readLines("data/ex_3.csv"), sep = "\n")
```

Let's explore one last file `ex_3.csv` that has parsing failures. Run `read_csv("data/ex_3.csv")` and examine the parsing failures.

```{r parsing-a-file-5, exercise = TRUE}

```

```{r parsing-a-file-5-hint-1, eval = FALSE}
read_csv("data/ex_3.csv")
```

### 

What are the problems here? First, R parses column `x` as a character, when it is clearly a date. Also, column `z` should be parsed as an integer not a character!

### Exercise 6

```{r parsing-a-file-6-setup}
cat(readLines("data/ex_3.csv"), sep = "\n")
```

Let's first fix column `x`. Pipe the results of `read_csv("data/ex_3.csv)` to the function `mutate()`. Within `mutate()` set `x` to `parse_date(x, "%d %B %Y")`.  

```{r parsing-a-file-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r parsing-a-file-6-hint-1, eval = FALSE}
... %>% 
    mutate(x = ...)
```

### 

The `%d` signifies that there's only 1 digit for the day, the `%B` means that we're using the name of the month rather than the number, and the spaces in between represent the spaces in between each value. By customizing our format string, we can easily parse any format of dates without any problems.

Also note that we did not need to use the `.default = col_character()` trick before we used `mutate()`. Why? Because R already read all of the columns as characters to begin with.

### Exercise 7

```{r parsing-a-file-7-setup}
cat(readLines("data/ex_3.csv"), sep = "\n")
```

Continue your pipe with `mutate()`. Within `mutate()` set `z` to `parse_integer(z)`. 

```{r parsing-a-file-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r parsing-a-file-7-hint-1, eval = FALSE}
... %>% 
    mutate(z = ...)
```

```{r download-answers, child = "../../child_documents/download_answers.Rmd"}
```
