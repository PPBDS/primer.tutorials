---
title: Sampling
author: David Kane and Anish Talla
tutorial:
  id: sampling
output:
  learnr::tutorial:
    progressive: yes
    allow_skip:: yes
runtime: shiny_prerendered
description: 'Chapter 3 Tutorial: Sampling'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(tidyverse)
library(gt)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

# Key Data

set.seed(10)
urn <- tibble(color = c(rep("red", 400), rep("white", 600))) |>
  sample_frac() |> 
  mutate(bead_ID = 1:1000) 

virtual_samples <- tibble(trial_ID = 1:1000) |> 
  mutate(shovel = map(trial_ID, ~ sample_n(urn, size = 50))) |> 
  mutate(numb_red = map_int(shovel, ~ sum(.$color == "red"))) |> 
  mutate(numb_beads = map_int(shovel, ~ length(.$color))) |> 
  mutate(prop_red = numb_red / numb_beads)

shovels_100 <- expand_grid(trial_ID = 1:100, shovel_size = 1:100) |> 
  mutate(shovel = map(shovel_size, ~ slice_sample(urn, n = .))) |> 
  mutate(numb_red = map_int(shovel, ~ sum(.$color == "red"))) |> 
  mutate(prop_red = numb_red / shovel_size) |> 
  summarize(st_dev_p_hat = sd(prop_red),
            .by = shovel_size)
```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```


<!-- DK: Not sure what to do with the Sampling Distribution and Standard error sections. Leave them alone for now. -->

<!-- Then add in a full copy of the template tutorial. Imagine that you are betting your friend about how many beads of which color will come out of the urn when you use a shovel of a certain size.  trying to estimate . . . And so on. -->

<!-- DK: There is a conflict in that the chapter does 1,000 replications when examining the results for 100 shovel sizes while we only do 100 replications here, because otherwise the code takes too long to run. Revisit this. -->

## Introduction
### 

This tutorial supports [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

The world confronts us. Make decisions we must.

We will learn about *sampling*, the beginning of our journey toward inference. When we sample, we take some *units* from a population. With the data collected via sampling, we will create statistical models with just one unknown parameter. With such models, we can make inferences in order to answer questions. Along that journey, we learn to use the **Cardinal Virtues** to guide our actions. 


## Sampling distribution
### 

In [Chapter 3: Sampling](https://ppbds.github.io/primer/sampling.html) of the *Primer*, we described a tactile sampling activity. We used a physical urn of beads and a physical shovel. We did this by hand so that we could develop our intuition about the ideas behind sampling. In this section, we mimic this physical sampling with virtual sampling, using a computer.

### 

We begin this chapter with a specific problem: 

> Given an urn consists of 1,000 identically sized red and white beads in the urn, mixed well together. What proportion, $p$, of this urn's beads are red?

In this section, we will create the following plot to answer this question.

```{r}
plot_vs <- virtual_samples |> 
  ggplot(aes(x = prop_red)) +
    geom_histogram(binwidth = 0.02, 
                   boundary = 0.4, 
                   color = "white") +
    labs(x = expression(hat(p)), 
         y = "Count",
         title = "Distribution of 1,000 proportions red") 

plot_vs
```

### Exercise 1

Define the **population** in this problem.

```{r sampling-distribution-1}
question_text(NULL,
	message = "In our sampling activities, the population is the collection 1,000 identically sized red and white beads in the urn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The urn is basically a container where we put all the beads in. We will be using the two terms "urn" and "population" interchangeably because they both mean the same thing in this example.

### Exercise 2

Just by counting each bead in the urn, explain how we can answer the question we have.

```{r sampling-distribution-2}
question_text(NULL,
	message = "We can answer our question by counting the number of red beads out of the total 1,000 beads in the urn and then computing the proportion of red beads.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We refer to this method as a census which, assuming zero error when counting, will return the **exact** portion of red beads in the urn. However, it can be quite expensive in terms of time, energy and money, or even impossible when the population is large. 

### Exercise 3

In your own words, describe the act of **sampling** and how it relates to our activity with the beads. 

<!-- DK: Bad question! -->


```{r sampling-distribution-3}
question_text(NULL,
	message = "Sampling is the act of collecting a sample from the population. In our sampling activity, we use the shovels to collect a certain number of beads from the urn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

What if we did not insert a shovel deep enough that only beads in the surface were collected, or what if the white beads are slightly smoother than the red beads that they just kept falling out of the shovel, or what if someone put in some beads before we take another shovel? Similar problems like these will affect the quality of our sample, which will be discussed shortly. 

### Exercise 4

In your own words, define what is necessary for a sample to be **representative** in our sampling activity?

```{r sampling-distribution-4}
question_text(NULL,
	message = 'Within a sample, the proportion of the red and white beads need to look "roughly" like the distribution inside the urn.',
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Consider the case in which we insert the shovel on the surface of the urn and take out a sample of beads that contains 40 red beads and only 10 white beds, can we say that the sample of red and white beads is representative of the beads in the urn? The answer is no. 

<!-- AC: It might be better to go even more extreme to like 45 or 50 red beads. 
But also I think that it may be better to include some info on what might be in the urn (as currently we are only assuming that the distribution is the same as the urn in the Primer) -->

### Exercise 5

In your own words, define what is necessary for a sample to be **generalizable** in our activity? 

<!-- DK: Bad question! -->

<!-- AC: I changed it to be more specific to our activity. Uhm, please change it back if y'all think this doesn't work.  -->

```{r sampling-distribution-5}
question_text(NULL,
	message = "The sample is generalizable if any results based on the sample of 50 beads can generalize to the broader population of 1,000 beads in the urn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We take a sample and compute the proportion of red beads, which is our guess of the proportion of red beads within the urn. This question considers whether the proportion we just computed from the sample is a "good guess". 

### Exercise 6

In your own words, define **biased sampling** and how it might apply to our activity.

```{r sampling-distribution-6}
question_text(NULL,
	message = "Our sampling activity is biased if certain beads in the urn are more likely to get in the shovel, or in other words, if every bead in the urn does not get a fair chance of being selected.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We can tell that our guess is a good guess by sampling several times and noticing how the results vary slightly around our estimate. Sadly, multiple biased samplings can also give us the same pattern, but obviously, this result is incorrect. 

### Exercise 7

<!-- AC: It might be good to merge this with the previous exercise -->

Provide one example for this problem where the sampling could be **biased**.

```{r sampling-distribution-7}
question_text(NULL,
	message = "Had the red beads been much smaller than the white beads, and therefore more prone to falling out of the shovel, our sample would have been biased.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Note that all of the above discussion refers back to our sampling activity and the way we do it. Such small changes in this process can cause lots of changes in the outcome.

### Exercise 8

In your own words, define when a sampling procedure is *random* in this specific problem. 

```{r sampling-distribution-8}
question_text(NULL,
	message = "The sampling procedure is random if we sample randomly from the population in an unbiased fashion. In our sampling activity, this would correspond to sufficiently mixing the urn before each use of the shovel and assuring that the red and white beads are identitical save for their differing colours.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

How can we tell if the urn is "sufficiently mixed"? Can we ensure that the urn is sufficiently mixed in the same way each round? The answer is no and thus we can never fully assume randomness in our sampling. 

### Exercise 9

<!-- AC: It may be good to call urn at the end so that we can see the tibble develop over the exercises (or assign it to `urn` after everything's done) -->

Create a `urn` variable on the second line that is set to a `tibble()`. Within the `tibble()` set `color` to the combination of `rep("red", 400)` and `rep("white", 600)`.

```{r sampling-distribution-9, exercise = TRUE}
set.seed(10)

```

```{r sampling-distribution-9-hint-1, eval = FALSE}
set.seed(10)
urn <- tibble(... = c(rep("...", ...), 
                        rep("...", ...)))
```

```{r sampling-distribution-9-test, include = FALSE}
set.seed(10)
urn <- tibble(color = c(rep("red", 400), 
                        rep("white", 600)))
```

### 

`set.seed()` ensures that the beads in our virtual urn are always in the same order. This ensures that the figures in the book match their written descriptions. We want 40% of the beads to be red. The `rep()` function will repeat the first argument a number of times specified by the second argument. We then combine our 400 red beads and 600 white beads using `c()`.

### Exercise 10

With the `urn` variable start a pipe into `sample_frac()`.

```{r sampling-distribution-10, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r sampling-distribution-10-hint-1, eval = FALSE}
urn <- ... |>
          sample_frac()
```

```{r sampling-distribution-10-test, include = FALSE}
urn <- tibble(color = c(rep("red", 400), 
                        rep("white", 600))) |> 
  sample_frac()
```

### 

`sample_frac()` keeps all the rows in the tibble but rearranges their order. We don't need to do this. A virtual urn does not care about the order of the beads. But we find it aesthetically pleasing to mix them up.

### Exercise 11

Finish the pipe with `mutate()` and set `bead_ID` to 1 through 1000.

```{r sampling-distribution-11, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r sampling-distribution-11-hint-1, eval = FALSE}
urn <- ... |>
          mutate(... = 1:1000)
```

```{r sampling-distribution-11-test, include = FALSE}
urn <- tibble(color = c(rep("red", 400), 
                        rep("white", 600))) |> 
  sample_frac() |> 
  mutate(bead_ID = 1:1000)
```

### 

The first variable `bead_ID` is used as an identification variable. None of the beads in the actual urn are marked with numbers. The second variable `color` indicates whether a particular virtual bead is red or white.

### Exercise 12

Run the command `slice_sample()` with the first argument is `urn` and the second argument is `n = 1`. Hit "Run Code"

```{r sampling-distribution-12, exercise = TRUE}

```

```{r sampling-distribution-12-hint-1, eval = FALSE}
slice_sample(..., ... = 1)
```

```{r sampling-distribution-12-test, include = FALSE}
slice_sample(urn, n = 1)
```

### 

The `slice_sample()` function is like the shovel in real sampling in which it goes into the `urn` and takes out a desired number of samples. In this case, as we set `n` equals to 1, the output creates a 1x1 tibble.

### Exercise 13

Run the above command again, but this time change `n` to `10`. Hit "Run Code"

```{r sampling-distribution-13, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r sampling-distribution-13-hint-1, eval = FALSE}
slice_sample(..., ... = 10)
```

```{r sampling-distribution-13-test, include = FALSE}
slice_sample(urn, n = 1)
```

### 

Setting `n` equal 10 means that we want to take a sample of 10 beads from the `urn` and thus it will return a 10x1 tibble. Note that each time we run this command, we always get a different tibble, this is exactly similar to inserting the shovel into the real urn to take out samples several times.

### Exercise 14

To simulate the process of real-world sampling, let’s take a sample of 50 beads from our virtual urn. To do so, create a `tibble()` that has one variable `trial_ID` that takes on the values 1 to 1000.

```{r sampling-distribution-14, exercise = TRUE}

```

```{r sampling-distribution-14-hint-1, eval = FALSE}
tibble(trial_ID = ...)
```

```{r sampling-distribution-14-test, include = FALSE}
tibble(trial_ID = 1:1000)
```

### 

By this we are actually creating 1,000 virtual urns that we can take the sample from. For each urn, we sampling to get 50 beads and calculate the proportion of red beads per each sample. Note that if we conduct 10,000 trials as in [Chapter 3](https://ppbds.github.io/primer/sampling.html#courage), we will notice some extreme values (can be much higher or lower) of the proportion of red beads. 


### Exercise 15

<!-- DK: Split into 2 or 3 questions. Before creating the tibble, have a question which does slice_sample(urn, n = 1). And then one which does slice_sample(urn, n = 10).  Highlight that slice_sample(urn, n = 10) returns a shovel. DONE-->

Now pipe your results to the function `mutate()` to create the variable `shovel`, which is set to the function `map()`. The first argument to `map()` is `trial_ID`. The second argument is `slice_sample(urn, n = 50)`

```{r sampling-distribution-15, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r sampling-distribution-15-hint-1, eval = FALSE}
... |> 
  mutate(shovel = map(..., ~ ...))
```

```{r sampling-distribution-15-test, include = FALSE}
tibble(trial_ID = 1:1000) |> 
  mutate(shovel = map(trial_ID, ~ slice_sample(urn, n = 50)))
```

### 

The `slice_sample()` helps us take a sample of 50 beads from the urn, we then use the `map()` function to map that result to each virtual urn we created.

### Exercise 16

Continue your pipe with `mutate()` to create the variable `numb_red`. Set `numb_red` to the function `map_int()`. The first argument to `map_int()` should be `shovel`. The second argument should take the `sum()` of where `.$color` is equal to `"red"`.


```{r sampling-distribution-16, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r sampling-distribution-16-hint-1, eval = FALSE}
... |> 
  mutate(... = map_int(..., ~...))
```

```{r sampling-distribution-16-hint-2, eval = FALSE}
... |> 
  mutate(... = map_int(..., ~ sum(.$color == "red")))
```

```{r sampling-distribution-16-test, include = FALSE}
tibble(trial_ID = 1:1000) |> 
  mutate(shovel = map(trial_ID, ~ slice_sample(urn, n = 50))) |> 
  mutate(numb_red = map_int(shovel, ~sum(.$color == "red")))
```

### 

R evaluates if `color == "red"`, and treats `TRUE` values like the number `1` and `FALSE` values like the number `0`. So summing the number of `TRUE`s and `FALSE`s is equivalent to summing `1`’s and `0`’s. In the end, this operation counts the number of beads where `color` equals `“red”`.

### Exercise 17

Use `mutate()` one last time to create the variable `prop_red`. Set `prop_red` to `numb_red` divided by the sample size (in this exercise we are using a set sample size of 50).

```{r sampling-distribution-17, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r sampling-distribution-17-hint-1, eval = FALSE}
... |> 
   mutate(prop_red = ... / ...)
```

```{r sampling-distribution-17-test, include = FALSE}
tibble(trial_ID = 1:1000) |> 
  mutate(shovel = map(trial_ID, ~ slice_sample(urn, n = 50))) |> 
  mutate(numb_red = map_int(shovel, ~sum(.$color == "red"))) |> 
  mutate(prop_red = numb_red / 50)
```

### 

`prop_red` estimates our proportion of red beads in the urn. We will have 1,000 proportions of red beads, which we refer to as a sampling distribution.

### Exercise 18

Behind the scenes, we have assigned the results of that pipe to a new object: `virtual_samples`. Type `virtual_samples` and hit "Run Code."

```{r sampling-distribution-18, exercise = TRUE}

```

```{r sampling-distribution-18-hint-1, eval = FALSE}
virtual_samples
```

```{r sampling-distribution-18-test, include = FALSE}
virtual_samples
```

### 

Recall the difference between taking 1,000 trials versus 10,000 trials, as the number of trials increases, the sample mean will tend to get closer to the population mean, but it also makes room for the occurrence of rare and extreme values.

### Exercise 19

Now start a pipe with `virtual_samples`. Use `ggplot()` to map `prop_red` to the x-axis.

```{r sampling-distribution-19, exercise = TRUE}

```

```{r sampling-distribution-19-hint-1, eval = FALSE}
virtual_samples |> 
  ggplot(aes(...))
```

```{r sampling-distribution-19-test, include = FALSE}
virtual_samples |> 
  ggplot(aes(x = prop_red))
```

### Exercise 20

Add the layer `geom_histogram()` to create a histogram of our data.

```{r sampling-distribution-20, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r sampling-distribution-20-hint-1, eval = FALSE}
... +
  geom_histogram()
```

```{r sampling-distribution-20-test, include = FALSE}
virtual_samples |> 
  ggplot(aes(x = prop_red)) + 
  geom_histogram()
```

### Exercise 21

Within `geom_histrogram()` set `binwidth` to .02, `boundary` to .4, and `color` to "white".

```{r sampling-distribution-21, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r sampling-distribution-21-hint-1, eval = FALSE}
... +
  geom_histrogram(binwidth = ..., boundary = ..., color = ...)
```

```{r sampling-distribution-21-test, include = FALSE}
virtual_samples |> 
ggplot(aes(x = prop_red)) +
  geom_histogram(binwidth = 0.02, 
                 boundary = 0.4, 
                 color = "white")
```

### 

Recall that `p` is equal to the proportion of beads which are red in each sample.

### Exercise 22

To finish, use `labs()` to give your graph the appropriate title and axis labels. See **hint** for guidance to create the symbol $\hat{p}$.

```{r sampling-distribution-22, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

Reminder: This is what your plot should look like. 

<!-- DK: The x-axis label does not have the proper $\hat{p}$, or so it seems -->

<!-- AC: The best I can get is "\U0070\U0302" or "\U03C1\U0302", please take a look and see if it works -->

```{r}
plot_vs
```

```{r sampling-distribution-22-hint-1, eval = FALSE}
Within labs(), set x to expression(hat(p))
```

```{r sampling-distribution-22-test, include = FALSE}
virtual_samples |> 
ggplot(aes(x = prop_red)) +
  geom_histogram(binwidth = 0.01, 
                 boundary = 0.4, 
                 color = "white") +
  labs(x = expression(hat(p)),
       y = "Count",
       title = "Distribution of 1,000 proportions red") 
```

### 

This visualization allows us to see how our results differed between our tactile and virtual urn results. As we can see, there is some variation between our results. This is not a cause for concern, as there is always expected sampling variation between results.


## Standard error
### 

<!-- MT: add questions about the definitions/important concepts of standard error -->

Standard errors (SE) quantify the effect of sampling variation on our estimates. In other words, they quantify how much we can expect the calculated proportions of a shovel’s beads that are red to vary from one sample to another sample to another sample, and so on. As a general rule, as sample size increases, the standard error decreases.

### 

In this section, we will create the following plot that displays different standard deviations of red bead proportions for 100 different shovel sizes.

```{r}
shovel_p <- shovels_100 |>
 ggplot(aes(x = shovel_size, y = st_dev_p_hat)) +
 geom_point() +
 labs(title = "Sampling Variation",
      subtitle = "Larger samples have less variation",
      x = "Shovel size",
      y = "Standard deviation of the proportion red")

shovel_p
```

### Exercise 1

In your own words, define *standard error*.


```{r standard-error-1}
question_text(NULL,
	message = "The standard error is the standard deviation of a sample statistic (aka point estimate), such as the proportion.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The standard error equals the standard deviation of the data divided by the square root of the sample size. Accordingly, the standard error is inversely proportional to the square root of the sample size. The larger the sample size, the smaller the standard error.

### Exercise 2

<!-- AC: In both the example graph and the graph we'll make, we only do 100 trials, not 1000 -->

Run `expand_grid()` with two arguments. The first argument is `trial_ID = c(1:100)`. The second argument is `shovel_size = c(1:100)`. We need a hundred trials to draw reasonable conclusions about what happens when the size of the shovel varies between 1 and 100.


```{r standard-error-2, exercise = TRUE}

```

```{r standard-error-2-hint-1, eval = FALSE}
expand_grid(trial_ID = ..., shovel_size = ...)
```

```{r standard-error-2-test, include = FALSE}
expand_grid(trial_ID = c(1:100), 
            shovel_size = c(1:100))
```

### 

The resulting tibble has 10,000 rows because 100 trials times 100 shovel sizes equals 10,000. In other words, for each shovel size, we will perform 100 simulations.

### Exercise 3

Continue the pipe with `mutate()`, creating a new column called `shovel`. Set `shovel` equal to a `map()` function, passing in `shovel_size` as the first argument, and the `slice_sample()` function as the second argument. Within `slice_sample()`, the first argument should be `urn` (the data we want to sample from), and then set `n` equal to `.` (we want to pass in the `shovel_size` using `map()`). Don't forget the `~`.


```{r standard-error-3, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r standard-error-3-hint-1, eval = FALSE}
... |>
  mutate(shovel = map(..., ~ ... ))
```

```{r standard-error-3-hint-2, eval = FALSE}
... |>
  mutate(shovel = map(... , ~ slice_sample(..., n = ...)))
```

```{r standard-error-3-test, include = FALSE}
expand_grid(trial_ID = c(1:100), 
            shovel_size = c(1:100)) |> 
  mutate(shovel = map(shovel_size, ~ slice_sample(urn, n = .)))
```

### 

In the second line, we use `shovel_size` rather than `trial_ID` as the mapping variable since we can no longer hard code the shovel size into the call to `slice_sample()`.

### Exercise 4

Continue your pipe with `mutate()` to create the variable `numb_red`, which will tells us the number of red beads present. Set `numb_red` to the function `map_int()`. The first argument to `map_int()` should be `shovel`. The second argument should take the `sum()` of where the column `color` of `shovel` is equal to red.


```{r standard-error-4, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r standard-error-4-hint-1, eval = FALSE}
... |> 
  mutate(... = map_int(..., ~ ...))
```

```{r standard-error-4-hint-2, eval = FALSE}
... |> 
  mutate(... = map_int(..., ~ sum(.$color == "red")))
```

```{r standard-error-4-test, include = FALSE}
expand_grid(trial_ID = c(1:100),  
            shovel_size = c(1:100)) |> 
  mutate(shovel = map(shovel_size, ~ slice_sample(urn, n = .))) |> 
  mutate(numb_red = map_int(shovel, ~ sum(.$color == "red")))
```

### 

The purpose of setting the `shovel_size` from 1 to 100 is that we want to illustrate the relationship between the sample size and the sample variation. Specifically, as the sample size increases, the sample-to-sample variation decreases, and our guesses at the true proportion of the urn’s beads that are red get more precise. 

### Exercise 5

Continue your pipe from above, using `mutate()` to create one final column called `prop_red` which represents the proportion of red beads in a sample. Set `prop_red` to `numb_red` divided by the `shovel_size` column. 

```{r standard-error-5, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r standard-error-5-hint-1, eval = FALSE}
... |>
  mutate(prop_red = ... / ...)
```

```{r standard-error-5-test, include = FALSE}
expand_grid(trial_ID = c(1:100), 
            shovel_size = c(1:100)) |> 
  mutate(shovel = map(shovel_size, ~ slice_sample(urn, n = .))) |> 
  mutate(numb_red = map_int(shovel, ~ sum(.$color == "red"))) |> 
  mutate(prop_red = numb_red / shovel_size)
```

### 

Why does variation decrease as sample size increases? If we use a large sample size like 100 or 500, our sample is much more representative of the population. As a result, the proportion red in our sample ($\hat{p}$) will be closer to the true population proportion ($p$).

### Exercise 6

Continue the pipe with `summarize()` to create a new column named `st_dev_p_hat` which is equal to the standard deviation of `prop_red`. (`sd()` calculates standard deviation). The second argument is `.by` equal `shovel_size` to group the `st_dev_p_hat` based on the shovel size. 
 
```{r standard-error-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r standard-error-6-hint-1, eval = FALSE}
... |> 
  summarize(st_dev_p_hat = sd(...))
```

```{r standard-error-6-test, include = FALSE}
expand_grid(trial_ID = c(1:100), 
            shovel_size = c(1:100)) |> 
  mutate(shovel = map(shovel_size, ~ slice_sample(urn, n = .))) |> 
  mutate(numb_red = map_int(shovel, ~ sum(.$color == "red"))) |> 
  mutate(prop_red = numb_red / shovel_size) |> 
  summarize(st_dev_p_hat = sd(prop_red),
            .by = shovel_size)
```


### 

<!-- DK: After you have finished a pipe which creates X, the knowledge drop should give an overview of what X is and why we care. Also, the next question should be "Behind the scenes, we have assigned the result of the pipe to `cool-object`. Type `cool-object` and hit "Run Code." -->
<!-- I think it's better to keep the same name as `shovels_100` not only because we dont have to change every exercise that use the `shovels_100` but also the `shovels_100` makes more sense than the random name `cool-object`. -->

This will return a tibble with 2 columns, `shovel_size` and `st_dev_p_hat`, with 100 rows associated to 100 shovel sizes. By looking at the output we can tell that as the shovel size increases, the standard deviation decreases.

### Exercise 7

Behind the scenes, we have assigned the result of the pipe to `shovels_100`. Type `shovels_100` and hit "Run Code."

```{r standard-error-7, exercise = TRUE}

```

```{r standard-error-7-hint-1, eval = FALSE}
shovels_100
```

```{r standard-error-7-test, include = FALSE}
shovels_100 
```

### 

The Central Limit Theorem states, more or less, that when sample means are based on larger and larger sample sizes, the sampling distribution of these sample means becomes both narrower and more bell-shaped. In other words, the sampling distribution increasingly follows a normal distribution and the variation of this sampling distribution gets smaller, meaning smaller standard errors. 

### Exercise 8

Start a new pipe from `shovels_100`. Use `ggplot()`to map `shovel_size` to the x-axis and `st_dev_p_hat` to the y axis. Also, add the layer `geom_point()` to create a scatterplot.

```{r standard-error-8, exercise = TRUE}

```

```{r standard-error-8-hint-1, eval = FALSE}
shovels_100 |> 
  ggplot(aes(x = ..., y = ...)) + 
  geom_point()
```

```{r standard-error-8-test, include = FALSE}
shovels_100 |> 
  ggplot(aes(x = shovel_size, y = st_dev_p_hat)) + 
  geom_point()
```

### 

Each point in the graph is the shovel size and its associated standard deviation of the proportion red. Note that when the shovel size is 1, the standard deviation is highest, and the standard deviation decreases as the shovel size increases, as we saw in the output above.

### Exercise 9

Now use `labs()` to label the x-axis "Shovel size" and the y-axis 
"Standard deviation of the proportion red". You should also provide a title and subtitle.

```{r standard-error-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

Reminder: This is what your plot should look like.

```{r}
shovel_p
```

```{r standard-error-9-hint-1, eval = FALSE}
... +
   labs(title = "Sampling Variation",
      subtitle = "Larger samples have less variation",
      x = "Shovel size",
      y = "Standard deviation of the proportion red")
```

```{r standard-error-9-test, include = FALSE}
shovels_100 |> 
  ggplot(aes(x = shovel_size, y = st_dev_p_hat)) + 
  geom_point() + 
  labs(title = "Sampling Variation",
      subtitle = "Larger samples have less variation",
      x = "Shovel size",
      y = "Standard deviation of the proportion red")
```

### 

This is the power of running many analyses at once using map functions and list columns: before, we could tell that the standard deviation was decreasing as the shovel size increased, but when only looking at shovel sizes of 25, 50, and 100, it wasn’t clear how quickly it was decreasing.

### Exercise 10

In one sentence, describe the relationship between standard error and the sample size.


```{r standard-error-10}
question_text(NULL,
	message = "The standard error of an estimate decreases at the rate of the square root of the sample size.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

<!-- Need a couple of questions which highlight what we really care about:  -->

<!-- **Central lesson: Your posterior for (almost) any population parameter is normally distributed with a mean equal to the sample mean and a standard deviation equal to the standard error. And that means that your posterior has the same shape as the sampling distribution.** -->


<!-- NOTES -->

<!-- Question: There are 1,00 beads in the urn. How many are red? -->

## Summary
### 

This tutorial covered [Chapter 3: Sampling](https://ppbds.github.io/primer/sampling.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 
 

```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
