---
title: "Data API"
tutorial:
  id: "data-api"
output:
  learnr::tutorial:
      progressive: true
      allow_skip: true
runtime: shiny_prerendered
description: "Chapter 3: Working with APIs"
---

```{r setup, include = FALSE}
library(learnr)
library(primer.tutorials)
library(tidyverse)
library(httr)
library(countrycode)
library(imfr)
library(jsonlite)
library(rbison)
library(WDI)
library(plotly)
library(pageviews)
library(stringr)
library(png)
library(grid)
knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 60, 
        tutorial.storage = "local") 


response1 <- GET("https://bison.usgs.gov/")
response1.bin  <- content(response1, "raw")

response2 <- GET("https://bison.usgs.gov/doc/api.jsp")
response2.bin <- content(response2, "raw")

bison_base <- "https://bison.usgs.gov/api/search.json"

# response3 <- GET(bison_base,
#     query = list(species = "Bison bison",
#                  type = "scientific_name",
#                  count = "1"))
# 
# write_rds(response3, "inst/www/03-data-response3.rds")

response3 <- read_rds(
  system.file("www/03-data-response3.rds",
               package = "primer.tutorials"))
    
# Meso

meso_url <- "https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py/"

meso1 <- GET(url = meso_url) 

# denver_response <- GET(url = meso_url,
#     query = list(station = "DEN",
#                  data = "tmpf",
#                  year1 = "2017",
#                  month1 = "01",
#                  day1 = "01",
#                  year2 = "2019",
#                  month2 = "12",
#                  day2 = "31",
#                  tz = "America/Denver"))

# write_rds(denver_response, "inst/www/03-data-denver-response.rds")

denver_response <- read_rds(
  system.file("www/03-data-denver-response.rds",
              package = "primer.tutorials"))

### IMF Objects

# imf_raw <- imf_data(database_id = "HPDD", 
#                     indicator = "GGXWDG_GDP", 
#                     start = 2014)

# write_rds(imf_raw, file = "inst/www/03-data-imf.rds")

imf_raw <- read_rds(
  system.file("www/03-data-imf.rds", 
              package = "primer.tutorials"))

iso_codes <- codelist %>% 
  select(iso2c, country.name.en)

imf_named <- left_join(imf_raw, iso_codes, by = "iso2c")

### Wikipedia Objects

# supreme_views <- old_pageviews(project = "en.wikipedia",
#                            article = "Supreme_Court_of_the_United_States",
#                            platform = "all",
#                            user_type = "all",
#                            start = "2008012000",
#                            end = "2016012000") 
# 
# write_rds(supreme_views, file = "inst/www/03-data-supreme-views.rds")

supreme_views <- read_rds(
  system.file("www/03-data-supreme-views.rds",
              package = "primer.tutorials"))

supreme_plot <- supreme_views %>% 
  arrange(date) %>% 
  ggplot(aes(date, views, 
             text = paste("Date:", date, "\n"))) +
  geom_col() +
  scale_y_continuous(labels = scales::number_format()) +
  labs(title = "Wikipedia Supreme Court Page During Pres. Obama's Tenure",
       x = "Date", 
       y = "Views", 
       caption = "Wikimedia Traffic Data API") 

### RBison objects

# output <- bison(species = "Accipiter", type = "scientific_name", count = 500)

# write_rds(output, "inst/www/03-data-output.rds")

output <- read_rds(
  system.file("www/03-data-output.rds",
              package = "primer.tutorials"))

bison_plot <- bisonmap(input = output, geom = geom_jitter)

### Bison objects

# bison_response <- GET(url = "https://bison.usgs.gov/api/search.json",
#     query = list(species = "Accipiter",
#                  type = "scientific_name", 
#                  count = 500))

# write_rds(bison_response, "inst/www/03-data-bison-response.rds")

bison_response <- read_rds(
  system.file("www/03-data-bison-response.rds",
              package = "primer.tutorials"))

output_api <- content(bison_response, "text") %>% 
  fromJSON() 

clean_data_api <- output_api$states$data %>% 
  as_tibble() %>% 
  mutate(across(everything(), as.character)) %>% 
  mutate(names = c("total", "fips")) %>% 
  pivot_longer(cols = -names, 
               names_to = "state", 
               values_to = "values") %>% 
  pivot_wider(names_from = names, 
              values_from = values) %>% 
  mutate(total = as.numeric(total)) %>% 
  mutate(region = tolower(state)) %>% 
  select(-fips, -state)
```


<!-- Do not even mention API keys in the initial Query section. Too confusing! Instead, have the second section, called "API Keys" walk through the concept. 

This second section would show an example of using a key we provide in a call to a the API. First question, run GET without API key. Get back this failure. Sad! Then run this command with API key. Get back data. Cool! Then run `usethis::edit_r_environ()` -->

<!-- BM: unsure how to implement edit_r_environ in a useful way -->

<!-- > denver <- GET(url = meso_url) -->
<!-- > denver -->
<!-- Response [https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py/] -->
<!--   Date: 2021-05-22 14:28 -->
<!--   Status: 500 -->
<!--   Content-Type: text/plain; charset=UTF-8 -->
<!--   Size: 23 B -->

<!-- > class(denver) -->
<!-- [1] "response" -->
<!-- >  -->

## Information
###

```{r information}
quiz(caption = "",
  question_text(
    "Name:",
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL),
  question_text(
    "Email:",
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL))
```

## Interacting with Sites with `GET()`
###

In order to get data from an API, we use the **httr** package. The package is designed to imitate standard HTTP in R. Read more about HTTP [here](https://www.jmarshall.com/easy/http/).


### Exercise 1

Load the `httr` package.  

```{r httr-1, exercise = TRUE}

```

```{r httr-1-hint, eval = FALSE}
Use the library(...) command. 
```

### 

We now have access to the `httr` package. 

### Exercise 2

`GET()` is the key command in the **httr** package and is used to get information from sites. It takes a URL  and optionally a query to define the limits of the data accessed as its arguments. 

###

Use `GET()` with the `url` argument set to the homepage for USGS BISON, "https://bison.usgs.gov/". Assign the resulting object to `response1`. 

```{r httr-2, exercise = TRUE}

```

```{r httr-2-hint, eval = FALSE}
response1 <- GET(url = "https://...")
```

```{r httr-2-hint-2, eval = FALSE}
class(response1)
```

### Exercise 3

Print out and read `response1`. 

```{r httr-3, exercise = TRUE}

```

```{r httr-3-hint, eval = FALSE}
response1
```

### 

The URL which returns the response is the same one that we contacted. Status 200 mean success. The response is a html file of size 38kB.  We can see a preview of the html file we recieved below the header.

### Exercise 4

Use the function `class()` with the argument `response1`.


```{r httr-4, exercise = TRUE}

```

```{r httr-4-hint, eval = FALSE}
class(response1)
```

### 

Output from `GET()` is always of class "response".

### Exercise 5

Use the function `content()` to view the content of `response1`.

```{r httr-5, exercise = TRUE}

```

```{r httr-5-hint, eval = FALSE}
content(response1)
```

### 

You should see the beginnings of html content.

### Exercise 6

Let's save a copy of `response1` in our working directory. First run `content()` with the argument `response1` and  with the second argument `"raw"`. View this output and then assign it to an object called `response1.bin`. 

```{r httr-6, exercise = TRUE}

```

```{r httr-6-hint, eval = FALSE}
response1.bin <- content(..., "raw")
```

###

The `"raw"` argument saves the file to binary. This is the highest fidelity way to save files. 

### Exercise 7

Use the function `writeBin()` to save the binary object to a file in your present working directory called "response.html". The first argument is the name of the R object, `response1.bin`, and  the second object is the name of the new file. 

```{r httr-7, exercise = TRUE}

```

```{r httr-7-hint, eval = FALSE}
writeBin(..., "response.html")
```

###

The `html` suffix here tells our computer to treat this as an HTML file and open it with a compatible application. 

### Exercise 8

In the Tutorial interface, `writeBin()` does not actually write a file on your computer. If you want to be able to perform the following command, repeat the instructions above on your console. If not, we will provide a picture below.

###

In the Terminal, run `open response.html`. If this does not work, try to open the file in the file pane in RStudio or in your computer's file viewer. Copy and paste the line of the terminal command for your answer. If you are using the file we have provided, write "done" for your answer. 

```{r httr-8}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    options = list(nrows = 3))
```

###

This command opens the file in the default html viewer on your computer, likely your default browser. Read about USGS BISON.

Here is a picture of the site:

```{r image-1}
file <- system.file("images/bison1.png", 
                           package = "primer.tutorials")
img <- readPNG(file)
grid.raster(img)
```

Notice that in place of a URL beginning with "www", there is a file to a local path on a computer. This is the response which has been download.

### Exercise 9

On this page, we see a hyperlink named "API". We cannot click on links because we are not connected to the website on the web, but only to this page on our computer. We can make a new request to communicate with this page. 

###

If you were to copy the link address, it would return something like this "file:///Users/username/home-directory-subfolder/r-project-folder/r-project/doc/api.jsp". We should add this path at the end, `/doc/api.jsp` to the site's domain name to get to the API page. If we were looking at the html as a text file, this path would simply be: `./doc/api.jsp`. 

###

Use `GET()` to contact the link "https://bison.usgs.gov/doc/api.jsp". Save this to output to an object called `response2``.

```{r httr-9, exercise = TRUE}

```

```{r httr-9-hint, eval = FALSE}
GET(url = "https://...")
```

### 

This response is also of type html and 69.3kB. 

### Exercise 10

When navigating an API page for the first time we have two goals. First, to figure find the URL at which we can make our queries and get data. Second, to figure out what parameters we should use to make a query for the particular API. Ideally, there is a page where all of this information is conveniently documented. 

###

Assign the "raw" version of the `content()` of `response2` to an object called `response2.bin`

```{r httr-10, exercise = TRUE}

```

```{r httr-10-hint, eval = FALSE}
response2.bin <- content(..., "raw")
```

### Exercise 11

Use `writeBin` to save `response2.bin` to a file on your computer called `response.html`.

```{r httr-11, exercise = TRUE}

```

```{r httr-11-hint, eval = FALSE}
writeBin(response2.bin, "response.html")
```

###

This overwrites the last thing we saved as `response.html`

### Exercise 12

In the Tutorial interface, `writeBin()` does not actually write a file on your computer. If you want to be able to perform the following command, repeat the instructions above on your console. If not, we will provide a picture of the page below. 

###

Use the up arrow in the Terminal to access your last command, `open response.html`, and run it. Copy and paste the line of the command for this answer. If you are using the picture we have provided, write "done" for your answer. Read the first section, BISON Search. Look for both a URL at which we can request data and parameters with which we can specify our request. 

```{r httr-12}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    options = list(nrows = 3))
```

Here are pictures of the page:

```{r image-2}
file <- system.file("images/bison2.png",
                     package = "primer.tutorials")
img <- readPNG(file)
grid.raster(img)
```

```{r image-3}
file <- system.file("images/bison3.png",
                     package = "primer.tutorials")
img <- readPNG(file)
grid.raster(img)
```

### Exercise 13

On this page, we see a new url that allows us to make queries for JSON file responses: "https://bison.usgs.gov/api/search.json". Because the URL to make queries is one you will use often, assign it to an R object called `bison_base`.

```{r httr-13, exercise = TRUE}

```

```{r httr-13-hint, eval = FALSE}
bison_base <- "https://..."
```

### Exercise 14

In the BISON Search section there are also several parameters for requesting JSON files at the URL, including species, type, and count.

###

If you studied the example in detail, you should have noticed that in the url all the parameters came after a question mark that follows the base URL. The argument `query` in `GET()` essentially creates this question mark.  

###

Use `GET()` with `bison_base` as its first argument. The second argument will be `query`. Set `query` equal to a `list()` in which we will place our parameter requests. Within `list()`, set `species` equal to "Bison bison", set `type` equal to "scientific_name", and set `count` equal to "1". Run this function and assign the output to an object called `response3``.

```{r httr-14, exercise = TRUE}

```

```{r httr-14-hint, eval = FALSE}
response3 <- GET(bison_base, 
    query = list(species = "Bison bison", 
                 type = "scientific_name", 
                 count = "1"))
```

### Exercise 15

Print and read `response3`

```{r httr-15, exercise = TRUE}

```

```{r httr-15-hint, eval = FALSE}
response3
```

###

Notice that unlike our last two responses, this response comes from a different URL than the one we started from. Notice also that everything our query has added follows  a question mark. This URL matches the parameters we chose and is also a very close match to the example URL on the website. 

###

The content type is also different. It is no longer an HTML file as before, but a JSON file of 15kB. JSON is a file type which stores data. 

### Exercise 16 

Use `content()` on `response3` with the argument "text" to view the JSON as a text file. 

```{r httr-16, exercise = TRUE}

```

```{r httr-16-hint, eval = FALSE}
content(..., "text")
```

###

You should see lots of brackets, slahses and colons, the syntax of a JSON file. You should also see state and county names and numbers. These are data, and we will work on how to handle this type of data later in the tutorials. 

### Exercise 17

Go to Terminal and use the `rm` command to remove "response.html". Copy and paste the line of the command for this answer. 

```{r httr-17, exercise = TRUE}

```

## Iowa Environmental Mesonet
###

Let's make the following plot. We will use ASOS data from the Iowa Environmental Mesonet. 

```{r make-mesonet}
denver_p <- denver_response %>%
  content() %>% 
  read_csv(na = "M") %>% 
  separate(col = valid,
           into = c("date", NA),
           sep = " ") %>%
  group_by(date) %>%
  summarise(avg_temp = mean(tmpf, na.rm = TRUE),
            .groups = "drop") %>% 
  ggplot(aes(y = avg_temp,
                  x = date)) +
  geom_point() + 
  scale_x_discrete(breaks = c("2017-06-01", "2018-06-01", "2019-06-01")) +
  labs(x = NULL,
       y = "Average Temp. F*",
       title = "Daily Avg. Temperature in Denver, CO",
       caption = "Source: Iowa Environmental Mesonet")

denver_p
```

### Exercise 1

In the last exercise, you started from the homepage and had to find the URL at which you could access the API. In this exercise, we will give you the URL at which to access the API from the start. Below, we will discuss how you would navigate from the home page.

###

If you were to naviagte from the home page looking for the ASOS API, you would eventually be redirected to this link, https://mesonet.agron.iastate.edu/request/download.phtml. While this site has some useful documentation such as the variable list at the bottom, the page is designed for interactive use in a browser (hence .phtml instead of just .html)  and so is missing some important information, such as the access URL and the format for time parameters. One option would be to view the html file as a text file, where you could find the access URL and variable names which undergird the UI. 

###

Though this cannot be done using `GET()`, another way to find information on an interactive site is to make a request on your browser and then look at the resulting link. Doing so, you will see both the base link and the names for as many parameters as you selected. 

###

Assign this url, "https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py/"  to an an object named `meso_url`. 

```{r meso-1, exercise = TRUE}


```

```{r meso-1-hint-1, eval = FALSE}
The URL should be a text string when being assigned to an object. 
```

```{r meso-1-hint-2, eval = FALSE}
meso_url <- "https://..." 
```


<!-- In traditional cases, you would store your API key in the .Renviron file and use that reference to access the desired data. This is a simpler example of API use in which we don't need to protect a uniquely generated access key.  -->

You will now have access to this object, the URL for making requests to the API, throughout the rest of this exercise. 


### Exercise 2

Use `GET()` with the `url` argument set to `meso_url`. Assign the resulting object to `meso1`. In the second line, run `class()` on `meso1`.

```{r meso-2, exercise = TRUE}

```

```{r meso-2-hint, eval = FALSE}
my.response <- GET(url = ...)
```

```{r meso-2-hint-2, eval = FALSE}
class(meso1)
```

###

Note that even without a query specification, the GET command appears to run but returns no data. You get an object of `class()` "response" because you are still communicating with the url. 

### Exercise 3

Print out `meso1`. 

```{r meso-3, exercise = TRUE}

```

```{r meso-3-hint, eval = FALSE}
meso1
```

###

Note that the URL is still the base url, which indicates that there was no further query. We can confirm that by looking at the size of the response - 23 Bytes (our previous responses were in **kilo**bytes. `Status: 500` indicates that there was an error. 


### Exercise 4

Within the function `GET()`, use `meso_url` to fill the `url` argument and then set the argument `query` equal to a `list()` of parameters: `station`, `data`, `year1`.  We want to know for station Denver (`"DEN"`) the temperature in degrees Fahrenheit (`"tpmf"`) starting in the year 2017. 

```{r meso-4, exercise = TRUE}

```

```{r meso-4-hint-1, eval = FALSE}
The abbreviation for temperature in Fahrenheit is "tmpf".
```

```{r meso-4-hint-2, eval = FALSE}
GET(url = meso_url,
           query = list(station = "DEN",
                        data = "tmpf",
                        year1 = 2017))
```

This response is still of `Status: 500`, which means something is wrong. 

### 

There are several different types of data to be had from this API, including the temperature in degrees celsius, which come with different names to be used as arguments in query. See the discussion at the beginning of this section for where we would find this information on this site and others like it. 

### Exercise 5

This API requires a start and end date (Year, Month, and Day) to be supplied in order to return a request successfully. 

###

Copy and paste the code from the previous exercise. Within `GET()`, you should add parameters to include the start, `year1` `month1` `day1`, and end point of your time frame, `year2` etc. We are interested in the daily records from 01/01/2017 to 12/31/2019. You should also specify the appropriate time zone, `tz` for this station, "America/Denver". View this output and then assign it to an object named `denver_response`. 

###

Note: This command may take longer to run. 

```{r meso-5, exercise = TRUE, exercise.timelimit = 600}

```

```{r meso-5-hint-1, eval = FALSE}
All date parameters should be quoted numbers
i.e. "01" is January.
```

```{r meso-5-hint-2, eval = FALSE}
GET(url = meso_url,
    query = list(station = "DEN",
                 data = "tmpf",
                 year1 = "2017",
                 month1 = "01",
                 day1 = "01",
                 year2 = "2019",
                 month2 = "12",
                 day2 = "31",
                 tz = "America/Denver"))
```

### 

Now our response is of `Status: 200`, and much larger (7.98MB) file.  We can see a preview of the data below the header. The response is a text file and we can see that each column is separated by commas. 

### Exercise 6

Start a pipe with `denver_response`. Use the `content()` to convert `denver_response` from class response. Then, pipe `read_csv()` to convert the comma separated values in our response file into a tibble. 

```{r meso-6, exercise = TRUE}

```

```{r meso-6-hint, eval = FALSE}
GET(...) %>% 
  content() %>% 
  read_csv()
```

###

If you scroll through the tibble, you will see that there are values that are not `NA` in the `tmpf` column. We cann assume that temperature was not recorded at every 5 minute interval. 

### Exercise 7

Notice all the Ms in the data. These represent missing values. Copy and paste your code from above.  Within `read_csv()`, use the `na` argument to change all occurrences of the lone character `"M"` to `NA`. 

```{r meso-7, exercise = TRUE}

```

```{r meso-7-hint-1, eval = FALSE}
GET(url = ...,
              query = list(...,
                           format = "comma")) %>% 
  content() %>% 
  read_csv(na = "M")
```

### Exercise 8

Let's remove the timestamp from the given date variable and rename the remaining column "date". Copy and paste your code and continue your pipe with the `separate()` function. Within the function `separate()`, use the argument `col` to select which column's content you are separating, use the argument `into` to create a vector of the new column names, `"date"` and `NA`, and use the third argument, `sep` to show by what character you are separating the data `" "` (i.e. a space).  

```{r meso-8, exercise = TRUE}

```

```{r meso-8-hint, eval = FALSE}
  separate(col = valid,
           into = c("...", NA),
           sep = " ")
```

###

The NA operator drops the second column from the separation, removing the need to `select(-)` the unwanted data later. 

### Exercise 9

The date column has multiple rows for the same day. Continue your pipe and use `group_by()` and `summarize()` to calculate the daily average temperature in a new column named "avg_temp". Remember to exclude `NA` values from calculation of the mean.

```{r meso-9, exercise = TRUE}

```

```{r meso-9-hint-1, eval = FALSE}
Within the `mean()` function, set `na.rm` to TRUE 
to remove NA values from calculation. 
```

```{r meso-9-hint-2, eval = FALSE}
  ... %>% 
  group_by(date) 
  summarise(avg_temp = mean(..., na.rm = TRUE),
            .groups = "drop")
```

### Exercise 10

Continue your pipe with `ggplot()` and `geom_point()`. Create a scatterplot that maps average daily temperature to the y-axis and the date to the x-axis. 

```{r meso-10, exercise = TRUE}

```

```{r meso-10-hint, eval = FALSE}
... %>% 
  ggplot(aes(x = ..., y = ...)) +
  geom_point()
```

### Exercise 11

There are so many labels for x-axis breaks that they are indistinguishable. Use `scale_x_discrete()` to set only three x axis breaks, "2017-06-01", "2018-06-01", and "2019-06-01".

```{r meso-11, exercise = TRUE}

```

```{r meso-11-hint, eval = FALSE}
... +
  scale_x_discrete(breaks = c(...)) 
```

### Exercise 12

Use `labs()` to set an appropriate title, subtitle, caption, axes labels, and captions.

```{r meso-12, exercise = TRUE}

```

Reminder: The graph should look like this

```{r show-denver-p}
denver_p
```


## API Keys

In traditional cases, you would store your API key in the .Renviron file and use that reference to access the desired data. The previous and all the following  are examples of API use in which we don't need to use a uniquely generated access key.

###

### Exercise 1

If you have not already, request a US Census API Key here. You must include both your name and an organization. Write "Done" when you are finished. 

```{r api-1}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    options = list(nrows = 3))
```

### Exercise 2

In the Terminal, run `cat $HOME/.Renviron`. the .Renviron file makes environmental variables which are run every time R starts up and is where you store sensitive information like API Keys. Copy and paste the command and its result into the box below. 

```{r api-2}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    options = list(nrows = 3))
```

###

Most likely, you do not have one yet. In this case the Terminal will return the message "No such file or directory". If you do have one, the Terminal will print the contents of your .Renviron file, which might very well be empty. 

### Exercise 3 

<!-- DK: Combine Exercise 3 and 4. Only answer needed is the result of cat -->

In your Console (not the Terminal!), run the command `usethis::edit_r_environ()`. This is a command that opens the .Renviron file so that we can edit it. If you do not already have a .Renviron file, it will create one for you.  Copy and paste the command into the box below. 

```{r api-3}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    options = list(nrows = 3))
```

### Exercise 4

In the Terminal run `cat $HOME/.Renviron` again. Now that you have created the file, Terminal should not return "No such file or directory". The file exists, after all. It might have nothing in it. Or it might have something already. Copy and paste the command and its result into the box below. 

```{r api-4}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    options = list(nrows = 3))
```

###

If you still get the message "No such file or directory", look at the output of the `edit_r_environ()` function. On many machines, R creates the `.Renviron` in the home directory, but not on all. The output of `edit_r_environ()` contains the path for the `.Renviron` file on your computer. If this is not `/Users/your-user-name/.Renviron` then your file is not in the home directory. Copy the path in the output and run the terminal command with this path in the place of  `$HOME/.Renviron`. 

If the above applies to you, you will have to make the same replacement in Exercise 6 as well. 

###

If you had content in the .Renviron before, Terminal should return the same content as before since you have not changed it.

### Exercise 5
 
Let's add your Census API Key to `.Renviron`. Type `CENSUS_API_KEY`. This will be the name of the environmental variable. On the same line use an `=` to set the variable to a string that contains your Census API Key. If you have not received a Census API Key, leave a code comment about how you plan to instead. When you are finished, save the file and type "done" in the  box below.

```{r api-5}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    options = list(nrows = 3))
```

Your completed .Renviron file should look like this:

```{r}
file <- system.file("images/apikey.png", 
                           package = "primer.tutorials")
img <- readPNG(file)
grid.raster(img)
```


### Exercise 6

Now run `cat $HOME/.Renviron`. Terminal should return the line with your API Key and any other content you may have already had in your .Renviron file. Copy and paste the command and its result into the box below. 

```{r api-6}
question_text(NULL,
    answer(NULL, correct = TRUE),
    allow_retry = TRUE,
    try_again_button = "Edit Answer",
    incorrect = NULL,
    options = list(nrows = 3))
```

###

You must restart R for the new environent variable to be able to be used. 

###

`tidycensus` functions automatically look for this environmental variable. When using API Keys in less developed packages or with `GET()`, use the following command `sys.getenv("CENSUS_API_KEY")`. getenv = **get** **env**ironmental variable. 

###

The primary reason why we do not include API Keys in our code is security. We don't want people who look at our GitHub projects to be able to see our API Key. API Keys are unique for us and can be used for paid services in some cases. Other sensitive information, like GITHUB_PAT or a client's account number is also stored in the .Renviron. 

## The International Monetary Fund
###

Let's make the following plot with data from the International Monetary Fund API. 

```{r make-imf-plot}
imf_plot <- imf_named %>%
  rename(dtg = `GGXWDG_GDP`) %>%
  arrange(desc(dtg)) %>%
  slice(1:15) %>%
  ggplot(aes(x = dtg,  y = fct_reorder(country.name.en, dtg))) +
  geom_col() +
  labs(title = "Countries with the 15 Highest Debt to GDP Ratios in 2015",
       subtitle = "The United States of America is in 12th Place",
       x = "Debt to GDP Ratio",
       y = "",
       caption = "International Monetary Fund")

imf_plot
```

###

The **imfr** package provides helper functions for access to the API for the International Monetary Fund. Instead of navigating pages and using `GET()` to make requests, we use functions within the package.  You can learn more about the package [here](https://github.com/christophergandrud/imfr).

### Exercise 1

Load the `imfr` package. 

```{r imfr-1, exercise = TRUE}

```

```{r imfr-1-hint, eval = FALSE}
library(imfr)
```

### Exercise 2

Let's learn more about the `imfr` package. In your console, run `help(package = "imfr")`. Click and read about the function `imf_data()`, the function used to download data in this package. You can also read about the function in the Tutorial window using the `?`. Write "done" when you are finished. 

```{r imfr-2, exercise = TRUE}

```

```{r imfr-2-hint, eval = FALSE}
help(package = "imfr")
```

###

We see that `imf_data()` requires two arguments. A `database_id` which can be found with the function `imf_ids()` and a string or vector of indicator IDs which can be found in the function `imf_codes()`. 

###

If a function in a help page  has an argument that is set equal to something, this means that argument has a default which will be used if the user does set the argument to something else. Note that the default for the argument `country` is "all" and that the defualt for the argument `freq` is "A" for annual. 
 
###

At the bottom of the help page we can find example uses of the functions. There we see examples both where `indicator` is set equal to one string and to a vector of strings. 

### Exercise 3 

Use the back button at the top left corner of the help pane to navigate to the previous page. Read the page `imf_ids()` and `imf_codes()`. You can also read about the function in the Tutorial window using the `?`.

```{r imfr-3, exercise = TRUE}

```

###

Both functions return a data frame. `imf_ids()` requires no arguments, but `imf_codes()` requires a codelist argument which we can get from the function `imf_codelist()`. 

### Exercise 4

Use the back button at the top left corner of the help pane to navigate to the previous page. Read about `imf_codelist()`.

```{r imfr-4, exercise = TRUE}

```

###

`imf_codelist` also returns a data frame of codelist codes and their descriptions. It requires the argument `database_id`. 

### Exercise 5

Run the function `imf_ids()`. 

```{r imfr-5, exercise = TRUE}

```

```{r imfr-5-hint, eval = FALSE}
imf_ids()
```

###

Explore this tibble. On page three we see a row with the description "Historical Public Debt" with the code "HPDD". 

### Exercise 6

Run the function `imf_codelist()` with the argument "HPDD". 

```{r imfr-6, exercise = TRUE}

```

```{r imfr-6-hint, eval = FALSE}
imf_ids("HPDD")
```

### 

One item has the description `Indicator` which was the name for the argument in `imf_data()`.

###

On the example page we saw a function with only one code, so it is safe to assume that it is not necessary to specify codes for every item in the tibble from `imf_codelist()`.

### Exercise 7 

Run the function `imf_codes()` with the argument being the indicator in the codelist, "CL_INDICATOR_HPDD". 

```{r imfr-7, exercise = TRUE}

```

```{r imfr-7-hint, eval = FALSE}
imf_codes("CL_INDICATOR_HPDD")
```

###

There is only code, "GGXWDG_GDP", which has a description "Debt to GDP Ratio". 

### Exercise 8

Run the function `imf_data()`. Set the first argument `database_id` equal to "HPDD". Set the second argument `indicator` equal to "GGXWDG_GDP". Set start equal to 2014. Save this to an output called `imf_raw`.

```{r imfr-8, exercise = TRUE, exercise.timelimit = 600}

```

```{r imfr-8-hint, eval = FALSE}
imf_data(database_id = "HPDD", indicator = "GGXWDG_GDP", 
         start = 2014)
```

Recall in the help page that the argument `country` has a default value of "all" and that the argument `freq` has a default value of "A" for annual.  

### Exercise 9

Start a new pipe with `imf_raw`. Let's see how many years were included in this output. Arrange the tibble in descending order by `year`. 

```{r imfr-9, exercise = TRUE}

```

```{r imfr-9-hint, eval = FALSE}
imf_raw %>% 
  arrange(desc(...))
```

###

The data has a max year of 2015, even though the argument `end` is set by default to `current_year()`.

### Exercise 10

There is a package called `countrycode`. In the console, run `help(package = "countrycode")` to bring up the help page for this package. Click on the function `codelist`. Write "done" for your answer when you are finished. 

```{r imfr-10, exercise = TRUE}

```

###

We found out about the package `countrycode` by reading the help page for the function `all_iso2c` in `imfr`. 

### Exercise 11

Run `codelist`. Check to see if there is an `iso2c` column in this tibble. 

```{r imfr-11, exercise = TRUE}

```

```{r imfr-11-hint, eval = FALSE}
codelist
```

### Exercise 12

Select the columns `iso2c` and `country.name.en`. Save this to an object called `iso_codes`. 

```{r imfr-12, exercise = TRUE}

```

```{r imfr-12-hint, eval = FALSE}
iso_codes <- codelist %>% 
  select(..., ...)
```

### Exercise 13

Use `left_join()` to join `iso_codes` to `imf_raw` by the shared column "iso2c". Save this to an object named `imf_named`.   

```{r imfr-13, exercise = TRUE}

```

```{r imfr-13-hint, eval = FALSE}
imf_named <- left_join(imf_raw, iso_codes, by = "...")
```

### Exercise 14

Let's check if any countries have not been matched to a `country.name.en`. Run the command `is.na()` with the argument being the column `iso2c` as a vector.

```{r imfr-14, exercise = TRUE}

```

```{r imfr-14-hint-1, eval = FALSE}
Remember that we use the $ operator to extract a column as a vector.
```

```{r imfr-14-hint-2, eval = FALSE}
is.na(imf_named$country.name.en)
```

### Exercise 15

It is hard to see whether there are any values of `TRUE` in so large a vector. Copy and paste the previous code. Pipe the function `table()` into it. 

```{r imfr-15, exercise = TRUE}

```

```{r imfr-15-hint, eval = FALSE}
is.na(imf_named$iso2c) %>% 
  table()
```

### 

Every country was able to be matched to a value in `country.name.en` through the column `iso2c`. 

### Exercise 16

Start a new pipe with `imf_named`. Rename the column `GGXWDG_GDP` to `dtg`.

```{r imfr-16, exercise = TRUE}

```

```{r imfr-16-hint, eval = FALSE}
... %>% 
rename(... = `GGXWDG_GDP`)
```

### Exercise 17

Copy and paste the code above. Filter the data to keep rows only where year is equal to "2015". 

```{r imfr-17, exercise = TRUE}

```

```{r imfr-17-hint, eval = FALSE}
... %>% 
  filter(year == "2015")
```

### Exercise 18

Arrange the column in descending order by `dtg`. Use `slice()` to select the rows with the 15 countries with the highest debt to gdp ratios, i.e. the first fifteen rows.

```{r imfr-18, exercise = TRUE}

```

```{r imfr-18-hint, eval = FALSE}
... %>% 
  arrange(desc(dtg)) %>% 
  slice(1:15)
```

### Exercise 19 

Continue your pipe with `ggplot()`. Map `dtg` to the x-axis and `country.name.en` to the y-axis. Add the layer `geom_col()`. 

```{r imfr-19, exercise = TRUE}

```

```{r imfr-19-hint, eval = FALSE}
... %>% 
  ggplot(mapping = aes(x = ..., y = ...)) 
```

### Exercise 20

Let's reorder the order of the countries on the y axis. Within `ggplot()` set `y` equal to the function `fct_reorder()`. The first argument should be the current y-axis variable, `country.name.en`. The second argument should be the variable by which we want to order the countries, `dtg`. 

```{r imfr-20, exercise = TRUE}

```

```{r imfr-20-hint, eval = FALSE}
... +
  ggplot(mapping = aes(x = dpg, y = fct_reroder(country.name.en, dpg))) 
```

### Exercise 21

Use the layer `labs()` to add a title, subtitle, and axes labels to your plot. 

```{r imfr-21, exercise = TRUE}

```

```{r imfr-21-hint, eval = FALSE}
... +
  labs(...,
       y = ""
       ...)
```

Reminder: Your graph should look like this

```{r show-imf-plot}
imf_plot
```

## Wikipedia Page Access
###

The **pageviews** package provides helper functions for accesses the API for the World Bank. You can learn more about the package [here](https://cran.rstudio.com/web/packages/pageviews/pageviews.pdf). 


```{r supreme_setup}
final <- ggplotly(supreme_plot, tooltip = "text")

final
```

###

Note that this graph is interactive and you will use the package `plotly` to add this feature.

### Exercise 1

On the first line, load the **pageviews** package. In this package, the functions `article_pageviews()` and `old_pageviews()` allow us to communicate with the Wikimedia API. 

```{r supreme-1, exercise = TRUE}

```

```{r supreme-1-hint, eval = FALSE}
library(pageviews)
```

###

`old_pageviews()` is for counts before 2016. They are not as accurate as they did not omit the activity of web-crawlers and bots.

### Exercise 2

We will be looking at the wikipedia page views for the Supreme Court of the United States countries during President Obama's tenure, from January 20th 2008 to January 20th 2016.

###

Start a call with `old_pageviews()`. Set the `project` argument equal to `wikipedia.en` and the article to `Supreme_Court_of_the_United_States`. Set the start time and end time in the format: YYYYMMDDHH. Set hours to 00, they do not matter as the granularity is by default daily. Assign this to an object called `supreme_views`.

```{r supreme-2, exercise = TRUE}

```

```{r supreme-2-hint-1, eval = FALSE}
old_pageviews(project = "en.wikipedia",
                           article = "...",
                           start = "2008012000",
                           end = "2016012000") 
```

###

Because this is a package designed to work with this API, we do not need to use a base url. Also, the output of the function is made into a tibble by default.

### Exercise 3

Start a new pipe with `supreme_views`. Use `ggplot()` and `geom_col()` to make a bar graph with `date` on the x-axis and `views` on the y axis. 

```{r supreme-3, exercise = TRUE}

```

```{r supreme-3-hint, eval = FALSE}
supreme_views %>% 
  ggplot(aes(..., ,...)) +
  geom_col()
```

### Exercise 4

Within `ggplot(aes())` Use the `text` argument and the function `paste()` to create a label which you can use for plotly that tells the `date` of an observation.

```{r supreme4, exercise = TRUE}

```

```{r supreme-4-hint-1, eval = FALSE}
supreme_views %>% 
  arrange(date) %>% 
  ggplot(aes(date, views, 
             text = paste("...", ...))) +
  geom_col()
```

```{r supreme-4-hint-2, eval = FALSE}
supreme_views %>% 
  arrange(date) %>% 
  ggplot(aes(date, views, 
             text = paste("Date:", date))) +
  geom_col()
```

### Exercise 5

Add the layer `scale_y_continuous`. Set the argument `labels` to `scales::number_format()` to convert the y-axis from scientific notation.

```{r supreme-5, exercise = TRUE}

```

```{r supreme-5-hint-1, eval = FALSE}
supreme_views %>% 
  arrange(date) %>% 
  ggplot(aes(date, views, 
             text = paste("...", ..., "\n"))) +
  geom_col() +
  scale_y_continuous(... = scales::numer_format())
```


### Exercise 6

Use `labs()` to set an appropriate title, caption, and axes labels

```{r supreme-6, exercise = TRUE}

```

###

`plotly` does not support subtitles. 

### Exercise 7

Copy/paste your code. Assign the output of the pipe to an object called `supreme_plot`.

```{r supreme-7, exercise = TRUE}

```

### Exercise 8

Use the function `ggplotly()` to add interactive labels to supreme_plot.

```{r supreme-8, exercise = TRUE}

```

```{r supreme-8-hint-1, eval = FALSE}
ggplotly(..., tooltip = "text")
```

```{r suoreme-8-hint-2, eval = FALSE}
ggplotly(..., tooltip = "text")
```


Reminder: you plot should look like this: 

```{r show-supreme-plot}
final
```

## BISON with Package
###

Let's make the following plot with data from the USGS Bison API and the `rbison` package. This package is designed to make work with the BISON API, the site which we first accessed with HTTP, easier. 

```{r make-bison-plot}
bison_plot <- bisonmap(input = output, geom = geom_jitter)
```

###

The **rbison** package provides helper functions for access to the API for the USGS Bison API You can learn more about the package [here](https://github.com/ropensci/rbison.)

### Exercise 1

Load the `rbison` package. 

```{r rbison-1, exercise = TRUE}

```

```{r rbison-1-hint, eval = FALSE}
library(rbsion)
```

### Exercise 2

Let's learn more about the `rbison` package. In your console, run `help(package = "rbison")`. Click and read about the function `bison()`, the function used to download data in this package. Also click and read about the function `bisonmap()`. You can also use `?` to view the function help pages in the Tutorial window. When you are finished reading, write "done" for this question. 

```{r rbsion-2, exercise = TRUE}

```

```{r rbison-2-hint, eval = FALSE}
help(pacakge = "rbison")
```

###

`bison` has lots of possible arguments, but the help page has examples in which it specifies very few. 

### Exercise 3

Run `rbison`. Set the argument `species` equal to "Accipiter" and set `type` to "scientific_name". Set count to `500`. Save the output to a file named 
`output`.

```{r rbison-3, exercise = TRUE}

```

```{r rbison-3-hint, eval = FALSE}
output <- bison(species = "Accipiter", type = "...", count = ...)
```

###

`output` seems to be a complex object.

### Exercise 4

An easier way to view the structure of a complex object like `output` is to use the function `str()`. 

```{r rbison-4, exercise = TRUE}

```

```{r rbison-4-hint, eval = FALSE}
str(output)
```

###

`output` is a list of four main objects

### Exercise 5

Run `class(output)`. 

```{r rbison-5, exercise = TRUE}


```

```{r rbison-5-hint, eval = FALSE}
class(output)
```

###

This object is of class "bison", which we can assume is an object class custom for the `rbison` package. 

### Exercise 6

Run `output$counties`, according to `str()`, this should return a data frame with the columns `record_id`, `total`, `county_name`, and `state`.

```{r rbison-6, exercise = TRUE}


```

```{r rbison-6-hint, eval = FALSE}
output$counties
```

### Exercise 7

The `rbison` package comes with a function, `bisonmap()`, that helps make a `ggplot()` map with BISON data. Set the argument `input` to `output` and set the argument `geom` to `geom_jitter`. 

```{r rbison-7, exercise = TRUE}

```

```{r rbison-7-hint, eval = FALSE}
bisonmap(input = ..., geom = ...)
```

Reminder: This is what your plot should look like

```{r}
bison_plot <- bisonmap(input = output, geom = geom_jitter)
```

### Exercise 8

Copy and paste your code. Try to use labs to add a title to this `ggplot()` object. 

```{r rbison-8, exercise = TRUE}

```

```{r rbison-8-hint, eval = FALSE}
bisonmap(input = output, geom = geom_jitter) +
  labs(title = "...")
```

###

This works but for some reason separates Hawaii from the original plot. Because we do not have immediate access to the `ggplot()` code, we cannot easily see what is causing this problem. 

## Bison Data with GET()
###

Let's make the following plot. 

```{r make-bison-plot-api}
 bison_plot_api <- map_data("state") %>% 
  left_join(clean_data_api, by = "region") %>% 
  ggplot(aes(long, lat, group = group, fill = total)) +
  geom_polygon() +
  scale_fill_gradient(low = "blue", high = "red", na.value = "grey50") +
  labs(title = "Accipiter in the Contiguous United States", 
       subtitle = "Hawaii has 1, Alaska has 0", 
       x = "Longitude", 
       y = "Latitude", 
       fill = "Total",
       caption = "USGS BISON API") 

bison_plot_api
```

### Exercise 1

Run `GET()` with the URL we assigned to the object `bison_base`. Note: this may take longer.

```{r bison-1, exercise = TRUE}

```

```{r bison-1-hint, eval = FALSE}
GET(url = bison_base)
```

### 

You should get an error message. In the console, this command returns the error message: "Empty reply from server." This URL does not return a response without a query. 

### Exercise 2

Run `GET()` with the same url and with the second argument `query`. Set `query` equal to a `list()` which contains the parameters you want to use in your search, `species = "Accipiter"`, `type = "scientific_name"`, and `count = 500`. View this output and save it to an output called `bison_response`. 

```{r bison-2, exercise = TRUE}

```

```{r bison-2-hint, eval = FALSE}
bison_response <- GET(url = "https://bison.usgs.gov/api/search.json",
    query = list(species = "...",
                 type = "...", 
                 count = 500))
```

###

This response is a JSON file and 119kB in size. Notice the addition of the question mark and our query list to the url. 

### Exercise 3

Run `content()` on `bison_response`, set the second argument to "text".

```{r bison-3, exercise = TRUE}

```

```{r bison-3-hint, eval = FALSE}
content(response, "text")
```

### 

This file matches what we expect of JSON files: lots of curly brackets.

### Exercise 4

Because the content of `bison_response` is a JSON file we need to convert it before we can use it in R. Start a pipe with `content(bison_response)` and then pipe the function `fromJSON()` into it. 

```{r bison-4, exercise = TRUE}

```

```{r bison-4-hint, eval = FALSE}
content(response) %>% 
  fromJSON()
```

###

This returns an error. `content()` by default tries to read the response into its most usable form in RStudio. `fromJSON()` expects a text file. 

### Exercise 5

Start a pipe with `content(bison_response, "text")` and then pipe the function `fromJSON()` into it. View this and assign it to an output named `output_api`.

```{r bison-5, exercise = TRUE}

```

```{r bison-5-hint, eval = FALSE}
output_api <- content(response, "...") %>% 
  fromJSON()
```

###

`output_api` seems to be an even more complex R object than the `output` we got from the `rbison` package. 
 
### Exercise 6

Run `str()` on `output_api`. 

```{r bison-6, exercise = TRUE}

```

```{r bison-6-hint, eval = FALSE}
str(output_api)
```

###

`output_api` is a list of 12 main objects. Peruse these objects and their sub-organizations

### Exercise 7

Locate `output_api$states$data$Oregon` in the `str()` ouput from the previous exercise. Then run `output_api$states$data$Oregon`.

```{r bison-7, exercise = TRUE}

```

```{r bison-7-hint, eval = FALSE}
str(output_api)
```

###

This is a list of two values, the state's total (number of bison) and its county FIPS. We could observe all these details in the output of `str()`. 

### Exercise 8

Start a pipe with `output_api$states$data`. Add the function `as_tibble()`. 

```{r bison-8, exercise = TRUE}

```

```{r bison-8-hint, eval = FALSE}
str(output_api)
```

###

`output$states$data` is a list  containing 45 two-item lists of the type we just saw for Oregon for every state with Accipiter. When we make this into a tibble, each list becomes a `list` column which contains its two items. 

### Exercise 9

Because the columns are list columns, they do not display well in our tibble. We can convert these to character columns, with the functions `mutate()` and `as.character()`. 

###

To avoid having to do a mutation for each column, we can nest the `across()` function within `mutate()`. Copy/paste your code from the previous exercise. The first argument in `across` specifies the columns you want,`everything()`. The second argument specifies the function we want to use, `as.character`, in this case without arguments or parentheses.  

```{r bison-9, exercise = TRUE}

```

```{r bison-9-hint, eval = FALSE}
... %>% 
mutate(across(everything(), as.character))
```

###

We use character since the Candian FIPS values are letters. 

### Exercise 10

Use `mutate()` to create a new column called `names` whose first row contains the string "total" and whose second row contains the string "fips". 

```{r bison-10, exercise = TRUE}

```

```{r bison-10-hint, eval = FALSE}
... %>% 
mutate(across(everything(), as.character))
```

### Exercise 11

Continue your pipe. Use `pivot_longer()` to transform the data so that states are contained in rows and not columns. Set `cols` equal to `-names`. Set `names_to` equal to "states" and set `values_to` equal to "values". 

```{r bison-11, exercise = TRUE}

```

```{r bison-11-hint, eval = FALSE}
... %>% 
pivot_longer(cols = -name, 
             names_to = "...", 
             values_to = "...")
```

### 

Tidyselect functions can generally be conveniently used for  `pivot_longer()` column selection.

###

Each state now has two rows, one with the total number of accipiter in the `values` column, the other with the FIPS in the `values` column.

### Exercuse 12

Continue your pipe. Use `pivot_wider()` to transform the data so that values for `total` and `fips` have individual columns. Set `names_from` equal to `names` and `values_from` equal to `values`. View this tibble and save it to an object called clean_data_api.

```{r bison-12, exercise = TRUE}

```

```{r bison-12-hint, eval = FALSE}
... %>% 
pivot_wider( names_from = "...", 
             values_from = "values")
```

### Exercise 13

Use `mutate()` to change the column `total` into a column of the same name whose values are integers. 

```{r bison-13, exercise = TRUE}

```

```{r bison-13-hint, eval = FALSE}
... %>% 
  mutate(total = as.integer(total))
```

### Exercise 14

Use `mutate()` and the function `tolower()` to make a new column named `region` which contains lowercase versions of the strings in the column `states`. 

```{r bison-14, exercise = TRUE}

```

```{r bison-14-hint, eval = FALSE}
... %>% 
  mutate(region = tolower(states))
```

### 

We are making the region column in preparation to join this data to the tibble that makes the map of the United States in `ggplot()`. 

### Exercise 15

Select the columns `region` and `total`. Assign this to an object called `clean_data_api`. 

```{r bison-15, exercise = TRUE}

```

```{r bison-15-hint, eval = FALSE}
clean_data api <- output$states$data %>% 
... %>% 
  select(..., ...)
```

### Exercise 16

The ggplot function `map_data()` is used to download data to make maps which can be used in `ggplot()`. Run `map_data("state")` which returns a tibble to make a map of the contiguous 48 states. 

```{r bison-16, exercise = TRUE}

```

```{r bison-16-hint, eval = FALSE}
  map_data("state")
```

### Exercise 17

Start a pipe with this tibble. Use `left_join()` with the appropriate column for the `by` argument to join `clean_data_api` to this tibble. 

```{r bison-17, exercise = TRUE}

```

```{r bison-17-hint, eval = FALSE}
  map_data("state") %>% 
  left_join("...", by = "region")
```

### Exercise 18

Continue this pipe with `ggplot()`. Map `long` to the x-axis, `lat` to the y-axis, `group` to the group argument, and `total` to fill. Add the layer `geom_polygon()`.

```{r bison-18, exercise = TRUE}

```

```{r bison-18-hint, eval = FALSE}
... %>% 
  ggplot(aes(long, lat, group = group, fill = total)) +
  geom_polygon() 
```

### Exercise 19

Add the layer `scale_fill_gradient()`. Set the argument `low` to "blue" and `high` to "red".

```{r bison-19, exercise = TRUE}

```

```{r bison-19-hint, eval = FALSE}
...
  ggplot(aes(long, lat, group = group, fill = total)) +
  geom_polygon() 
```

### Exercise 20

Use `labs()` to add a title, subtitle, axes labels, legend label, and caption to your plot.  

```{r bison-20, exercise = TRUE}

```

```{r bison-20-hint, eval = FALSE}
... + 
  labs(title = "...", 
       ...)
```

Reminder: Your graph should look like this. 

```{r show-bison-plot-api}
bison_plot_api
```

<!-- I did not spend the time to convert this into the style of the rest of the tutorial. I think the tutorial is long enough. The example is similar to imf but differs because it has an actual search function rather than pre-loaded tibbles. This contributes to the difficulty in adapting it.  -->

<!-- ## The World Bank -->
<!-- ### -->

<!-- The **WDI** package provides helper functions for access to the API for the World Bank. You can learn more about the package [here](http://vincentarelbundock.github.io/WDI/).  -->


<!-- ```{r wb_setup} -->
<!-- ratio <- WDI( -->
<!--   country = "all", -->
<!--   indicator = "BI.WAG.PRVS.FM.SM", -->
<!--   start = 1990, -->
<!--   end = 2020, -->
<!--   language = "en") -->

<!-- ratio_p <- ratio %>% -->
<!--   rename(ratio = BI.WAG.PRVS.FM.SM) %>% -->
<!--   drop_na(ratio) %>% -->
<!--   filter(country %in% c("Colombia", "El Salvador", "Honduras", -->
<!--                         "Panama", "Philippines")) %>% -->
<!--   ggplot(aes(x = year, y = ratio, color = country)) + -->
<!--   geom_point() + -->
<!--   geom_line(aes(group = iso2c)) + -->

<!--   # debating the best way to show the y-axis - 100% is an even distribution, but -->
<!--   # I don't want to mislead the unattentive reader -->

<!--   scale_y_continuous(labels = scales::percent_format()) + -->
<!--   labs( -->
<!--     title = "Female to Male Private Sector Wage Ratio", -->
<!--     subtitle = "Women tend to earn more than men in Honduras", -->
<!--     y = "Female-to-Male Wage Ratio", -->
<!--     caption = "Source: The World Bank via the WDI API package", -->
<!--     x = NULL, -->

<!--     # Dropping the legend title -->

<!--     color = NULL) -->

<!-- ratio_p -->

<!-- ``` -->


<!-- ### Exercise 1 -->

<!-- The most complex part of this edition of an API call on the World Bank's data is the data indicator - the obscure name string that selects the type of information pulled. Thankfully - there are some handy functions from the **WDI** package we can use.  -->

<!-- ### -->

<!-- On the first line, load the **WDI** package. On the subsequent line, use `WDIsearch()` to search indicator descriptions for "investment", and take a look at the first ten results. -->

<!-- ```{r wdi-00, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r wdi-00-hint, eval = FALSE} -->
<!-- library(WDI) -->
<!-- WDIsearch(...)[1:10,]  -->

<!-- # or -->

<!-- WDIsearch(...) %>%  -->
<!--   head(...) -->
<!-- ``` -->

<!-- ### -->

<!-- This works for an array of terms that the World Bank may have data about - feel free to explore! It is important to note the indicator of the data you wish to extract as it must be entered in your query.  -->

<!-- ### Exercise 2 -->

<!-- Will be looking at various countries and their private sector wage allocation between males and females, *as measured by the average group wage across business sectors* between 1990 and 2020. The indicator for this data is:  -->

<!-- ### -->

<!-- Create an object named `ratio` and use the `WDI()` function to query the appropriate data. The `indicator` for this data is "BI.WAG.PRVS.FM.SM". -->

<!-- You should remember that unless we wish to know about a certain country, we should set `country` to "all"  You will need to specify a `start` and `end` year, as well as a language, `"en"` for English. -->

<!-- ```{r wdi-01, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r wdi-01-hint-1, eval = FALSE} -->
<!-- Use the WDIsearch() tool from the previous question if you are having  -->
<!-- difficulty locating the proper indicator.  -->
<!-- ``` -->

<!-- ```{r wdi-01-hint-2, eval = FALSE} -->
<!-- ratio <- WDI( -->
<!--   country = "all", -->
<!--   indicator = ..., -->
<!--   start = ..., -->
<!--   end = ..., -->
<!--   language = ... -->
<!-- ) -->
<!-- ``` -->

<!-- ### -->

<!-- NA values are common as some metrics are more difficult to measure consistently over time for various reporting, cooperation, or development issues among others.  -->

<!-- The output of the package WDI is ready to be coverted to a tibble by default. -->

<!-- ### Exercise 3 -->

<!-- Start a new pipe with `ratio` and begin creating a plot that answers our question. If we are interested in those countries that have the most closely aligned female and male wage allocations - we would expect the ratio to be 1.0. -->

<!-- ### -->

<!-- Rename the indicator column to be `wage_ratio` and then drop NA values from the `wage_ratio` column.  -->

<!-- ```{r wdi-02, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r wdi-02-hint, eval = FALSE} -->
<!-- ratio %>%  -->
<!--   mutate(wage_ratio = ...) %>%  -->
<!--   drop_na(...) -->
<!-- ``` -->

<!-- ### Exercise 4 -->

<!-- Create a scatter plot that shows changes in the spread across countries over time. -->

<!-- ```{r wdi-03, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r wdi-03-hint, eval = FALSE} -->
<!-- ... %>%  -->
<!--   ggplot(aes(...)) + -->
<!--   geom_point() -->
<!-- ``` -->

<!-- ### -->

<!-- While this might be interesting, it is quite messy.  -->


<!-- ### Exercise 5 -->

<!-- The graph is too clutered. Filter the data to keep rows only where `country` is equal to Colombia, El Salvador, Honduras, Panama, the Philippines. Filter the data for only these countries -->

<!-- ```{r wdi-04, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r wdi-04-hint, eval = FALSE} -->
<!-- ... %>%  -->
<!--   filter(...) %>% -->
<!--   ggplot(aes(...)) + -->
<!--   geom_point() -->
<!-- ``` -->

<!-- ### -->

<!-- Now we can start to see time trends within these countries.  -->

<!-- ### Exercise 6 -->

<!-- To make these trends easier to follow, connect the scatter-plot points with `geom_line()`.  -->

<!-- Be sure to add appropriate titles, labels, etc.  -->

<!-- ```{r WDI-final, exercise = TRUE} -->

<!-- ``` -->

<!-- ```{r WDI-final-hint, eval = FALSE} -->
<!-- ... %>%  -->
<!--   filter(...) %>% -->
<!--   ggplot(aes(...)) + -->
<!--   geom_point() + -->
<!--   geom_line(aes(group = ...)) + -->
<!--   scale_y_continuous(...) + -->
<!--   labs(...) -->
<!-- ``` -->

<!-- ### Exercise 7  -->

<!-- Use `labs()` to set an appropriate title, subtitle, axes labels, and captions. -->

<!-- ```{r denver-7, exercise = TRUE} -->

<!-- ``` -->

<!-- ### -->

<!-- Reminder: you plot should look like this:  -->

<!-- ```{r final_plot_shown} -->
<!-- ratio_p -->
<!-- ``` -->

```{r remove-rplots}
file.remove("Rplots.pdf")
```


## Submit

```{r context = "setup"}
submission_ui
```

```{r context = "server"}
submission_server()
```


