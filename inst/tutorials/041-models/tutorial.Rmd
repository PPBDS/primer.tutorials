---
title: Models
author: David Kane
tutorial:
  id: models
output:
  learnr::tutorial:
    progressive: yes
    allow_skip: yes
runtime: shiny_prerendered
description: 'Chapter 4 Tutorial: Models'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(tidyverse)
library(gt)  

library(tidymodels)
library(marginaleffects)
library(broom)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

# DK: Change poll data to be a factor variable.		

poll_data <- tibble(biden = as.factor(c(rep("Yes", 655), 
                                        rep("No", 904))))


fit_biden <- logistic_reg(engine = "glm") |> 
  fit(biden ~ 1, data = poll_data)


population_table <- 
tibble(source = c("...", "...", "...","...",  
                  "Data", "Data", "Data", "Data", "...",
                  "...", "...", "...","...", 
                  "Preceptor Table", "Preceptor Table", "Preceptor Table", "...",
                  "...", "...", "..."),
       time = c("February 2024", "February 2024", "February 2024", "...",
                "March 2024", "March 2024", "March 2024", "March 2024", "...",
                "October 2024", "October 2024", "October 2024", "...",
                "November 2024", "November 2024", "November 2024", "...",
                "December 2024", "December 2024", "December 2024"),
       id = c("1", "200", "976", "...",
              "1", "200", "...", "1559", "...",
              "1", "200", "2025", "...",
              "1", "200", "2078", "...",
              "1", "200", "2300"),
       biden = c("?", "?", "?", "...",
              "0", "1", "...", "1", "...",
              "?", "?", "?", "...",
              "1", "0", "1", "...",
              "?", "?", "?")) |>
  gt() |>
  cols_label(source = md("Source"),
             time = md("Time"),
             id = md("ID"),
             biden = md("Biden")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(source))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"),
            locations = cells_column_labels(columns = c(source))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(source)) |>
  fmt_markdown(columns = everything())


```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```


<!-- Learn about marginaleffects package and use a bunch of the functions which are in it, explaining what they mean. Don't worry if none of the functions work. That is OK! Just report that fact. -->

<!-- predictions(fit_biden, type = "prob") -->
<!-- plot_predictions(fit_biden, type = "prob", condition = "group") This is a nonsensical plot! But explain to students why! -->

<!-- Final plot with  -->
<!-- predictions(fit_biden, type = "prob") |> select(group == "Yes") |> slice_sample(n = 1) -->

<!-- Some concerns that this is too long. -->

## Introduction
### 

This tutorial supports [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

The world confronts us. Make decisions we must.

Imagine you are the chair of the DNC in early 2024. To allocate resources effectively, you need to estimate Joe Biden’s true level of voter support to decide how much funding to direct to his race versus other key contests.

## The Question
### 

*It is not the answer that enlightens, but the question.* - Eugene Ionesco

With this project, we’re not trying to predict every detail about the 2024 election. That would be impossible. Instead, we’re focusing on a question that we can actually begin to answer: what proportion of all votes will be cast for Joe Biden? 

### Exercise 1

Load [**tidyverse**](https://www.tidyverse.org/) package.

```{r the-question-1, exercise = TRUE}

```

```{r the-question-1-hint-1, eval = FALSE}
library(tidyverse)
```

```{r the-question-1-test, include = FALSE}
library(tidyverse)
```

### 

The polling data comes from a YouGov survey of 1,559 U.S. adult citizens conducted March 10-12, 2024.

### Exercise 2

Load the [**primer.data**](https://ppbds.github.io/primer.data/) package.

```{r the-question-2, exercise = TRUE}

```

```{r the-question-2-hint-1, eval = FALSE}
library(primer.data)
```

```{r the-question-2-test, include = FALSE}
library(primer.data)
```

### 

A version of the data from **YouGov's March 2024 poll** is available in `poll_data`. 

### Exercise 3

After loading **poll_data** in your console, type `glimpse(poll_data),` and paste in the description below. The data comes from a YouGov poll conducted March 10-12, 2024, surveying 1,559 US adult citizens about their voting intentions for the 2024 presidential election.

```{r the-question-3}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

For this poll, the specific question asked was: 
"If an election for president were going to be held now and the Democratic nominee was Joe Biden and the Republican nominee was Donald Trump, would you vote for…"  
For our analysis, we focus only on whether respondents indicated they would vote for Biden (coded as 1) or not (coded as 0).

### Exercise 4

**Political Polling** is the broad topic of this tutorial. Given that topic, which variable in `poll_data` should we use as our outcome variable?


```{r the-question-4}
question_text(NULL,
	message = "biden: A binary outcome variable indicating whether a respondent supports Joe Biden (1) or not (0) in the upcoming election.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

We will use `biden` as our outcome variable.

```{r}
poll_data |> 
  ggplot(aes(x = factor(biden))) +
  geom_bar(fill = "steelblue") +
  labs(
    title = "Distribution of Support for Joe Biden",
    subtitle = "About 42% of respondents said they would vote for Biden",
    x = "Would Vote for Biden (1 = Yes, 0 = No)",
    y = "Number of Respondents"
  ) +
  theme_minimal(base_size = 14)
```

### Exercise 5

Let's imagine a brand new variable which **does not exists** in the data. This variable should be binary, meaning that it only takes on one of two values. It should also, at least in theory, be manipulable. In other words, if the value of the variable is "3," or whatever, then it generates one potential outcome and if it is "9," or whatever, it generates another potential outcome.


Describe this imaginary variable and how might we manipulate its value.

```{r the-question-5}
question_text(NULL,
	message = "Imagine a variable called `trump_ad` which has a value of `1` if the person was shown a pro-Trump advertisement and `0` if they were not shown the ad. We can manipulate this variable by deciding, either randomly or otherwise, whether or not a specific individual sees the advertisement.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Any data set can be used to construct a causal model as long as there is at least one covariate that we can, at least in theory, manipulate. It does not matter whether or not anyone did, in fact, manipulate it. 

### Exercise 6

Given our (imaginary) treatment variable `trump_ad`, how many potential outcomes are there for each `trump_ad` unit? Explain why.

```{r the-question-6}
question_text(NULL,
	message = "There are two potential outcomes because the treatment variable `trump_ad` takes on two possible values: `1` (exposure to a pro-Trump advertisement) versus `0` (no such exposure).",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The same data set can be used to create, separately, lots and lots of different models, both causal and predictive. We can just use different outcome variables and/or specify different treatment variables. This is a *conceptual* framework we apply to the data. It is never inherent in the data itself.

### Exercise 7

In a few sentences, specify the two different values for the imaginary treatment variable `trump_ad`, for a single unit, guess at the potential outcomes which would result, and then determine the causal effect for that unit given those guesses.

```{r the-question-7}
question_text(NULL,
	message = "For a given voter, the treatment variable might be **exposure to a pro-Trump advertisement** or **no exposure**. If exposed, their support for `biden` is `0`; if not, it's `1`. However, the causal effect is simply the difference between expressing support for Biden, or not expressing support for Biden.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The definition of a causal effect is the difference between two potential outcomes. Of course, you can't just say that the causal effect is 10. The exact value depends on which potential outcome comes first in the subtraction and which second. There is, perhaps, a default sense in which the causal effect is defined as treatment minus control. 

Any causal connection means exploring the *within row* difference between two potential outcomes. We don't need to look at any other rows to have that conversation.

### Exercise 8

<!-- XX: Replace stuff like `XX: the tibble` with just the name of the tibble, i.e., `trains`. -->

Let's consider a *predictive model*. Which variable in `poll_data` do you think might have an important connection to `biden?`

```{r the-question-8}
question_text(NULL,
	message = "One key covariate to explore is `age`, since voter preferences often vary by age group.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

With a predictive model, there is only one outcome for each individual unit. There are not two potential outcomes because we are not considering any of the covariates to be a treatment variable. We assuming that the values of all covariates are "fixed." 

There are no "treatments" in predictive models. There are only covariates.

### Exercise 9

Specify two different groups of **voters** which have different values for **age** and which might have different average values for the `biden` outcome.

```{r the-question-9}
question_text(NULL,
	message = "Consider two groups, the first with a value for age of **25** and the second with a value of **65**. Those two groups might have different average values for the outcome variable `biden`.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In predictive models, do not use words like "cause," "influence," "impact," or anything else which suggests causation. The best phrasing is in terms of "differences" between groups of units with different values for a covariate of interest.

### Exercise 10

Write a **causal question** which connects the outcome variable `biden` to `trump_ad`, the covariate of interest.

Example: What is the effect of being exposed to a **trump_ad** on a voter's likelihood of supporting `biden`?

```{r the-question-10}
question_text(NULL,
	message = "What is the causal effect of exposure to a `trump_ad` on support for `biden`?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The answer to this question is your "Quantity of Interest." 

Our Quantity of Interest might appear too specific, too narrow to capture the full complexity of the topic. There are many, many numbers in which we are interested, many numbers that we want to know. But we don't need to list them all here! We just need to choose one of them since our goal is just to have a specific number which helps to guide us in the creation of the Preceptor Table and, then, the model.


## Wisdom
### 

*Wonder is the beginning of wisdom.* - Socrates

The general question we are interested in is the future results of the 2024 election, as seen from a survey conducted March of 2024.

Our specific question:

> *What proportion of all votes will be cast for Joe Biden in the 2024 election?*

### Exercise 1

In your own words, describe the key components of Wisdom when working on a data science problem. What should you keep in mind before jumping into modeling?

```{r wisdom-1}
question_text(NULL,
    message ="1) Voters might change their minds between now and Election Day (e.g., due to debates or news events). 2) Poll participants may not reflect all voters. For example, groups such as young voters or rural voters could be underrepresented. 3) Some people might not answer honestly (e.g., hiding support for a certain candidate).",
    answer(NULL, correct = TRUE),
    allow_retry = FALSE,
    incorrect = NULL,
    rows = 6)
```

The central problem for **Wisdom** is: Can we use data from a March 2024 YouGov poll of U.S. adult citizens to understand the variables/relationships in **a table showing voter support for Biden across different sources and time periods?**

### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, we can easily calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Precisely describing the Preceptor Table for this problem is the first step in trying to solve it. 


### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem. Use words like "units," "covariates," and "outcomes." 

```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The way I like to think of it is that the units are the objects that are being affected (rows), while the outcome column is how the units are being affected.


### Exercise 4

Create a Github repo called `models`. Make sure to click the "Add a README file" check box.

Connect the Github repo to an R project on your computer. Give the R project the same name.

Select `File -> New File -> Quarto Document ...`. Provide a title (`"models"`) and an author (you). Render the document and save it as `analysis.qmd`.

Edit the `.gitignore` by adding `*Rproj`. Save and push.

In the Console, run:

```{r wisdom-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

### Exercise 5

What are the units for this problem?

```{r wisdom-5}
question_text(NULL,
	message = "The units are all voting-eligible citizens in November 2024",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Specifying the Preceptor Table forces us to think clearly about the units and outcomes implied by the question. The resulting discussion sometimes leads us to modify the question with which we started. No data science project follows a single direction. We always backtrack. There is always dialogue.

### Exercise 6

What is the outcome for this problem?

```{r wisdom-6}
question_text(NULL,
	message = "The outcome is whether a person voted for Joe Biden—1 for yes, 0 for no.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Looking at the question, having the outcome as "the candidate for whom the vote was cast" (or something similar) is too broad. We don't actually need to know the name of the candidate. We just need to know if the vote was cast for Biden or not. The name of the candidate, if it was not Biden, is irrelevant to our question. So, we can represent the outcome as 0 (did not vote for Biden) and 1 (did vote for Biden).

Realistically, then, this question only has 1 outcome. This means that the problem would be a predictive model.

### Exercise 7

What is a covariate which you think might be useful for this problem, regardless of whether or not it might be included in the data?

```{r wisdom-7}
question_text(NULL,
	message = "A plausible covariate is `age`, as it may influence voting preferences.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The term "covariates" is used in at least three ways in data science. First, it is all the variables which might be useful, regardless of whether or not we have the data. Second, it is all the variables for which we have data. Third, it is the set of variables in the data which we end up using in the model.

### Exercise 8

What are the treatments, if any, for this problem?

```{r wisdom-8}
question_text(NULL,
	message = "There is no treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

This is a predictive model, not a causal model, so there are no treatments, by definition. Recall that treatment is just a covariate which, given the question we are trying to answer, might at least in theory be manipulable.

### Exercise 9

What moment in time does the Preceptor Table refer to?

```{r wisdom-9}
question_text(NULL,
	message = "Just after Election Day (November), 2024",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Take note of the date of the Preceptor Table, as this will be different from our data. When working with multiple data sources, it's important to keep track of the date and how the information may be affected by it.

### Exercise 10

Define a causal effect. (Note that the model in this tutorial is predictive, not causal. We just want to make sure you understand what a causal model is.)

```{r wisdom-10}
question_text(NULL,
	message = "A causal effect is the difference between two potential outcomes.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table for this problem looks like this:

```{r}
#| echo: false
tibble(voter_ID = c("1", "2", 
                   "...", "200", "201", "...", "2078", "2079", "..."),
       biden = c("0", "0", 
                   "...", "1", "0", "...", "1", "0", "...")) |>
  gt() |>
    tab_header(title = "Preceptor Table") |> 
    cols_label(voter_ID = "Voter ID",
               biden = "Voted for Biden") |>
    tab_style(cell_borders(sides = "right"),
              location = cells_body(columns = c(voter_ID))) |>
    cols_align(align = "center", columns = everything())
```


According to the Rubin Causal Model, there must be two (or more) potential outcomes for any discussion of causation to make sense. This is simplest to discuss when the treatment only has two different values, thereby generating only two potential outcomes. 


### Exercise 11

What is the fundamental problem of causal inference?

```{r wisdom-11}
question_text(NULL,
	message = "The fundamental problem of causal inference is that we can only observe one potential outcome.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If the treatment variable is continuous (like income), then there are lots and lots of potential outcomes, one for each possible value of the treatment variable. 

### Exercise 12

How does the motto "No causation without manipulation" apply in this problem?

```{r wisdom-12}
question_text(NULL,
	message = "This tutorial uses a predictive model, so the motto 'No causation without manipulation' does not apply directly. However, you can still reflect on whether it's theoretically possible to manipulate the covariates or treatment to create a causal scenario.?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: We need to keep track of how these issues apply to both our Preceptor Table and our data.  -->

### Exercise 13

Describe in words the Preceptor Table for this problem.

```{r wisdom-13}
question_text(NULL,
	message = "The Preceptor Table consists of rows representing individual voters in the 2024 U.S. presidential election, with columns showing each voter's binary outcome (Biden support: 1/0).",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- The Preceptor Table for this problem looks something like this: -->

<!-- #| echo: false -->
<!-- tibble(voter_id = c("1", "2", "...", "158,000,000"), -->
<!--        biden_support = c("0", "1", "...", "0"), -->
<!--        age_group = c("18-29", "65+", "...", "30-44"), -->
<!--        region = c("South", "Midwest", "...", "Northeast")) |> -->

<!--   gt() |> -->
<!--   tab_header(title = "Preceptor Table: 2024 Presidential Election") |>  -->
<!--   cols_label(voter_id = md("Voter ID"), -->
<!--              biden_support = md("Voted for Biden (1=Yes)"), -->
<!--              age_group = md("Age Group"), -->
<!--              region = md("Region")) |> -->
<!--   tab_style(cell_borders(sides = "right"), -->
<!--             location = cells_body(columns = c(voter_id))) |> -->
<!--   cols_align(align = "center") |> -->
<!--   tab_spanner(label = "Outcome", columns = c(biden_support)) |> -->
<!--   tab_spanner(label = "Covariates", columns = c(age_group, region)) |> -->
<!--   fmt_markdown(columns = everything()) -->

<!-- Like all aspects of a data science problem, the Preceptor Table evolves as we continue our work.  -->

### Exercise 14

In your QMD, load the **tidyverse** and the **primer.data** packages in a new code chunk. Render the file.

Notice that the file does not look good because the code is visible and there are annoying messages. To take care of this, add `#| message: false` to remove all the messages in the `setup` chunk. Also add the following to the YAML header to remove all code echos from the whole file:

```         
execute: 
  echo: false
```

In the Console, run:

```         
show_file("analysis.qmd", start = -5)
```

CP/CR.

```{r wisdom-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

### 

Render again. Everything looks nice because we have added code to make the file look better and more professional.

### Exercise 15

In your own words, define "validity" as we use the term.

```{r wisdom-15}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Validity is always about the *columns* in the Preceptor Table and the data. Just because columns from these two different tables have the same *name* does not mean that they are the same *thing*.


### Exercise 16


Provide one reason why the assumption of validity might not hold when comparing the polling data to actual election results. Focus on either the outcome column (Biden support) or a potential covariate column, using the word "column" in your answer.

```{r wisdom-16}
question_text(NULL,
	message = "Validity may fail because the poll's 'would vote for Biden' column measures intentions months before the election, while the Preceptor Table's 'voted for Biden' column captures actual behavior - these can differ substantially.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In order to consider the Preceptor Table and the data to be drawn from the same population, the columns from one must have a *valid correspondence* with the columns in the other. Validity, if true (or at least reasonable), allows us to construct the Population Table, which is the first step in Justice.

Because we control the Preceptor Table and, to a lesser extent, the original question, we can adjust those variables to be “closer” to the data that we actually have. This is another example of the iterative nature of data science. If the data is not close enough to the question, then we check with our boss/colleague/customer to see if we can modify the question in order to make the match between the data and the Preceptor Table close enough for validity to hold.

Despite these potential problems, we will assume that validity holds since it, mostly (?), does.

### Exercise 17

Over the course of this tutorial, we will be creating a summary paragraph. The purpose of this exercise is to write the first two sentences of that paragraph.

The first sentence is a general statement about the overall topic, mentioning both the general class of the outcome variable and of at least one of the covariates. It is **not** connected to the initial "Imagine that you are XX" which set the stage for this project. That sentence can be rhetorical. It can be trite, or even a platitude. The purpose of the sentence to let the reader know, gently, about our topic.

The second sentence does two things. First, it introduces the data source. Second, it introduces the specific question. The sentence can't be that long. Important aspects of the data include when/where it was gather, how many observations it includes and the organization (if famous) which collected it.

Type your two sentences below.

```{r wisdom-17}
question_text(NULL,
	message = "Public opinion polls provide crucial but imperfect snapshots of voter sentiment during campaigns. Using March 2024 YouGov survey data from 1,559 U.S. adults, we estimate the proportion of votes Joe Biden will receive in the November election.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Read our answer. It will not be the same as yours. You can, if you want, change your answer to incorporate some of our ideas. Do not copy/paste our answer exactly. Add your two sentences, edited or otherwise, to your QMD, `Command/Ctrl + Shift + K`, and then commit/push.

## Justice
### 

*Justice is truth in action.* - Benjamin Disraeli

### Exercise 1

In your own words, name the four key components of Justice (without describing them) for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

Justice is about concerns that you (or your critics) might have, reasons why the model you create might not work as well as you hope. 

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Population Table is almost always much bigger than the combination of the Preceptor Table and the data because, if we can really assume that both the Preceptor Table and the data are part of the same population, than that population must cover a broad universe of time and units since the Preceptor Table and the data are, themselves, often far apart from each other.

### Exercise 3

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-3}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability is all about *time*. Is the relationship among the columns in the Population Table stable over time? In particular, is the relationship --- which is another way of saying "mathematical formula" --- at the time the data was gathered the same as the relationship at the (generally later) time referenced by the Preceptor Table. 

### Exercise 4

Provide one reason why the assumption of stability might not be true in this case. (This is somewhat of a trick question.)

```{r justice-4}
question_text(NULL,
	message = "Our Population Table is so simple that stability is almost automatically true. There is only one column!",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A change in time or the distribution of the data does not, in and of itself, demonstrate a violation of stability. Stability is about the parameters: $\beta_0$, $\beta_1$ and so on. Stability means these parameters are the same in the data as they are in the population as they are in the Preceptor Table.

### Exercise 5

We use our data to make inferences about the overall population. We use information about the population to make inferences about the Preceptor Table: `Data -> Population -> Preceptor Table`. In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-5}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationships among the rows in the Population Table. The first is between the data and the other rows. The second is between the other rows and the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case.

### Exercise 6

We do not use the data, directly, to estimate missing values in the Preceptor Table. Instead, we use the data to learn about the overall population. Provide one reason, involving the relationship between the data and the population, for why the assumption of representativeness might not be true in this case. 

```{r justice-6}
question_text(NULL,
	message = "The poll respondents might systematically differ from actual voters in their political engagement - frequent voters are overrepresented in surveys while occasional voters who decide late are harder to reach, potentially skewing our estimates of Biden's support.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The reason that representativeness is important is because, when it is violated, the estimates for the model parameters might be biased. 

### Exercise 7

We use information about the population to make inferences about the Preceptor Table. Provide one reason, involving the relationship between the population and the Preceptor Table, for why the assumption of representativeness might not be true in this case.

```{r justice-7}
question_text(NULL,
	message = "The Preceptor Table only includes actual voters, while the population contains all eligible voters - groups like young people and minorities often vote at different rates than their share of the population, creating a representativeness gap.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability examines how voter preferences change over time, while representativeness assesses whether our poll respondents mirror the actual voting population's demographics and engagement levels at a single point in time. 

### Exercise 8

In your own words, define the assumption of "unconfoundedness" in the context of data science.

```{r justice-8}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates. This assumption is only relevant for casual models.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This assumption is only relevant for causal models. We describe a model as "confounded" if this is not true. The easiest way to ensure unconfoundedness is to assign treatment randomly.

### Exercise 9

Write one sentence which highlights a potential weakness in your model. This will almost always be derived from possible problems with the assumptions discussed above. We will add this sentence to our summary paragraph. So far, our version of the summary paragraph looks like this:

Public opinion polls provide crucial but imperfect snapshots of voter sentiment during campaigns. Using March 2024 YouGov survey data from 1,559 U.S. adults, we estimate the proportion of votes Joe Biden will receive in the November election. 

Of course, your version will be somewhat different.

```{r justice-9}
question_text(NULL,
	message = "Our estimates may be biased if late-deciding voters break differently for Biden than survey respondents who expressed firm preferences in March.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Add a weakness sentence to the summary paragraph in your QMD. You can modify your paragraph as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`, and then commit/push.


## Courage
### 

*Courage is found in unlikely places.* - J.R.R. Tolkien


### Exercise 1

In your own words, describe the components of the virtue of Courage for analyzing data.

```{r courage-1}
question_text(NULL,
	message = "Courage starts with math, explores models, and then creates the data generating mechanism.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

A statistical model consists of two parts: the *probability family* and the *link function*. The probability family is the probability distribution which generates the randomness in our data. The link function is the mathematical formula which links our data to the unknown parameters in the probability distribution. 

### Exercise 2

<!-- XX: Only load tidymodels if you are actually using it. Or load the modeling package that you are using, like ordinal. Or, if you are just using something built in like glm(), delete this question but move the knowledge drop back to the previous question. -->

Load the [**tidymodels**](https://www.tidymodels.org/) package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(tidymodels)
```

### 

The probability family is determined by the outcome variable $Y$. 

Since $Y$ is a binary variable (with exactly two possible values), the probability family is Bernoulli.

$$Y \sim \text{Bernoulli}(\rho)$$

where $\rho$ is the probability that one of the two possible values --- conventionally referred to as `1` or `TRUE` --- occurs. By definition, $1 - \rho$ is the probability of the other value.

### Exercise 3

Load the [**broom**](https://broom.tidymodels.org/) package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(broom)
```

### 

The link function, the basic mathematical structure of the model, is (mostly) determined by the type of outcome variable. 

For a binary outcome variable, we use a log-odds model:

$$
\log\left[ \frac { \rho }{ 1 - \rho } \right] = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots 
$$

The link functions for categorical and cumulative variables are also built out of a log-odds link functions.

### Exercise 4

Use AI to come up with a $\LaTeX$ representation of the mathematical structure of the model, with $Y$ as the dependent variable and $X_1$, $X_2$ and so on as the independent variables. This version will not have the values of any parameters since we have not, yet, estimated them. Confirm that the code works by placing it in your QMD and then rendering. Paste that $\LaTeX$ code below.

```{r courage-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 5)
```

**Prompt to AI:**  
"Create LaTeX code for a logistic regression model where the outcome is binary Biden vote (1 = voted for Biden, 0 = didn't vote for Biden), showing the probability formulation and distribution assumption."

**Resulting Model:**

$$P(\text{BidenVote} = 1) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 \text{Age} + \beta_2 \text{Income} + \beta_3 \text{Education})}}$$

with $\text{BidenVote} \sim \text{Bernoulli}(p)$ where $p$ is the modeled probability.

### Exercise 5

Add `library(tidymodels)` and `library(broom)` to the `setup` code chunk in your QMD. `Command/Ctrl + Shift + K`.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", pattern = "library")
```

CP/CR.

```{r courage-5}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

### 

Having decided on the basic mathematical structure of the model, a choice mostly driven by the distribution of our outcome variable, we now turn toward estimating the model.

### Exercise 6

Because our outcome variable is **binary**, start to create the model by entering `logistic_reg(engine = "glm")`.

```{r courage-6, exercise = TRUE}

```

```{r courage-6-hint-1, eval = FALSE}
logistic_reg(engine = "glm")
```

```{r courage-6-test, include = FALSE}
logistic_reg(engine = "glm")
```

### 

The *[tidymodels](https://www.tidymodels.org/)* framework is the most popular one in the R world for estimating models. *[Tidy Modeling with R](https://www.tmwr.org/)* by Max Kuhn and Julia Silge is a great introduction.

### Exercise 7

<!-- XX: Fit the model to a single categorical variable, ideally one with just two levels, like sex. If that is not possible, use your best judgment as to what to do instead. -->

Continue the pipe to `fit(XX, data = poll_data).`

```{r courage-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-7-hint-1, eval = FALSE}
... |>
  fit(..., data = ...)
```

```{r courage-7-test, include = FALSE}
logistic_reg(engine = "glm") |> 
  fit(biden ~ 1, data = poll_data)
```

###

The `biden` variable is already in binary format, representing whether someone voted for Biden (1) or not (0). Since logistic regression models require a binary outcome, `biden` can be used directly without needing to convert it into dummy variables.

However, if `biden` were stored as a text variable like "yes" or "no", R would automatically convert it into a dummy variable — typically coding "yes" as 1 and "no" as 0 — so it can be used in the logistic regression model.

### Exercise 8

Continue the pipe with `tidy(conf.int = TRUE)`.

```{r courage-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-8-hint-1, eval = FALSE}
...
  tidy(... = TRUE)
```

```{r courage-8-test, include = FALSE}
logistic_reg(engine = "glm") |> 
  fit(biden ~ 1, data = poll_data) |> 
  tidy(conf.int = TRUE)
```

###

<!-- DK: Use response scale? -->

The intercept $\beta_0$ is the log-odds of voting for Biden when all predictors are zero. Each coefficient $\beta_i$ shows how the log-odds change with a one-unit increase in that predictor, holding others constant. Confidence intervals indicate plausible ranges for these estimates.

### Exercise 9

Behind the scenes of this tutorial, an object called `fit_XX` has been created which is the result of the code above. Type `fit_XX` and hit "Run Code." This generates the same results as using `print(fit_XX)`.

```{r courage-9, exercise = TRUE}

```

```{r courage-9-hint-1, eval = FALSE}
fit_XX
```

```{r courage-9-test, include = FALSE}
# fit_XX
```

###

In data science, **we deal with words, math, and code, but the most important of these is code.** We created the mathematical structure of the model and then wrote a model formula in order to estimate the unknown parameters.

### Exercise 10

Load the **[easystats](https://easystats.github.io/easystats/)** package.

```{r courage-10, exercise = TRUE}

```

```{r courage-10-hint-1, eval = FALSE}
library(...)
```

```{r courage-10-test, include = FALSE}
library(easystats)
```

###

We don't add **easystats** to the QMD because we are only using it for an interactive check of our fitted model. However, the [easystats ecosystem](https://easystats.github.io/easystats/) has a variety of interesting functions and packages which you might want to explore.

### Exercise 11

In the Console, run `check_predictions(extract_fit_engine(fit_biden))`. There will probably be an error. CP/CR.

```{r courage-11, exercise = TRUE}

```

```{r courage-11-hint-1, eval = FALSE}
check_predictions(extract_fit_engine(...))
```

```{r courage-11-test, include = FALSE}
check_predictions(extract_fit_engine(fit_biden))
```

###

<!-- DK: Explain the plot. -->

### Exercise 12

Ask AI to create $\LaTeX$ code for this model, including our variable names and estimates for all the coefficients. Because this is a fitted model, the dependent variable will have a "hat" and the formula will not include an error term.

Add the code to your QMD. `Cmd/Ctrl + Shift + K`.

Make sure the resulting display looks good. For example, you don't want an absurd number of figures to the right of the decimal. If the model is too long, you will need to spread it across several lines. You may need to go back-and-forth with the AI a few times.

Once the $\LaTeX$ code looks good, paste it below.

```{r courage-12}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

###

<!-- XX: Replace these examples with your code. -->

Our formula looks like:

$$\widehat{\text{att_end}} = 8.45 + 1.55 \cdot \text{treatment}_{\text{Treated}}$$

It was created with:

````
$$\widehat{\text{att_end}} = 8.45 + 1.55 \cdot \text{treatment}_{\text{Treated}}$$
````

Note the differences. First, we have replaced the parameters with our best estimates. Second, we have dropped the error term because this is a formula for predicting the value for our outcome variable. Third, the left-hand side variable is $\widehat{\text{XX}}$ instead of $\text{XX}$ because this formula generates our estimated `XX`. A hat indicates an estimated value.

**This is our data generating mechanism.**

A data generating mechanism is just a formula, something which we can write down and implement with computer code.

### Exercise 13

Create a new code chunk in your QMD. Add a code chunk option: `#| cache: true`. Copy/paste the code from above for estimating the model into the code chunk, assigning the result to `fit_XX`.

`Command/Ctrl + Shift + K`. It may take some time to render your QMD, depending on how complex your model is. But, by including `#| cache: true` you cause Quarto to cache the results of the chunk. The next time you render your QMD, as long as you have not changed the code, Quarto will just load up the saved fitted object.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", start = -8)
```

CP/CR.

```{r courage-13}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 8)
```

###

To confirm, `Command/Ctrl + Shift + K` again. It should be quick.

### Exercise 14

Add `*_cache` to `.gitignore` file. Cached objects are often large. They don't belong on Github.

At the Console, run:

```
tutorial.helpers::show_file(".gitignore")
```

CP/CR.

```{r courage-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 6)
```

###

Because of the change in your `.gitignore` (assuming that you saved it), the cache directory should not appear in the Source Control panel because Git is ignoring it, as instructed. Commit and push.

### Exercise 15

In the Console, run `tidy()` on `fit_bern` with the argument `conf.int` set equal to `TRUE`. The returns 95% intervals for all the parameters in our model.

```{r courage-15, exercise = TRUE}

```

```{r courage-15-hint-1, eval = FALSE}
tidy(..., conf.int = ...)
```

```{r courage-15-test, include = FALSE}
# tidy(fit_bern, conf.int = TRUE)
```

###

`tidy()` is part of the [**broom**](https://broom.tidymodels.org/) package, used to summarize information from a wide variety of models.

### Exercise 16

Create a new code chunk in your QMD. Ask AI to help you make a nice looking table from the tibble which is returned by `tidy()`. You don't have to include all the variables which `tidy()` produces. We often just show the estimate and the confidence intervals.

Insert that code into the QMD.

`Command/Ctrl + Shift + K`.

Make sure it works. You might need to add some new libraries, e.g., **[tinytable](https://vincentarelbundock.github.io/tinytable/)**, **[knitr](https://yihui.org/knitr/)**, **[gt](https://gt.rstudio.com/)**, **[kableExtra](https://haozhu233.github.io/kableExtra/)**, **[flextable](https://davidgohel.github.io/flextable/)**, **[modelsummary](https://modelsummary.com/)**, et cetera, to the `setup` code chunk, if you use any functions from these packages, all of which have strengths and weaknesses for making tables.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", end = -10)
```

CP/CR.

```{r courage-16}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 12)
```

###

<!-- XX: Consider showing your table, and the code which you used to create it. -->

At the very least, your table should include a title and a caption with the data source. The more you use AI, the better you will get at doing so.

### Exercise 17

Add a sentence to your project summary.

Explain the structure of the model. Something like: "I/we model XX [the concept of the outcome, not the variable name], [insert description of values of XX], as a [linear/logistic/multinomial/ordinal] function of XX [and maybe other covariates]."

Recall the beginning of our version of the summary:

Public opinion polls provide crucial but imperfect snapshots of voter sentiment during campaigns. Using March 2024 YouGov survey data from 1,559 U.S. adults, we estimate the proportion of votes Joe Biden will receive in the November election. Our estimates may be biased if late-deciding voters break differently for Biden than survey respondents who expressed firm preferences in March.

```{r courage-17}
question_text(NULL,
	message = "We model voting preference [the probability of supporting Biden in the election], where responses are coded as 1 (voted for Biden) or 0 (did not vote for Biden), as a logistic function of age, income level, and party identification. The model accounts for both continuous (age) and categorical (income, party ID) predictors, with the logistic transformation ensuring predicted probabilities remain between 0 and 1",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

Read our answer. It will not be the same as yours. You can, if you want, change your answer to incorporate some of our ideas. Do not copy/paste our answer exactly. Add your two sentences, edited or otherwise, to the summary paragraph portion of your QMD. `Command/Ctrl + Shift + K`, and then commit/push.






<!-- DK: Here is some leftover junk which might be useful. -->

<!-- The "Intercept" is the key part of the model. Because the family is Bernoulli and the link function an identity, the model we are estimating looks like: -->

<!-- $$ biden_i =  \mu + \epsilon_i $$ -->

<!-- $biden_i$ is a binary variable indicating whether or not voter $i$ voted for Biden. $\mu$ is true proportion of Biden voters. $\epsilon_i$ is the "error term," the difference between the vote of person $i$ and the true proportion of Biden voters. $\mu$, also called the "Intercept," is about 0.42. The value of `biden` is either `0` or `1`. So, the value of $\epsilon$ is either -0.42 or + 0.58. No other value is possible. -->


<!-- Write a few sentences which summarize your work so far. The first few sentences are the same as what you had at the end of the Justice Section. Add one sentence which describes the modelling approach which you are using. Then, add a sentence which tells us something about the model.


question_text(NULL,
	message = "Using data from a YouGov poll of 1,559 US adult citizens, conducted March 10 - 12, 2024, we seek to understand what proportion of voters will support Biden in the 2024 election. Biden’s popularity might change significantly over the course of the election campaign. In the poll, Biden’s support was much less than 50%.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
-->



## Temperance
###

<!-- XX: Discuss newdata objects slowly. "A newdata tibble must include columns for all the right-hand side variables --- all the "covariates" --- in the model, and with all the same variable names and, mostly, variable types" - DONE

First ask a question about which columns are needed in the newdata object. This might just be a written question. The answer is all the variables which are on the rightside of the formula. - DONE

Second, ask a question about which values you want those variables to have. That is not easy! Again, a written answer. For each row in the newdata tibble, you get a new posterior. How many posteriors do you want?

Third, give them the R code which creates the newdata object. All they need to do is run it. Asking them to create it, even after you help them figure out the columns (question 1) and rows (question 2) is too hard, at least until they get more experiences. - DONE

Fourth, inform them that you have, behind the scenes (which really means the setup code chunk), already assigned this tibble to the `ndata` object. In this question, they just type `ndata` to confirm. - DONE

The knowledge drops for all four of these questions allow you to explain/teach more about what goes in the argument for newdata and what does not. Explaining what other newdata objects would produce, if we used them, is a good idea.

-->

*Temperance is a tree which as for its root very little contentment, and for its fruit calm and peace.* - Buddha

Temperance means practicing restraint and not rushing to judgment. In any kind of work, including data analysis, this leads to peace of mind and stronger results.

In this project, we show temperance by being careful with our models. We don’t jump to causal claims. Instead, we build slowly, check our assumptions, and focus on what the data can actually support.


### Exercise 1

In your own words, describe the use of Temperance in data science.

```{r temperance-1}
question_text(NULL,
	message = "Temperance uses the data generating mechanism to answer the question with which we began. Humility reminds us that this answer is always a lie. We can also use the DGM to calculate many similar quantities of interest, displaying the results graphically.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 2

In the end, we don't really care about parameters, much less how to interpret them. Parameters are *imaginary*, like unicorns. We care about answers to our questions. Parameters are tools for answering questions. They aren't interesting in-and-of themselves. *In the modern world, all parameters are nuisance parameters.*

Load the [**marginaleffects**](https://marginaleffects.com/) package.

```{r temperance-2, exercise = TRUE}

```

```{r temperance-2-hint-1, eval = FALSE}
library(...)
```

```{r temperance-2-test, include = FALSE}
library(marginaleffects)
```

###

We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.

### Exercise 3

What is the general topic we are investigating? What is the specific question we are trying to answer?

```{r temperance-3}
question_text(NULL,
	message = "The general question we are interested in is the future results of the 2024 election, as seen from a survey conducted March 2024. Our specific question: What proportion of all votes will be cast for Joe Biden in the 2024 election?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

Data science projects almost always begin with a broad topic of interest. Yet, in order to make progress, we need to drill down to a specific question. This leads to the creation of a data generating mechanism, which can now be used to answer lots of questions, thus allowing us to explore the original topic broadly.

### Exercise 4

Run this code:

```
plot_predictions(fit_bern,
                 condition = c("age", "sex"))
```

```{r temperance-4, exercise = TRUE}

```

```{r temperance-4-test, include = FALSE}

```

###

<!-- XX: The knowledge drop MUST discuss the estimate (and its uncertainty) that you go on to include in your summary paragraph. You MUST discuss how you are reading, roughly, the values for the estimate and the confidence interval by looking at this plot. -->

<!-- XX: There are a lot of interesting options in plot_predictions. Check them out. You may want to use some of them in your plot. I think `points` is quite interesting. Add a couple more questions which use different argument values and/or add other options.  -->

<!-- XX: You can use the draw = FALSE option to return a tibble which can then be piped directly into ggplot.  -->

### Exercise 5

<!-- XX: After you have run several marginaleffects functions, it is time to finish up, to create your final plot. In this question, have them run the final marginaleffects function, the one that will form the basis of the final plot. -->

Run this code:

```
plot_predictions(fit_bern,
                 condition = c("age", "sex")))
```

```{r temperance-5, exercise = TRUE}

```

```{r temperance-5-test, include = FALSE}

```

###

### Exercise 6

Work interactively with your QMD to make a beautiful version of this plot. Your title should highlight the key variables. Your subtitle should describe the key takeaway, the sentence/conclusion which readers will, you hope, remember. Your caption should mention the data source. Your axis labels should look nice.

This plot is not directly connected to your question. It answers lots of questions! It might be used by lots of different people.

Copy the code for your plot here:

```{r temperance-6}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 20)
```

###

Data science often involves this-back-and-forth style of work. First, we need to make a single chunk of code, in this case, a new plot, work well. This requires interactive work between the QMD and the Console. Second, we need to ensure that the entire QMD runs correctly on its own.

### Exercise 7

Finalize the new graphics code chunk in your QMD.

`Command/Ctrl + Shift + K` to ensure that it all works as intended. Don't forget to add `library(marginaleffects)` to your `setup` code chunk.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", start = -8)
```

CP/CR.

```{r temperance-7}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 10)
```


###


<!-- XX: Discuss some limitations of this model. Remind us of some of the reasons to demonstrate humility. -->

### Exercise 8

Write the last sentence of your summary paragraph. It describes at least one quantity of interest (QoI) and provides a measure of uncertainty about that QoI. (It is OK if this QoI is not the one that you began with. The focus of a data science project often changes over time.)

```{r temperance-8}
question_text(NULL,
	message = "One quantity of interest is the overall probability that a respondent supports Biden, which our model estimates using only an intercept. This gives a single predicted value for all observations, reflecting the average level of support in the dataset.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

Add a final sentence to your summary paragraph in your QMD as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`.

### Exercise 9

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval, if you think either might be warranted.

```{r temperance-9}
question_text(NULL,
	message = "The model uses only an intercept and assumes a representative sample, but real-world data often involves unmeasured factors and sampling bias. Because of this, the estimate may be off, and the confidence interval should be wider to reflect greater uncertainty.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

###

Always go back to your Preceptor Table, the information which, if you had it, would make answering your question easy. In almost all real world cases, the Preceptor Table and the data are fairly different, not least because validity never holds perfectly. So, even a perfectly estimated statistical model is rarely as useful as we might like.

### Exercise 10

Rearrange the material in your QMD so that the order is graphic, followed by the paragraph. Doing so, of course, requires sensible judgment. For example, the code chunk which creates the fitted model must occur before the chunk which creates the graphic. You can keep or discard the math and any other material at your own discretion.

`Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd")
```

CP/CR.

```{r temperance-10}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 30)
```

###

This is the version of your QMD file which your teacher is most likely to take a close look at.

### Exercise 11

Publish your rendered QMD to GitHub Pages. Copy/paste the resulting url below.

```{r temperance-11}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

###

Commit/push everything.

### Exercise 12

Copy/paste the url to your Github repo.

```{r temperance-12}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

###

We can never know all the entries in the Preceptor Table. That knowledge is reserved for God. If all our assumptions are correct, then our DGM is true, it accurately describes the way in which the world works. There is no better way to predict the future, or to model the past, than to use it. Sadly, this will only be the case with toy examples involving things like coins and dice. We hope that our DGM is close to the true DGM but, since our assumptions are never perfectly correct, our DGM will always be different. The estimated magnitude and importance of that difference is a matter of judgment.

The world confronts us. Make decisions we must.

<!-- XX: Make some comments about what this plot is telling us, especially with regard to the questions with which we began. What are the most important takeaways from this plot? (Obviously, this will -->


<!-- DK: Some potentially useful leftover junk. -->


<!-- Write a paragraph which summarizes the project in your own words. The first few sentences are the same as what you had at the end of the Courage Section. But, since your question may have evolved, you should feel free to change those sentences. Add at least one sentence which describes at least one quantity of interest (QoI) --- presumably one that answers your question -- and which provides a measure of uncertainty about that QoI.


question_text(NULL,
	message = "Using data from a YouGov poll of 1,559 US adult citizens, conducted March 10 - 12, 2024, we seek to understand what proportion of voters will support Biden in the 2024 election. Biden’s popularity might change significantly over the course of the election campaign. In the poll, Biden’s support was much less than 50%. We estimate that Biden’s percentage of the vote in Election Day will be about 42%, plus or minus 2.5%.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)

###

Edit the summary paragraph in `models.qmd` as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`. -->



## Summary
###

This tutorial covered [Chapter 4: Models](https://ppbds.github.io/primer/models.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/).



```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
